{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type : <class 'pandas.core.frame.DataFrame'>,   data의 shape : (70000, 784)\n",
      "target의 type : <class 'pandas.core.series.Series'>,   target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "data, target = mnist[\"data\"], mnist[\"target\"]\n",
    "print(f\"data의 type : {type(data)},   data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},   target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], ordered=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type : <class 'numpy.ndarray'>,   data의 shape : (70000, 784)\n",
      "target의 type : <class 'numpy.ndarray'>,   target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "target = target.astype(np.int8)\n",
    "data, target = data.values, target.values\n",
    "\n",
    "print(f\"data의 type : {type(data)},   data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},   target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(target[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6903, 1: 7877, 2: 6990, 3: 7141, 4: 6824, 5: 6313, 6: 6876, 7: 7293, 8: 6825, 9: 6958}\n"
     ]
    }
   ],
   "source": [
    "target_dict = {}\n",
    "label, freq = np.unique(target, return_counts=True)\n",
    "\n",
    "for l, f in zip(label, freq):\n",
    "    target_dict[l] = f\n",
    "    \n",
    "print(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "data = data / 255       # To keep our gradients manageable\n",
    "print(np.max(data), np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 70000, 10)\n",
      "[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "digits = 10\n",
    "examples = target.shape[0]    # 70000\n",
    "\n",
    "target_new = np.eye(digits)[target.reshape(1,-1)]   # target.reshape(1,-1) : (1, 70000),  target_new.shape : (1, 70000, 10)\n",
    "\n",
    "print(target_new.shape)\n",
    "print(target_new[:, 10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 10)\n"
     ]
    }
   ],
   "source": [
    "target_new = target_new.reshape(-1, 10)\n",
    "print(target_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),   y_train의 shape : (10, 60000)\n",
      "x_test의  shape : (784, 10000),   y_test의 shape :  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "m = 60000\n",
    "m_test = data.shape[0] - m\n",
    "\n",
    "x_train, x_test = data[:m].T, data[m:].T\n",
    "y_train, y_test = target_new[:m].T, target_new[m:].T\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},   y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의  shape : {x_test.shape},   y_test의 shape :  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),   y_train의 shape : (10, 60000)\n",
      "x_test의  shape : (784, 10000),   y_test의 shape :  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "x_train, y_train = x_train[:, shuffle_index], y_train[:, shuffle_index]\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},   y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의  shape : {x_test.shape},   y_test의 shape :  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIDklEQVR4nO3cMaiX9R7H8efEEZyyRZyCCBKHVBSC5rQpEqRNGtsaBHHQuUQUmlvcHRJxCopa0iUIAgcXHSoIiYI4IeggPHe4lzd3iLi//z3nPP9Or9f+4f9F0Le/5dmY53meAGCapheWPgCA9SEKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAGRz6QNgXdy6dWt48/nnnw9vbt++PbyZpmna2toa3nz44YfDm/Pnzw9vXnvtteEN68lLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAZGOe53npI2C7ffTRR8Obq1evDm+ePn06vFl3L7300vDm999/3/5DWISXAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiA/isfYeP348vDly5Mjw5o8//hje8G9ffvnl8Obtt9/egUv4f3kpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA2Vz6AP45nj9/vtLu+vXrw5vd+uLpBx98MLy5fPnySr914MCB4c2jR4+GN2+++ebwxhdm9w4vBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAkI15nuelj+Cf4bfffltpd/DgwW2+5M9duHBhePPJJ5/swCXbZ5X7Ll68OLzxz8je4aUAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQCyufQBsC7Onj279Anb7tChQ8Obb775Zgcu4e/CSwGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAMQH8dg19+/fX/qEv/TCC3vv/0jvv//+0ifwN7P3/hYAsDJRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIA8ZVUds1333239Al/6e7du8ObX3/9dQcu+XM//fTT8GZra2t488477wxvTpw4MbxhPXkpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA+CAe/MelS5eWPmEtXLlyZXjzww8/DG/2798/vJmmaTpw4MBKO/43XgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACA+iMeuefjw4dInbLtDhw4Nb959992Vfuvll18e3pw+fXql3xq1yp8D68lLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxAfxWMmFCxeGNzdu3NiBS7bPsWPHhjefffbZ8Obw4cPDG9gtXgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACAb8zzPSx/Bsu7fvz+8OX78+A5csqyvv/56ePPWW2/twCWwHC8FACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgm0sfwPJu3769K79z9OjRlXZnzpwZ3ly5cmV4c/PmzeGNr6Sy13gpABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGA+CAe01dffTW8eeWVV4Y3X3zxxfBmmqbpwYMHw5tr166t9FvwT+elAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAsjHP87z0EWyfH3/8cXhz/Pjx4c3rr78+vLl3797wZlUHDx4c3mxujn8f8vHjx8MbWGdeCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIONfAGOtPX36dHiztbW1A5dsn++//3548+TJk+HNG2+8MbyBvcZLAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoAxAfx9phXX311eHPy5Mnhzc8//zy8uXPnzvBmmqbp+vXrw5tnz54Nb957773hDew1XgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEA25nmelz6CZZ07d254c/PmzR24ZPu8+OKLw5tvv/12eHPkyJHhDawzLwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoAJDNpQ9geadOnRrerPsH8T7++OPhjY/bgZcCAP9FFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIBvzPM9LH8Gyfvnll+HNtWvXhjeffvrp8Gaapuny5cu7stm3b9/wBvYaLwUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABAfxAMgXgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoA5F8fZ9IEMv9HVAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 2023 * 2\n",
    "plt.imshow(x_train[:, i].reshape(28,28), cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y_train[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_multiclass_loss(y, y_hat):\n",
    "    L_sum = np.sum(np.multiply(y, np.log(y_hat)))\n",
    "    m = y.shape[1]\n",
    "    L = -(1.0/m) * L_sum\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, params):\n",
    "    cache = {}\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
    "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(X, Y, params, cache):\n",
    "    \n",
    "    dz2 = cache[\"A2\"] - Y\n",
    "    dw2 = (1.0/m_batch) * np.matmul(dz2, cache[\"A1\"].T)\n",
    "    db2 = (1.0/m_batch) * np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.matmul(params[\"W2\"].T, dz2)\n",
    "    dz1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "    dw1 = (1.0/m_batch) * np.matmul(dz1, X.T)\n",
    "    db1 = (1.0/m_batch) * np.sum(dz1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dw1\" : dw1, \"db1\" : db1, \"dw2\" : dw2, \"db2\" : db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the substansive stuff\n",
    "# To switch to mini-batch descent, we add another for loop inside the pass through each epoch. At each pass we randomly shuffle the training set, then iterate through it\n",
    "# in chunks of batch_size, which we'll arbitrarily set to 128. We'll see the code for all this in a moment.\n",
    "# Next, to add momentum, we keep a moving average of our gradients. So instead of upgrading our parameters by doing e.g.:\n",
    "# params[\"W1\"] = params[\"W1\"] - learning_rate * grads[\"dw1\"], we do this:\n",
    "# v_dw1 = (beta * v_dw1 + (1 - bata) * grads[\"dw1\"]),  params[\"W1\"] = params[\"W1\"] - learning_rage * v_dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "# hyperparameters\n",
    "n_x = x_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "beta = 0.9\n",
    "batch_size = 128\n",
    "batches = -(-m // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "params = {\"W1\" : np.random.randn(n_h, n_x) * np.sqrt(1.0/n_x),     \"b1\" : np.zeros((n_h, 1)) * np.sqrt(1.0/n_x),\n",
    "          \"W2\" : np.random.randn(digits, n_h) * np.sqrt(1.0/n_h),  \"b2\" : np.zeros((digits, 1)) * np.sqrt(1.0/n_h)}\n",
    "\n",
    "v_dw1 = np.zeros(params[\"W1\"].shape)\n",
    "v_db1 = np.zeros(params[\"b1\"].shape)\n",
    "v_dw2 = np.zeros(params[\"W2\"].shape)\n",
    "v_db2 = np.zeros(params[\"b2\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : training cost = 0.19376645530967887,  test cost : 0.1961419081373025\n",
      "Epoch 2 : training cost = 0.15299199295317745,  test cost : 0.1588419715826621\n",
      "Epoch 3 : training cost = 0.13041660850111927,  test cost : 0.14212718629785762\n",
      "Epoch 4 : training cost = 0.11133348373953401,  test cost : 0.12329826532073353\n",
      "Epoch 5 : training cost = 0.09673403186641309,  test cost : 0.11128546372341067\n",
      "Epoch 6 : training cost = 0.08564250500939995,  test cost : 0.10460291827141845\n",
      "Epoch 7 : training cost = 0.07748026503775822,  test cost : 0.09986950286901866\n",
      "Epoch 8 : training cost = 0.07053965274364542,  test cost : 0.09440637475955815\n",
      "Epoch 9 : training cost = 0.06633694311742425,  test cost : 0.0919795313356268\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for i in range(9):\n",
    "    \n",
    "    permutation = np.random.permutation(x_train.shape[1])\n",
    "    x_train_shuffled = x_train[:, permutation]\n",
    "    y_train_shuffled = y_train[:, permutation]\n",
    "    \n",
    "    for j in range(batches):\n",
    "        begin = j * batch_size\n",
    "        end = min(begin + batch_size, x_train.shape[1] - 1)\n",
    "        X = x_train_shuffled[:, begin:end]\n",
    "        Y = y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "        \n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache)\n",
    "        \n",
    "        v_dw1 = (beta * v_dw1 + (1.0 - beta) * grads[\"dw1\"])\n",
    "        v_db1 = (beta * v_db1 + (1.0 - beta) * grads[\"db1\"])\n",
    "        v_dw2 = (beta * v_dw2 + (1.0 - beta) * grads[\"dw2\"])\n",
    "        v_db2 = (beta * v_db2 + (1.0 - beta) * grads[\"db2\"])\n",
    "        \n",
    "        params[\"W1\"] -= learning_rate * v_dw1\n",
    "        params[\"b1\"] -= learning_rate * v_db1\n",
    "        params[\"W2\"] -= learning_rate * v_dw2\n",
    "        params[\"b2\"] -= learning_rate * v_db2\n",
    "        \n",
    "    cache = feed_forward(x_train, params)\n",
    "    train_cost = compute_multiclass_loss(y_train, cache[\"A2\"])\n",
    "    cache = feed_forward(x_test, params)\n",
    "    test_cost = compute_multiclass_loss(y_test, cache[\"A2\"])\n",
    "    print(f\"Epoch {i+1:d} : training cost = {train_cost},  test cost : {test_cost}\")\n",
    "    \n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       991\n",
      "           1       0.99      0.99      0.99      1134\n",
      "           2       0.98      0.96      0.97      1046\n",
      "           3       0.97      0.98      0.97      1004\n",
      "           4       0.98      0.96      0.97      1000\n",
      "           5       0.97      0.96      0.96       905\n",
      "           6       0.97      0.97      0.97       955\n",
      "           7       0.95      0.98      0.96      1005\n",
      "           8       0.97      0.96      0.96       979\n",
      "           9       0.95      0.98      0.96       981\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cache = feed_forward(x_test, params)\n",
    "predictions = np.argmax(cache[\"A2\"], axis=0)\n",
    "labels = np.argmax(y_test, axis=0)\n",
    "\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 967    0    4    0    0    4    7    1    5    3]\n",
      " [   0 1120    0    0    0    1    3    6    0    4]\n",
      " [   0    4 1008    7    2    0    1   19    4    1]\n",
      " [   0    0    4  979    1    7    1    4    2    6]\n",
      " [   0    0    5    0  962    1    3    5    5   19]\n",
      " [   4    1    0   10    0  867    9    0    5    9]\n",
      " [   5    4    1    1    5    5  929    0    5    0]\n",
      " [   2    0    5    7    1    2    0  980    3    5]\n",
      " [   2    6    5    5    3    4    5    3  942    4]\n",
      " [   0    0    0    1    8    1    0   10    3  958]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
