{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml(\"mnist_784\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type : <class 'pandas.core.frame.DataFrame'>,   data의 shape : (70000, 784)\n",
      "target의 type : <class 'pandas.core.series.Series'>,   target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "data, target = mnist[\"data\"], mnist[\"target\"]\n",
    "print(f\"data의 type : {type(data)},   data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},   target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], ordered=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type : <class 'numpy.ndarray'>,   data의 shape : (70000, 784)\n",
      "target의 type : <class 'numpy.ndarray'>,   target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "target = target.astype(np.int8)\n",
    "data, target = data.values, target.values\n",
    "\n",
    "print(f\"data의 type : {type(data)},   data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},   target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(target[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6903, 1: 7877, 2: 6990, 3: 7141, 4: 6824, 5: 6313, 6: 6876, 7: 7293, 8: 6825, 9: 6958}\n"
     ]
    }
   ],
   "source": [
    "target_dict = {}\n",
    "label, freq = np.unique(target, return_counts=True)\n",
    "\n",
    "for l, f in zip(label, freq):\n",
    "    target_dict[l] = f\n",
    "    \n",
    "print(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "data = data / 255       # To keep our gradients manageable\n",
    "print(np.max(data), np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 70000, 10)\n",
      "[[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "digits = 10\n",
    "examples = target.shape[0]    # 70000\n",
    "\n",
    "target_new = np.eye(digits)[target.reshape(1,-1)]   # target.reshape(1,-1) : (1, 70000),  target_new.shape : (1, 70000, 10)\n",
    "\n",
    "print(target_new.shape)\n",
    "print(target_new[:, 10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 10)\n"
     ]
    }
   ],
   "source": [
    "target_new = target_new.reshape(-1, 10)\n",
    "print(target_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),   y_train의 shape : (10, 60000)\n",
      "x_test의  shape : (784, 10000),   y_test의 shape :  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "m = 60000\n",
    "m_test = data.shape[0] - m\n",
    "\n",
    "x_train, x_test = data[:m].T, data[m:].T\n",
    "y_train, y_test = target_new[:m].T, target_new[m:].T\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},   y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의  shape : {x_test.shape},   y_test의 shape :  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),   y_train의 shape : (10, 60000)\n",
      "x_test의  shape : (784, 10000),   y_test의 shape :  (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "x_train, y_train = x_train[:, shuffle_index], y_train[:, shuffle_index]\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},   y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의  shape : {x_test.shape},   y_test의 shape :  {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 2023\n",
    "plt.imshow(x_train[:, i].reshape(28,28), cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y_train[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_multiclass_loss(y, y_hat):\n",
    "    L_sum = np.sum(np.multiply(y, np.log(y_hat)))\n",
    "    m = y.shape[1]\n",
    "    L = -(1.0/m) * L_sum\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, params):\n",
    "    cache = {}\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"], X) + params[\"b1\"]\n",
    "    cache[\"A1\"] = sigmoid(cache[\"Z1\"])\n",
    "    cache[\"Z2\"] = np.matmul(params[\"W2\"], cache[\"A1\"]) + params[\"b2\"]\n",
    "    cache[\"A2\"] = np.exp(cache[\"Z2\"]) / np.sum(np.exp(cache[\"Z2\"]), axis=0)\n",
    "    \n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(X, Y, params, cache):\n",
    "    \n",
    "    dz2 = cache[\"A2\"] - Y\n",
    "    dw2 = (1.0/m_batch) * np.matmul(dz2, cache[\"A1\"].T)\n",
    "    db2 = (1.0/m_batch) * np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    dA1 = np.matmul(params[\"W2\"].T, dz2)\n",
    "    dz1 = dA1 * sigmoid(cache[\"Z1\"]) * (1 - sigmoid(cache[\"Z1\"]))\n",
    "    dw1 = (1.0/m_batch) * np.matmul(dz1, X.T)\n",
    "    db1 = (1.0/m_batch) * np.sum(dz1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dw1\" : dw1, \"db1\" : db1, \"dw2\" : dw2, \"db2\" : db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the substansive stuff\n",
    "# To switch to mini-batch descent, we add another for loop inside the pass through each epoch. At each pass we randomly shuffle the training set, then iterate through it\n",
    "# in chunks of batch_size, which we'll arbitrarily set to 128. We'll see the code for all this in a moment.\n",
    "# Next, to add momentum, we keep a moving average of our gradients. So instead of upgrading our parameters by doing e.g.:\n",
    "# params[\"W1\"] = params[\"W1\"] - learning_rate * grads[\"dw1\"], we do this:\n",
    "# v_dw1 = (beta * v_dw1 + (1 - bata) * grads[\"dw1\"]),  params[\"W1\"] = params[\"W1\"] - learning_rage * v_dw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "# hyperparameters\n",
    "n_x = x_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "beta = 0.9\n",
    "batch_size = 128\n",
    "batches = -(-m // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "params = {\"W1\" : np.random.randn(n_h, n_x) * np.sqrt(1.0/n_x),     \"b1\" : np.zeros((n_h, 1)) * np.sqrt(1.0/n_x),\n",
    "          \"W2\" : np.random.randn(digits, n_h) * np.sqrt(1.0/n_h),  \"b2\" : np.zeros((digits, 1)) * np.sqrt(1.0/n_h)}\n",
    "\n",
    "v_dw1 = np.zeros(params[\"W1\"].shape)\n",
    "v_db1 = np.zeros(params[\"b1\"].shape)\n",
    "v_dw2 = np.zeros(params[\"W2\"].shape)\n",
    "v_db2 = np.zeros(params[\"b2\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'A1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Jonathan_Weisberg\\OneHiddenNode_Digit1.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m Y \u001b[39m=\u001b[39m y_train_shuffled[:, begin:end]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m m_batch \u001b[39m=\u001b[39m end \u001b[39m-\u001b[39m begin\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cache \u001b[39m=\u001b[39m feed_forward(X, params)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m grads \u001b[39m=\u001b[39m back_propagate(X, Y, params, cache)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m v_dw1 \u001b[39m=\u001b[39m (beta \u001b[39m*\u001b[39m v_dw1 \u001b[39m+\u001b[39m (\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta) \u001b[39m*\u001b[39m grads[\u001b[39m\"\u001b[39m\u001b[39mdw1\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;32me:\\딥러닝입문\\Jonathan_Weisberg\\OneHiddenNode_Digit1.ipynb Cell 20\u001b[0m in \u001b[0;36mfeed_forward\u001b[1;34m(X, params)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m cache[\u001b[39m\"\u001b[39m\u001b[39mZ1\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(params[\u001b[39m\"\u001b[39m\u001b[39mW1\u001b[39m\u001b[39m\"\u001b[39m], X) \u001b[39m+\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mb1\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m cache[\u001b[39m\"\u001b[39m\u001b[39mA1\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sigmoid(cache[\u001b[39m\"\u001b[39m\u001b[39mZ1\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m cache[\u001b[39m\"\u001b[39m\u001b[39mZ2\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmatmul(params[\u001b[39m\"\u001b[39m\u001b[39mW2\u001b[39m\u001b[39m\"\u001b[39m], params[\u001b[39m\"\u001b[39;49m\u001b[39mA1\u001b[39;49m\u001b[39m\"\u001b[39;49m]) \u001b[39m+\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mb2\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m cache[\u001b[39m\"\u001b[39m\u001b[39mA2\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(params[\u001b[39m\"\u001b[39m\u001b[39mZ2\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mexp(params[\u001b[39m\"\u001b[39m\u001b[39mZ2\u001b[39m\u001b[39m\"\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Jonathan_Weisberg/OneHiddenNode_Digit1.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cache\n",
      "\u001b[1;31mKeyError\u001b[0m: 'A1'"
     ]
    }
   ],
   "source": [
    "# train\n",
    "for i in range(2000):\n",
    "    \n",
    "    permutation = np.random.permutation(x_train.shape[1])\n",
    "    x_train_shuffled = x_train[:, permutation]\n",
    "    y_train_shuffled = y_train[:, permutation]\n",
    "    \n",
    "    for j in range(batches):\n",
    "        begin = j * batch_size\n",
    "        end = min(begin + batch_size, x_train.shape[1] - 1)\n",
    "        X = x_train_shuffled[:, begin:end]\n",
    "        Y = y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "        \n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache)\n",
    "        \n",
    "        v_dw1 = (beta * v_dw1 + (1.0 - beta) * grads[\"dw1\"])\n",
    "        v_db1 = (beta * v_db1 + (1.0 - beta) * grads[\"db1\"])\n",
    "        v_dw2 = (beta * v_dw2 + (1.0 - beta) * grads[\"dw2\"])\n",
    "        v_db2 = (beta * v_db2 + (1.0 - beta) * grads[\"db2\"])\n",
    "        \n",
    "        params[\"W1\"] -= learning_rate * v_dw1\n",
    "        params[\"b1\"] -= learning_rate * v_db1\n",
    "        params[\"W2\"] -= learning_rate * v_dw2\n",
    "        params[\"b2\"] -= learning_rate * v_db2\n",
    "        \n",
    "    cache = feed_forward(x_train, params)\n",
    "    train_cost = compute_multiclass_loss(y_train, cache[\"A2\"])\n",
    "    cache = feed_forward(x_test, params)\n",
    "    test_cost = compute_multiclass_loss(y_test, cache[\"A2\"])\n",
    "    print(f\"Epoch {i+1} : training cost = {train_cost},  test cost : {test_cost}\")\n",
    "    \n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
