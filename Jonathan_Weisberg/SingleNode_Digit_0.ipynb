{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hello, MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mnist dataset from sklearn\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1797, 64)\n",
      "<class 'numpy.ndarray'> (1797,)\n"
     ]
    }
   ],
   "source": [
    "# load_digits() is a short version of mnist dataset\n",
    "\"\"\"\n",
    "mnist = load_digits()\n",
    "x, y = mnist['data'], mnist['target']\n",
    "\n",
    "print(type(x), x.shape)\n",
    "print(type(y), y.shape)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784) (70000,)\n"
     ]
    }
   ],
   "source": [
    "# import mnist dataset from sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')\n",
    "x, y = mnist['data'].values, mnist['target']\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "category\n",
      "[<class 'str'>]\n",
      "[<class 'float'>]\n"
     ]
    }
   ],
   "source": [
    "print(type(x))\n",
    "print(type(y))\n",
    "print(y.dtypes)\n",
    "print([type(i) for i in y[:1]])\n",
    "\n",
    "# since y' dtype is str, we need to convert it to float\n",
    "y = y.astype(float)\n",
    "print([type(i) for i in y[:1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize x to keep our gradients manageable\n",
    "x = x / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to build a zero-classifier, make the label 1 when we have a zero, and 0 otherwise\n",
    "import numpy as np\n",
    "y_new = np.zeros(shape=y.shape)\n",
    "y_new[np.where(y == 0.0)] = 1\n",
    "y = y_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (1, 60000) (784, 10000) (1, 10000)\n",
      "(784,) (1,)\n",
      "\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# we can make our train/test split. we'll also transform the data into the shape we want, with each example in a column(instead of a row)\n",
    "m = 60000\n",
    "m_test = x.shape[0] - m\n",
    "\n",
    "x_train, x_test = x[:m].T, x[m:].T\n",
    "y_train, y_test = y[:m].reshape(1,m), y[m:].reshape(1,m_test)\n",
    "\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(x_train[:,0].shape, y_train[:1,0].shape)\n",
    "print()\n",
    "print(x_train[:10, 0])\n",
    "print(y_train[0, :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "# finally we shuffle the training set for good measure\n",
    "np.random.seed(138)\n",
    "shuffle_index = np.random.permutation(m)\n",
    "x_train, y_train = x_train[:, shuffle_index], y_train[:, shuffle_index]\n",
    "print(x_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# take a look at a random image\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "i = 1\n",
    "plt.imshow(x_train[:, i].reshape(28, 28), cmap=matplotlib.cm.binary)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print(y_train[0][i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build & Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_loss(Y, Y_hat):\n",
    "    m = Y.shape[1]\n",
    "    L = -(1.0/m) * (np.sum(np.multiply(np.log(Y_hat), Y)) + np.sum(np.multiply(np.log(1-Y_hat), (1-Y))))\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (1, 60000)\n"
     ]
    }
   ],
   "source": [
    "X, Y = x_train, y_train\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 60000\n"
     ]
    }
   ],
   "source": [
    "n_x = X.shape[0]    # number of features\n",
    "m = X.shape[1]      # number of examples\n",
    "print(n_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W.shape : (784, 1),  b.shape : (1, 1)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.randn(n_x, 1) * 0.01\n",
    "b = np.zeros((1,1))\n",
    "print(f\"W.shape : {W.shape},  b.shape : {b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z.shape : (1, 60000)\n",
      "A.shape : (1, 60000)\n",
      "(A-Y).T shape : (60000, 1)\n",
      "dW.shape : (784, 1)\n",
      "db.shape : (1, 1)\n",
      "[[0.38819289]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.matmul(W.T, X) + b\n",
    "print(f\"Z.shape : {Z.shape}\")\n",
    "\n",
    "A = sigmoid(Z)\n",
    "print(f\"A.shape : {A.shape}\")\n",
    "\n",
    "print(f\"(A-Y).T shape : {((A-Y).T).shape}\")\n",
    "\n",
    "\n",
    "dW = (1/m) * np.matmul(X, (A-Y).T)\n",
    "print(f\"dW.shape : {dW.shape}\")\n",
    "\n",
    "db = (1/m) * np.sum((A-Y)).reshape(-1,1)\n",
    "print(f\"db.shape : {db.shape}\")\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6784013154196323"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(Y, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0   cost : 0.6784013154196323\n",
      "Epoch 100   cost : 0.041302908759714714\n",
      "Epoch 200   cost : 0.03578437989110894\n",
      "Epoch 300   cost : 0.03322549293126029\n",
      "Epoch 400   cost : 0.031628739415190746\n",
      "Epoch 500   cost : 0.03049178280959142\n",
      "Epoch 600   cost : 0.02962165753217041\n",
      "Epoch 700   cost : 0.028925362656828373\n",
      "Epoch 800   cost : 0.02835107252343741\n",
      "Epoch 900   cost : 0.02786688272412182\n",
      "Epoch 1000   cost : 0.027451709456821065\n",
      "Epoch 1100   cost : 0.027090875867479547\n",
      "Epoch 1200   cost : 0.02677375567467287\n",
      "Epoch 1300   cost : 0.026492416327870926\n",
      "Epoch 1400   cost : 0.02624078932763677\n",
      "Epoch 1500   cost : 0.026014137871112\n",
      "Epoch 1600   cost : 0.025808701689659486\n",
      "Epoch 1700   cost : 0.025621452389434335\n",
      "Epoch 1800   cost : 0.025449920349893834\n",
      "Epoch 1900   cost : 0.025292069445598375\n",
      "f{Final cost : {cost}}\n"
     ]
    }
   ],
   "source": [
    "for i in range(2000):\n",
    "    Z = np.matmul(W.T, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    cost = compute_loss(Y, A)\n",
    "    \n",
    "    dW = (1/m) * np.matmul(X, (A-Y).T)\n",
    "    db = (1/m) * np.sum((A-Y)).reshape(-1,1)\n",
    "    \n",
    "    W -= learning_rate * dW\n",
    "    b -= learning_rate * db\n",
    "    \n",
    "    if (i % 100 == 0):\n",
    "        print(f\"Epoch {i:>3d}   cost : {cost}\")\n",
    "        \n",
    "print(f\"Final cost : {cost}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
