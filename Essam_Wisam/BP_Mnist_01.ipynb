{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type   : <class 'pandas.core.frame.DataFrame'>,  data의 shape : (70000, 784)\n",
      "target의 type : <class 'pandas.core.series.Series'>,    target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "data, target = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "print(f\"data의 type   : {type(data)},  data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},    target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalDtype(categories=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], ordered=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 type   : <class 'numpy.ndarray'>,  data의 shape : (70000, 784)\n",
      "target의 type : <class 'numpy.ndarray'>,    target의 shape : (70000,)\n"
     ]
    }
   ],
   "source": [
    "target = target.astype(np.int8)\n",
    "data, target = data.values, target.values\n",
    "\n",
    "print(f\"data의 type   : {type(data)},  data의 shape : {data.shape}\")\n",
    "print(f\"target의 type : {type(target)},    target의 shape : {target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 3 6 1 7 2 8 6 9]\n"
     ]
    }
   ],
   "source": [
    "print(target[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 6903, 1: 7877, 2: 6990, 3: 7141, 4: 6824, 5: 6313, 6: 6876, 7: 7293, 8: 6825, 9: 6958}\n"
     ]
    }
   ],
   "source": [
    "target_dict = {}\n",
    "label, freq = np.unique(target, return_counts=True)\n",
    "\n",
    "for l, f in zip(label, freq):\n",
    "    target_dict[l] = f\n",
    "    \n",
    "print(target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255.0 0.0\n",
      "1.0 0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(data), np.min(data))\n",
    "\n",
    "data = data / 255      # To keep our gradients manageable\n",
    "print(np.max(data), np.min(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = 10\n",
    "examples = target.shape[0]     # 70000\n",
    "target_new = np.eye(digits)[target.reshape(1, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_new의 shape : (1, 70000, 10)\n",
      "\n",
      "[3 5 3 6 1 7 2 8 6 9]\n",
      "\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"target_new의 shape : {target_new.shape}\")\n",
    "print()\n",
    "print(target[10:20])\n",
    "print()\n",
    "print(target_new[0, 10:20, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target의 shape : (70000, 10)\n",
      "\n",
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "target_new = target_new.reshape(-1, 10)\n",
    "print(f\"target의 shape : {target_new.shape}\")\n",
    "print()\n",
    "print(target_new[10:20, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),     y_train의 shape : (10, 60000)\n",
      "x_test의 shape  : (784, 10000),     y_test의 shape  : (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "m = 60000\n",
    "m_test = data.shape[0] - m\n",
    "\n",
    "x_train, x_test = data[:m].T, data[m:].T\n",
    "y_train, y_test = target_new[:m].T, target_new[m:].T\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},     y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의 shape  : {x_test.shape},     y_test의 shape  : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 shape : (784, 60000),     y_train의 shape : (10, 60000)\n",
      "x_test의 shape  : (784, 10000),     y_test의 shape  : (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "shuffle_index = np.random.permutation(m)\n",
    "x_train, y_train = x_train[:, shuffle_index], y_train[:, shuffle_index]\n",
    "\n",
    "print(f\"x_train의 shape : {x_train.shape},     y_train의 shape : {y_train.shape}\")\n",
    "print(f\"x_test의 shape  : {x_test.shape},     y_test의 shape  : {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "i = 20230\n",
    "plt.imshow(x_train[:, i].reshape(28, 28), cmap=matplotlib.cm.binary)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "print(y_train[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1.0 / (1.0 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "def compute_multiclass_loss(y, y_hat):\n",
    "    L_sum = np.sum(np.multiply(y, np.log(y_hat)))\n",
    "    m = y.shape[1]\n",
    "    L = -(1.0/m) * L_sum\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(X, params):\n",
    "    cache = {}\n",
    "    cache[\"Z0\"] = np.matmul(params[\"W0\"].T, X) + params[\"b0\"]\n",
    "    cache[\"A0\"] = sigmoid(cache[\"Z0\"])\n",
    "    cache[\"Z1\"] = np.matmul(params[\"W1\"].T, cache[\"A0\"]) + params[\"b1\"]\n",
    "    cache[\"A1\"] = np.exp(cache[\"Z1\"]) / np.sum(np.exp(cache[\"Z1\"]), axis=0)\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(X, Y, params, cache, m_batch):\n",
    "    delta1 = cache[\"A1\"] - Y    # (10, 60000)\n",
    "    dw1 = (1.0/m_batch) * np.matmul(cache[\"A0\"], delta1.T)     # (64, 60000) * (60000, 10) = (64, 10)\n",
    "    db1 = (1.0/m_batch) * np.sum(delta1, axis=1, keepdims=True)   # (10, 1)\n",
    "    \n",
    "    delta0 = np.multiply(sigmoid(cache[\"Z0\"]) * (1.0 - sigmoid(cache[\"Z0\"])), np.matmul(params[\"W1\"], delta1)) # (64,60000) & (64,10)*(10, 60000)=(64,60000) ==> (64,60000)\n",
    "    \n",
    "    dw0 = (1.0/m_batch) * np.matmul(X, delta0.T)\n",
    "    db0 = (1.0/m_batch) * np.sum(delta0, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dw0\" : dw0, \"db0\" : db0, \"dw1\" : dw1, \"db1\" : db1}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2  -6 -20 -42]\n",
      " [  0 -12  -2 -56]\n",
      " [-42  -2  -6 -42]]\n",
      "[[41 15 22 36]\n",
      " [34 46 13 33]\n",
      " [23 17 11 21]]\n",
      "[[  -82   -90  -440 -1512]\n",
      " [    0  -552   -26 -1848]\n",
      " [ -966   -34   -66  -882]]\n"
     ]
    }
   ],
   "source": [
    "q0 = np.array([[2,3,5,7],[1,4,2,8],[7,2,3,7]])\n",
    "\n",
    "w1 = np.array([[2,5],[9,1],[3,2]])\n",
    "d1 = np.array([[3,5,1,3],[7,1,4,6]])\n",
    "\n",
    "print(q0 * (1-q0))\n",
    "print(np.matmul(w1, d1))\n",
    "print(q0 * (1-q0) * np.matmul(w1, d1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2023)\n",
    "\n",
    "n_x = x_train.shape[0]\n",
    "n_h = 64\n",
    "learning_rate = 1\n",
    "beta = 0.9\n",
    "batch_size = 128\n",
    "batches = m // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"W0\" : np.random.randn(n_x, n_h) * np.sqrt(1.0/n_x),    \"b0\" : np.zeros((n_h, 1)) * np.sqrt(1.0/n_x),\n",
    "          \"W1\" : np.random.randn(n_h, digits) * np.sqrt(1.0/n_h), \"b1\" : np.zeros((digits, 1)) * np.sqrt(1.0/n_h)}\n",
    "\n",
    "v_dw0 = np.zeros(params[\"W0\"].shape)\n",
    "v_db0 = np.zeros(params[\"b0\"].shape)\n",
    "v_dw1 = np.zeros(params[\"W1\"].shape)\n",
    "v_db1 = np.zeros(params[\"b1\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 : training cost = 0.2474298118,  test cost : 0.2473321741\n",
      "Epoch  2 : training cost = 0.1933355579,  test cost : 0.1970380586\n",
      "Epoch  3 : training cost = 0.1491959792,  test cost : 0.1559571629\n",
      "Epoch  4 : training cost = 0.1268977925,  test cost : 0.1371186696\n",
      "Epoch  5 : training cost = 0.1106544184,  test cost : 0.1224431577\n",
      "Epoch  6 : training cost = 0.0964592784,  test cost : 0.1091176707\n",
      "Epoch  7 : training cost = 0.0857526438,  test cost : 0.1025292590\n",
      "Epoch  8 : training cost = 0.0796376342,  test cost : 0.1000686749\n",
      "Epoch  9 : training cost = 0.0716921716,  test cost : 0.0929349102\n",
      "Epoch 10 : training cost = 0.0668371152,  test cost : 0.0908083798\n",
      "Epoch 11 : training cost = 0.0643064472,  test cost : 0.0920360582\n",
      "Epoch 12 : training cost = 0.0566496754,  test cost : 0.0856498351\n",
      "Epoch 13 : training cost = 0.0521565918,  test cost : 0.0825498468\n",
      "Epoch 14 : training cost = 0.0492943199,  test cost : 0.0830321695\n",
      "Epoch 15 : training cost = 0.0482665570,  test cost : 0.0834291647\n",
      "Epoch 16 : training cost = 0.0430914611,  test cost : 0.0811881788\n",
      "Epoch 17 : training cost = 0.0402461034,  test cost : 0.0806583154\n",
      "Epoch 18 : training cost = 0.0390948539,  test cost : 0.0815807157\n",
      "Epoch 19 : training cost = 0.0353516723,  test cost : 0.0772115473\n",
      "Epoch 20 : training cost = 0.0336996015,  test cost : 0.0763892050\n",
      "Epoch 21 : training cost = 0.0312890689,  test cost : 0.0770634494\n",
      "Epoch 22 : training cost = 0.0309777518,  test cost : 0.0775077805\n",
      "Epoch 23 : training cost = 0.0294066045,  test cost : 0.0776526250\n",
      "Epoch 24 : training cost = 0.0264350078,  test cost : 0.0761203362\n",
      "Epoch 25 : training cost = 0.0256336561,  test cost : 0.0774400377\n",
      "Epoch 26 : training cost = 0.0240442809,  test cost : 0.0767998027\n",
      "Epoch 27 : training cost = 0.0228689267,  test cost : 0.0759367819\n",
      "Epoch 28 : training cost = 0.0227612123,  test cost : 0.0784477384\n",
      "Epoch 29 : training cost = 0.0212529074,  test cost : 0.0781787354\n",
      "Epoch 30 : training cost = 0.0195108081,  test cost : 0.0776265648\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    \n",
    "    permutation = np.random.permutation(x_train.shape[1])\n",
    "    x_train_shuffled = x_train[:, permutation]\n",
    "    y_train_shuffled = y_train[:, permutation]\n",
    "    \n",
    "    for j in range(batches):\n",
    "        begin = j * batch_size\n",
    "        end = min(begin + batch_size, x_train.shape[1]-1)\n",
    "        X = x_train_shuffled[:, begin:end]\n",
    "        Y = y_train_shuffled[:, begin:end]\n",
    "        m_batch = end - begin\n",
    "        \n",
    "        cache = feed_forward(X, params)\n",
    "        grads = back_propagate(X, Y, params, cache, m_batch)\n",
    "        \n",
    "        v_dw0 = beta * v_dw0 + (1.0 - beta) * grads[\"dw0\"]\n",
    "        v_db0 = beta * v_db0 + (1.0 - beta) * grads[\"db0\"]\n",
    "        v_dw1 = beta * v_dw1 + (1.0 - beta) * grads[\"dw1\"]\n",
    "        v_db1 = beta * v_db1 + (1.0 - beta) * grads[\"db1\"]\n",
    "        \n",
    "        params[\"W0\"] -= learning_rate * v_dw0\n",
    "        params[\"b0\"] -= learning_rate * v_db0\n",
    "        params[\"W1\"] -= learning_rate * v_dw1\n",
    "        params[\"b1\"] -= learning_rate * v_db1\n",
    "        \n",
    "    cache = feed_forward(x_train, params)\n",
    "    train_cost = compute_multiclass_loss(y_train, cache[\"A1\"])\n",
    "    cache = feed_forward(x_test, params)\n",
    "    test_cost = compute_multiclass_loss(y_test, cache[\"A1\"])\n",
    "    print(f\"Epoch {i+1:2d} : training cost = {train_cost:.10f},  test cost : {test_cost:.10f}\")\n",
    "        \n",
    "print(\"Done!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       991\n",
      "           1       0.99      0.99      0.99      1138\n",
      "           2       0.98      0.98      0.98      1030\n",
      "           3       0.98      0.97      0.98      1024\n",
      "           4       0.97      0.97      0.97       979\n",
      "           5       0.97      0.99      0.98       875\n",
      "           6       0.98      0.98      0.98       963\n",
      "           7       0.98      0.97      0.97      1040\n",
      "           8       0.97      0.98      0.97       964\n",
      "           9       0.96      0.97      0.97       996\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cache = feed_forward(x_test, params)\n",
    "predictions = np.argmax(cache[\"A1\"], axis=0)\n",
    "labels = np.argmax(y_test, axis=0)\n",
    "\n",
    "print(classification_report(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 968    1    4    0    1    4    5    1    5    2]\n",
      " [   0 1124    3    0    0    1    3    5    0    2]\n",
      " [   2    2 1007    5    4    0    0    8    2    0]\n",
      " [   1    1    4  993    1    5    1    3    5   10]\n",
      " [   1    0    2    1  952    3    3    1    2   14]\n",
      " [   1    1    0    2    0  862    3    0    3    3]\n",
      " [   2    2    1    0    4    8  940    0    5    1]\n",
      " [   2    2    6    5    3    2    0 1006    7    7]\n",
      " [   2    2    5    3    3    5    3    0  941    0]\n",
      " [   1    0    0    1   14    2    0    4    4  970]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(predictions, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
