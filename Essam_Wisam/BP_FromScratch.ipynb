{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementing Backpropagation From Scratch on Python 3+\n",
    "- Let's see if theory and practice are the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sympy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative defined function\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide some structure of the network\n",
    "class Network:\n",
    "    def __init__(self, structure):   \n",
    "        # A list that contains the number of neurons in each layer of the network\n",
    "        self.structure = structure\n",
    "        # Number of layers in the network\n",
    "        self.num_layers = len(structure)\n",
    "        # A list of all the bias vectors in the network, _n indicates it has all the bias vectors\n",
    "        self.B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "        # A list of all the weight vectors in the network\n",
    "        self.W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "        \n",
    "    # Call forth all the equations for forward and backward process\n",
    "    def backprop(self, x, y):\n",
    "        # Initialize bias vector & weights matrix of each layer in the network\n",
    "        e_Je_B_ns = [np.zeros(b.shape) for b in self.B_n]\n",
    "        e_Je_W_ns = [np.zeros(W.shape) for W in self.W_n]\n",
    "        \n",
    "        # Forward pass\n",
    "        # Create two lists that contain all the neuron values before & after activation        \n",
    "        Z_n, A_n = [], []\n",
    "        \n",
    "        # Forward pass layer by layer from L=0 thru L=H\n",
    "        for b, W in zip(self.B_n, self.W_n):\n",
    "            a = x\n",
    "            z = np.dot(W.T, a) + b\n",
    "            a = sigmoid(z)\n",
    "            \n",
    "            Z_n.append(z)\n",
    "            A_n.append(a)             \n",
    "            x = a\n",
    "            \n",
    "        # H : output layer\n",
    "        H = self.num_layers - 2\n",
    "        \n",
    "        # backpropagation\n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * np.dot(self.W_n[L+1], delta)\n",
    "            else:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y)\n",
    "                \n",
    "            e_Je_B_ns[L] = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)    \n",
    "            else:\n",
    "                e_Je_W_ns[L] = np.dot(x, delta.T) \n",
    "        \n",
    "        return e_Je_B_ns, e_Je_W_ns\n",
    "    \n",
    "    # Gradient Descent\n",
    "    def gradient_descent(self, mini_batch, learning_rate):\n",
    "        # Initialize bias vector & weights matrix of each layer in the network\n",
    "        e_Je_B_n = [np.zeros(b.shape) for b in self.B_n]\n",
    "        e_Je_W_n = [np.zeros(W.shape) for W in self.W_n]\n",
    "        \n",
    "        for x, y in mini_batch:\n",
    "            e_Je_B_ns, e_Je_W_ns = self.backprop(x, y)\n",
    "            e_Je_B_n = [e_Je_b + e_Je_b_s for e_Je_b, e_Je_b_s in zip(e_Je_B_n, e_Je_B_ns)] \n",
    "            e_Je_W_n = [e_Je_W + e_Je_W_s for e_Je_W, e_Je_W_s in zip(e_Je_W_n, e_Je_W_ns)]\n",
    "            \n",
    "        d = len(mini_batch)\n",
    "        self.W_n = [W - learning_rate/d * e_Je_W for W, e_Je_W in zip(self.W_n, e_Je_W_n)]\n",
    "        self.B_n = [b - learning_rate/d * e_Je_b for b, e_Je_b in zip(self.B_n, e_Je_B_n)]\n",
    "        \n",
    "    def train(self, epochs, training_data, learning_rate):\n",
    "        for j in range(epochs):\n",
    "            for mini_batch in training_data:\n",
    "                self.gradient_descent(mini_batch, learning_rate)               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "[[-0.10215984 -1.14129263]\n",
      " [ 2.65440726  1.44060519]\n",
      " [ 0.09890227 -3.12153215]]\n",
      "\n",
      "[[-1.07652165 -0.32568196]\n",
      " [-1.03549788 -0.42632038]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert data\n",
    "np.random.seed(2023)\n",
    "my_net = Network([3, 2, 2])\n",
    "\n",
    "print(\"Initial Weights:\")\n",
    "\n",
    "for weights in my_net.W_n:\n",
    "    print(weights)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0.3219883 ],\n",
      "       [0.89042245],\n",
      "       [0.58805226]]), array([[0.02208966],\n",
      "       [0.72727471]]))\n",
      "\n",
      "(array([[0.12659609],\n",
      "       [0.14134122],\n",
      "       [0.46789559]]), array([[0.52438734],\n",
      "       [0.54493524]]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2023)\n",
    "random_vectors = lambda dim, cnt : [np.random.rand(dim, 1) for i in range(cnt)]\n",
    "a = list(zip(random_vectors(3, 2), random_vectors(2, 2)))\n",
    "for i in a:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.00011648],\n",
      "       [-0.00101994]]), array([[-0.02561893],\n",
      "       [ 0.07600753]])]\n",
      "\n",
      "[array([[ 1.09709217e-05, -9.60657165e-05],\n",
      "       [ 5.32801640e-05, -4.66542124e-04]]), array([[-0.02451507,  0.07273257],\n",
      "       [-0.00572823,  0.01699482]])]\n",
      "\n",
      "\n",
      "[array([[ 0.00029624],\n",
      "       [-0.00095966]]), array([[-0.02561522],\n",
      "       [ 0.07976536]])]\n",
      "\n",
      "[array([[ 3.62536479e-05, -1.17443850e-04],\n",
      "       [ 1.42658755e-04, -4.62143658e-04]]), array([[-0.01931451,  0.06014504],\n",
      "       [-0.00387078,  0.01205354]])]\n",
      "\n",
      "\n",
      "[array([[-5.61654371e-07],\n",
      "       [-1.54543066e-03]]), array([[-0.02043116],\n",
      "       [ 0.06756297]])]\n",
      "\n",
      "[array([[-5.11246212e-08, -1.40672914e-04],\n",
      "       [-2.54421491e-07, -7.00058244e-04]]), array([[-0.01913458,  0.06327535],\n",
      "       [-0.00574378,  0.01899386]])]\n",
      "\n",
      "\n",
      "[array([[-0.0006507 ],\n",
      "       [-0.00210082]]), array([[-0.027629  ],\n",
      "       [ 0.10920277]])]\n",
      "\n",
      "[array([[-7.22263257e-05, -2.33186271e-04],\n",
      "       [-3.08219944e-04, -9.95103360e-04]]), array([[-0.02408703,  0.09520326],\n",
      "       [-0.00374094,  0.01478594]])]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in a:\n",
    "    xx, yy = my_net.backprop(x, y)\n",
    "    print(xx)\n",
    "    print()\n",
    "    print(yy)\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_net\u001b[39m.\u001b[39;49mgradient_descent(a, \u001b[39m2.0\u001b[39;49m)\n",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 8\u001b[0m in \u001b[0;36mNetwork.gradient_descent\u001b[1;34m(self, mini_batch, learning_rate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     e_Je_B_ns, e_Je_W_ns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     e_Je_B_n \u001b[39m=\u001b[39m [e_Je_b \u001b[39m+\u001b[39m e_Je_b_s \u001b[39mfor\u001b[39;00m e_Je_b, e_Je_b_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_B_n, e_Je_B_ns)] \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     e_Je_W_n \u001b[39m=\u001b[39m [e_Je_W \u001b[39m+\u001b[39m e_Je_W_s \u001b[39mfor\u001b[39;00m e_Je_W, e_Je_W_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_W_n, e_Je_W_ns)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(mini_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n \u001b[39m=\u001b[39m [W \u001b[39m-\u001b[39m learning_rate\u001b[39m/\u001b[39md \u001b[39m*\u001b[39m e_Je_W \u001b[39mfor\u001b[39;00m W, e_Je_W \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n, e_Je_W_n)]\n",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 8\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     e_Je_B_ns, e_Je_W_ns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     e_Je_B_n \u001b[39m=\u001b[39m [e_Je_b \u001b[39m+\u001b[39m e_Je_b_s \u001b[39mfor\u001b[39;00m e_Je_b, e_Je_b_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_B_n, e_Je_B_ns)] \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     e_Je_W_n \u001b[39m=\u001b[39m [e_Je_W \u001b[39m+\u001b[39;49m e_Je_W_s \u001b[39mfor\u001b[39;00m e_Je_W, e_Je_W_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_W_n, e_Je_W_ns)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(mini_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#X15sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n \u001b[39m=\u001b[39m [W \u001b[39m-\u001b[39m learning_rate\u001b[39m/\u001b[39md \u001b[39m*\u001b[39m e_Je_W \u001b[39mfor\u001b[39;00m W, e_Je_W \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n, e_Je_W_n)]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (2,2) "
     ]
    }
   ],
   "source": [
    "my_net.gradient_descent(a, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (2,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m random_vectors \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m dim, cnt : [np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrand(dim, \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(cnt)]\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m random_batch \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(random_vectors(\u001b[39m3\u001b[39m, \u001b[39m64\u001b[39m), random_vectors(\u001b[39m2\u001b[39m, \u001b[39m64\u001b[39m)))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m my_net\u001b[39m.\u001b[39;49mgradient_descent(random_batch, \u001b[39m3.0\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mOptimized Weights:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(my_net\u001b[39m.\u001b[39mW_n[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 9\u001b[0m in \u001b[0;36mNetwork.gradient_descent\u001b[1;34m(self, mini_batch, learning_rate)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     e_Je_B_ns, e_Je_W_ns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     e_Je_B_n \u001b[39m=\u001b[39m [e_Je_b \u001b[39m+\u001b[39m e_Je_b_s \u001b[39mfor\u001b[39;00m e_Je_b, e_Je_b_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_B_n, e_Je_B_ns)] \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     e_Je_W_n \u001b[39m=\u001b[39m [e_Je_W \u001b[39m+\u001b[39m e_Je_W_s \u001b[39mfor\u001b[39;00m e_Je_W, e_Je_W_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_W_n, e_Je_W_ns)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(mini_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n \u001b[39m=\u001b[39m [W \u001b[39m-\u001b[39m learning_rate\u001b[39m/\u001b[39md \u001b[39m*\u001b[39m e_Je_W \u001b[39mfor\u001b[39;00m W, e_Je_W \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n, e_Je_W_n)]\n",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_FromScratch.ipynb Cell 9\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     e_Je_B_ns, e_Je_W_ns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackprop(x, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     e_Je_B_n \u001b[39m=\u001b[39m [e_Je_b \u001b[39m+\u001b[39m e_Je_b_s \u001b[39mfor\u001b[39;00m e_Je_b, e_Je_b_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_B_n, e_Je_B_ns)] \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     e_Je_W_n \u001b[39m=\u001b[39m [e_Je_W \u001b[39m+\u001b[39;49m e_Je_W_s \u001b[39mfor\u001b[39;00m e_Je_W, e_Je_W_s \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(e_Je_W_n, e_Je_W_ns)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m d \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(mini_batch)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_FromScratch.ipynb#W5sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n \u001b[39m=\u001b[39m [W \u001b[39m-\u001b[39m learning_rate\u001b[39m/\u001b[39md \u001b[39m*\u001b[39m e_Je_W \u001b[39mfor\u001b[39;00m W, e_Je_W \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mW_n, e_Je_W_n)]\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (2,2) "
     ]
    }
   ],
   "source": [
    "# The following generates a list of cnt vectors of length dim.\n",
    "np.random.seed(2023)\n",
    "random_vectors = lambda dim, cnt : [np.random.rand(dim, 1) for i in range(cnt)]\n",
    "random_batch = list(zip(random_vectors(3, 64), random_vectors(2, 64)))\n",
    "\n",
    "my_net.gradient_descent(random_batch, 3.0)\n",
    "print(\"Optimized Weights:\")\n",
    "print(my_net.W_n[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.37214444]\n",
      " [0.57783618]\n",
      " [0.01429624]]\n",
      "\n",
      "[[0.92490225]\n",
      " [0.49228575]\n",
      " [0.66290319]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for rand_vector in random_vectors(3, 64)[-2:]:\n",
    "    print(rand_vector)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [3 4]]\n",
      "\n",
      "[[0.73105858 0.5       ]\n",
      " [0.95257413 0.98201379]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,0], [3,4]])\n",
    "y = 1.0 / (1.0 + np.exp(-x))\n",
    "print(x)\n",
    "print()\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4*x**3 + 3*x\n",
      "12*x**2 + 3\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "x = symbols(\"x\")\n",
    "fx = 4 * (x**3) + 3 * x\n",
    "print(fx)\n",
    "\n",
    "first_deriv = Derivative(fx, x).doit()\n",
    "print(first_deriv)\n",
    "\n",
    "value = first_deriv.subs({x:3})\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  9, 10])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([2,3,5])\n",
    "y = np.array([5,3,2])\n",
    "\n",
    "x * y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
