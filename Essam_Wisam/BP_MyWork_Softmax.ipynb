{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]\n",
      " [ 0.2829785 ]\n",
      " [-1.50629471]\n",
      " [-0.57860025]]\n",
      "\n",
      "[[ 1.65143654]\n",
      " [-2.42667924]\n",
      " [-0.42891263]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "\"\"\"\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545  0.2829785  -1.50629471 -0.57860025]\n",
      " [ 1.65143654 -2.42667924 -0.42891263  1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897  1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609  1.0040539   0.3861864 ]]\n",
      "\n",
      "[[ 0.73736858  1.49073203 -0.93583387]\n",
      " [ 1.17582904 -1.25388067 -0.6377515 ]\n",
      " [ 0.9071052  -1.4286807  -0.14006872]\n",
      " [-0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "\"\"\"\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()\n",
    "\"\"\"BrokenPipeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]]\n",
      "\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "ind = [73, 41, 106]\n",
    "\n",
    "data = data[ind]\n",
    "target = target[ind]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label의 종류 : [0 1 2],  label종류의 갯수 : 3\n"
     ]
    }
   ],
   "source": [
    "kind_labels, count_labels = np.unique(target, return_counts=True)\n",
    "num_labels = len(kind_labels)\n",
    "print(f\"label의 종류 : {kind_labels},  label종류의 갯수 : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(target), num_labels))\n",
    "\n",
    "for i in range(len(one_hot_labels)):\n",
    "    for j in range(len(one_hot_labels[i])):\n",
    "        one_hot_labels[i, target[i]] = 1\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# data is a np.ndarray with shape (150,4)\n",
    "# one_hot_labels is a np.ndarray with shape (150,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide activation and activation_derivative funcitions\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_total = np.sum([np.exp(i) for i in x])\n",
    "    exp_x = np.array([np.exp(i)/exp_total for i in x])\n",
    "    return exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss for categorical cross-entropy loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.sum(actual.reshape(-1) * expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([[0.10, 0.85, 0.05]])\n",
    "expected = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "calculate_loss(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.int64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_MyWork_Softmax.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork_Softmax.ipynb#X16sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m max_expected_indexes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(target)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork_Softmax.ipynb#X16sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m accuracy_sum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork_Softmax.ipynb#X16sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(max_actual_indexes)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork_Softmax.ipynb#X16sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     \u001b[39mif\u001b[39;00m max_actual_indexes \u001b[39m==\u001b[39m max_expected_indexes:\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork_Softmax.ipynb#X16sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m         accuracy_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.int64' has no len()"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.10\n",
    "epochs = 50\n",
    "\n",
    "all_epoch_errors = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Create a list that contains errors of all data points for each epoch\n",
    "    per_epoch_errors = []   \n",
    "    actuals = []    \n",
    "    \n",
    "    W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "    B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "    \n",
    "    for x, y in zip(data, one_hot_labels):       # x : (4,), y : (3,)\n",
    "        # Forward Propagate\n",
    "        # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "        Z_n, A_n = [], []\n",
    "        \n",
    "        for i, (b, w) in enumerate(zip(B_n, W_n)):\n",
    "            if i == 0:\n",
    "                z = np.dot(w.T, x).reshape(-1,1) + np.array(b)                \n",
    "                a = sigmoid(z)\n",
    "            elif (i > 0) and (i < H):\n",
    "                z = np.dot(w.T, a)\n",
    "                a = sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(w.T, a)\n",
    "                a = softmax(z)\n",
    "\n",
    "            Z_n.append(z)\n",
    "            A_n.append(a)\n",
    "            \n",
    "        # Backpropagate\n",
    "        e_Je_W_ns = [np.zeros(w.shape) for w in W_n]\n",
    "        e_Je_B_ns = [np.zeros(b.shape) for b in B_n]\n",
    "        \n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "            else:\n",
    "                delta = A_n[L] - y.reshape(-1,1)\n",
    "            \n",
    "            e_Je_B_ns = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "            else:\n",
    "                e_Je_W_ns[L] = np.dot(x.reshape(-1,1), delta.T)\n",
    "                \n",
    "        for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "            W_n[i] -= learning_rate/len(data) * ejew\n",
    "        B_n[i] -= learning_rate/len(data) * ejeb\n",
    "        \"\"\"\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()\n",
    "        \"\"\"    \n",
    "\n",
    "        datapoint_error = calculate_loss(A_n[-1], y)\n",
    "        per_epoch_errors.append(datapoint_error)\n",
    "        actuals.append(A_n[-1].reshape(-1))\n",
    "        max_actual_indexes = np.argmax(A_n[-1].reshape(-1))\n",
    "        max_expected_indexes = np.argmax(target)\n",
    "        accuracy_sum = 0\n",
    "        for i in range(len(max_actual_indexes)):\n",
    "            if max_actual_indexes == max_expected_indexes:\n",
    "                accuracy_sum += 1\n",
    "    print(f\"accuracy : {accuracy_sum}\")\n",
    "    total_errors = np.sum(per_epoch_errors)\n",
    "    all_epoch_errors.append(total_errors)\n",
    "    print(f\"{epoch:3d}th epoch total error : {total_errors:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "max_indexes = []\n",
    "for x in actuals:\n",
    "    max_idx = np.argmax(x)\n",
    "    max_indexes.append(max_idx)\n",
    "\n",
    "print(max_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15156028 0.42865508 0.41978464]\n",
      "[0.15198768 0.42794918 0.42006314]\n",
      "[0.15223947 0.42716547 0.42059506]\n",
      "[0.15277205 0.42631196 0.42091599]\n",
      "[0.15224123 0.4279247  0.41983406]\n",
      "[0.15197509 0.42888624 0.41913867]\n",
      "[0.15287106 0.42613624 0.4209927 ]\n",
      "[0.15280481 0.42756078 0.41963441]\n",
      "[0.1536396  0.42516341 0.42119699]\n",
      "[0.15337624 0.42694192 0.41968184]\n",
      "[0.15273565 0.42858031 0.41868404]\n",
      "[0.1537538  0.42623927 0.42000693]\n",
      "[0.15382445 0.42647838 0.41969718]\n",
      "[0.15421836 0.42463464 0.421147  ]\n",
      "[0.15261691 0.42960233 0.41778076]\n",
      "[0.15289435 0.42906495 0.4180407 ]\n",
      "[0.15318396 0.42848766 0.41832839]\n",
      "[0.15388051 0.42729441 0.41882508]\n",
      "[0.15364026 0.42855698 0.41780275]\n",
      "[0.15424593 0.42687232 0.41888175]\n",
      "[0.15440649 0.42746604 0.41812747]\n",
      "[0.15441561 0.42679786 0.41878653]\n",
      "[0.15482063 0.42532796 0.41985141]\n",
      "[0.15483188 0.42652107 0.41864705]\n",
      "[0.15603111 0.42457176 0.41939712]\n",
      "[0.15555705 0.42592941 0.41851354]\n",
      "[0.15539306 0.4259322  0.41867474]\n",
      "[0.155441   0.42650846 0.41805054]\n",
      "[0.15548427 0.42658201 0.41793372]\n",
      "[0.15651644 0.42431518 0.41916838]\n",
      "[0.15654116 0.42469995 0.4187589 ]\n",
      "[0.15557588 0.42702495 0.41739917]\n",
      "[0.15624339 0.4258351  0.41792151]\n",
      "[0.15582481 0.42693001 0.41724518]\n",
      "[0.15686678 0.42491662 0.4182166 ]\n",
      "[0.1565314  0.42563265 0.41783594]\n",
      "[0.15620441 0.42687305 0.41692254]\n",
      "[0.15727072 0.42456809 0.41816119]\n",
      "[0.15783194 0.42271934 0.41944872]\n",
      "[0.1573182  0.42514553 0.41753627]\n",
      "[0.15722189 0.42508515 0.41769296]\n",
      "[0.15808472 0.42334381 0.41857147]\n",
      "[0.15838098 0.42225952 0.4193595 ]\n",
      "[0.15756138 0.424455   0.41798361]\n",
      "[0.15819084 0.42409183 0.41771734]\n",
      "[0.15834818 0.4238765  0.41777532]\n",
      "[0.15842241 0.42428404 0.41729355]\n",
      "[0.15900725 0.42265686 0.4183359 ]\n",
      "[0.15837143 0.42496921 0.41665936]\n",
      "[0.15879597 0.4240992  0.41710482]\n",
      "[0.15846958 0.42605771 0.41547271]\n",
      "[0.15879428 0.42481772 0.416388  ]\n",
      "[0.15860267 0.42607968 0.41531765]\n",
      "[0.15976018 0.42292297 0.41731685]\n",
      "[0.15874362 0.42590621 0.41535018]\n",
      "[0.15997799 0.42291396 0.41710805]\n",
      "[0.1587582  0.42509964 0.41614216]\n",
      "[0.16004276 0.42212731 0.41782993]\n",
      "[0.15875547 0.42702675 0.41421778]\n",
      "[0.15934751 0.42187625 0.41877624]\n",
      "[0.16022732 0.42340293 0.41636974]\n",
      "[0.15870171 0.42565263 0.41564566]\n",
      "[0.15928847 0.42703881 0.41367272]\n",
      "[0.15921913 0.42624243 0.41453845]\n",
      "[0.15863694 0.42633153 0.41503154]\n",
      "[0.15803329 0.42928035 0.41268636]\n",
      "[0.15916722 0.42424086 0.41659191]\n",
      "[0.15950714 0.42715488 0.41333798]\n",
      "[0.15862252 0.42859533 0.41278215]\n",
      "[0.15931521 0.42729893 0.41338586]\n",
      "[0.15832358 0.42544471 0.41623171]\n",
      "[0.15830697 0.42948551 0.41220752]\n",
      "[0.15878538 0.42904904 0.41216558]\n",
      "[0.15927368 0.42864022 0.4120861 ]\n",
      "[0.1581449  0.43067318 0.41118193]\n",
      "[0.15782041 0.43138611 0.41079348]\n",
      "[0.15796875 0.4316356  0.41039564]\n",
      "[0.15782611 0.43131637 0.41085752]\n",
      "[0.15839595 0.42964205 0.411962  ]\n",
      "[0.15847834 0.4307425  0.41077916]\n",
      "[0.15897025 0.42967858 0.41135117]\n",
      "[0.15899133 0.43010475 0.41090392]\n",
      "[0.15837875 0.4311047  0.41051655]\n",
      "[0.15882093 0.4295865  0.41159257]\n",
      "[0.15871732 0.42680872 0.41447396]\n",
      "[0.15781382 0.43062264 0.41156354]\n",
      "[0.15748291 0.43383294 0.40868415]\n",
      "[0.15801404 0.4334284  0.40855756]\n",
      "[0.1584013  0.43076736 0.41083134]\n",
      "[0.15849783 0.43116805 0.41033412]\n",
      "[0.15921151 0.43046706 0.41032144]\n",
      "[0.1581202  0.43294284 0.40893696]\n",
      "[0.15817832 0.43330864 0.40851304]\n",
      "[0.15875076 0.43125849 0.40999075]\n",
      "[0.15841231 0.43224963 0.40933806]\n",
      "[0.1583849  0.43283471 0.40878039]\n",
      "[0.15816777 0.43308253 0.4087497 ]\n",
      "[0.15761476 0.43538279 0.40700245]\n",
      "[0.15780302 0.43340258 0.4087944 ]\n",
      "[0.15796367 0.43409098 0.40794535]\n",
      "[0.15641877 0.42896909 0.41461214]\n",
      "[0.15766292 0.43119286 0.41114422]\n",
      "[0.15686457 0.43620664 0.40692879]\n",
      "[0.15796294 0.43304256 0.4089945 ]\n",
      "[0.15706    0.43268657 0.41025343]\n",
      "[0.15693986 0.43612602 0.40693412]\n",
      "[0.15785472 0.42383606 0.41830921]\n",
      "[0.15740653 0.43513016 0.40746331]\n",
      "[0.15769009 0.43384799 0.40846192]\n",
      "[0.15603552 0.43380536 0.41015912]\n",
      "[0.15658515 0.4331517  0.41026315]\n",
      "[0.15718162 0.43264788 0.4101705 ]\n",
      "[0.15655969 0.4335233  0.409917  ]\n",
      "[0.15716345 0.42803331 0.41480325]\n",
      "[0.15583964 0.42527107 0.41888929]\n",
      "[0.15608663 0.4301323  0.41378107]\n",
      "[0.15731678 0.43151005 0.41117317]\n",
      "[0.15643898 0.43342498 0.41013604]\n",
      "[0.15663337 0.43341719 0.40994944]\n",
      "[0.15804639 0.43027199 0.41168163]\n",
      "[0.15610848 0.4314686  0.41242292]\n",
      "[0.15672588 0.42486829 0.41840583]\n",
      "[0.15672544 0.43264912 0.41062544]\n",
      "[0.15678248 0.43051741 0.4127001 ]\n",
      "[0.15650798 0.42976499 0.41372702]\n",
      "[0.15680032 0.43140104 0.41179864]\n",
      "[0.15668299 0.42948178 0.41383524]\n",
      "[0.15679504 0.42823905 0.41496591]\n",
      "[0.15670957 0.42794513 0.41534529]\n",
      "[0.1568045  0.43082323 0.41237228]\n",
      "[0.15645364 0.43097085 0.41257551]\n",
      "[0.1559251  0.43145656 0.41261835]\n",
      "[0.15639927 0.42683919 0.41676154]\n",
      "[0.15733307 0.42809628 0.41457065]\n",
      "[0.15856143 0.42605921 0.41537936]\n",
      "[0.15552878 0.43081618 0.41365504]\n",
      "[0.1555207  0.42294572 0.42153358]\n",
      "[0.1569525  0.42646505 0.41658245]\n",
      "[0.15652314 0.42550393 0.41797293]\n",
      "[0.15579624 0.4283454  0.41585835]\n",
      "[0.15553863 0.42614321 0.41831816]\n",
      "[0.1552122  0.42818647 0.41660134]\n",
      "[0.15677295 0.4225485  0.42067855]\n",
      "[0.1558573  0.42562855 0.41851415]\n",
      "[0.15523547 0.42436725 0.42039728]\n",
      "[0.15532822 0.42628924 0.41838253]\n",
      "[0.15626093 0.42556161 0.41817746]\n",
      "[0.15595144 0.42535167 0.41869689]\n",
      "[0.15535073 0.42057695 0.42407232]\n",
      "[0.15668461 0.42171115 0.42160424]\n"
     ]
    }
   ],
   "source": [
    "for x in actuals:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83154471]\n",
      " [ -0.96947549]\n",
      " [  6.09361791]\n",
      " [-15.10743014]\n",
      " [ -3.23182179]]\n",
      "\n",
      "[[ 1.95534369]\n",
      " [-2.13481311]\n",
      " [ 1.30590787]\n",
      " [ 2.54368828]\n",
      " [-0.56127734]]\n",
      "\n",
      "[[ 1.87108937]\n",
      " [ 0.37920913]\n",
      " [-3.28865198]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.61945643e-01]\n",
      " [2.74985060e-01]\n",
      " [9.97747856e-01]\n",
      " [2.74742811e-07]\n",
      " [3.79856179e-02]]\n",
      "\n",
      "[[0.87602815]\n",
      " [0.10575893]\n",
      " [0.78682759]\n",
      " [0.92714834]\n",
      " [0.36325196]]\n",
      "\n",
      "[[0.81255067]\n",
      " [0.1827827 ]\n",
      " [0.00466663]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in A_n:\n",
    "    print(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = np.array([[-0.67888615],[-0.09470897],[ 1.49138963]])\n",
    "\n",
    "qw = np.array([[-0.01183049, 2.39236527, 0.41291216],\n",
    "               [ 0.97873601, 2.23814334,-1.29408532],\n",
    "               [-1.03878821, 1.74371223, -0.79806274],\n",
    "               [ 0.02968323, 1.06931597, 0.89070639],\n",
    "               [ 1.75488618, 1.49564414, 1.06939267]])\n",
    "\n",
    "qa = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01183049,  2.39236527,  0.41291216],\n",
       "       [ 0.97873601,  2.23814334, -1.29408532],\n",
       "       [-1.03878821,  1.74371223, -0.79806274],\n",
       "       [ 0.02968323,  1.06931597,  0.89070639],\n",
       "       [ 1.75488618,  1.49564414,  1.06939267]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81255067],\n",
       "       [0.1827827 ],\n",
       "       [0.00466663]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = np.array([[ 1.87108937],[ 0.37920913], [-3.28865198]])\n",
    "softmax(qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.993801077857318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937)+np.exp(0.37920913)+np.exp(-3.28865198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125506680475049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937) / 7.993801077857318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.08463061]\n",
      " [-10.99406957]\n",
      " [  1.47841105]]\n",
      "[[ 0.20035037]\n",
      " [-0.61525204]\n",
      " [-1.41450794]]\n",
      "\n",
      "[[4.37456981e-02]\n",
      " [1.68007611e-05]\n",
      " [8.14332459e-01]]\n",
      "[[0.60927625]\n",
      " [0.26952722]\n",
      " [0.12119653]]\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "print()\n",
    "    \n",
    "for a in A_n:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24282174500874198 0.23243223430314788 0.5247460206881103\n"
     ]
    }
   ],
   "source": [
    "w1 = np.exp(4.37456981e-02)\n",
    "w2 = np.exp(1.68007611e-05)\n",
    "w3 = np.exp(8.14332459e-01)\n",
    "w = w1 + w2 + w3\n",
    "print(w1/w, w2/w, w3/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.82984282],\n",
       "       [-10.93711486],\n",
       "       [  3.874953  ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = np.array([[ 1.49073203, -1.25388067, -1.4286807,  -0.25561937],\n",
    "               [-0.93583387, -0.6377515,  -0.14006872, -2.79858911],\n",
    "               [ 1.17582904,  0.9071052,  -0.8617549,  -1.7715331 ]])\n",
    "q2 = np.array([[6.1], [2.8], [4.7], [1.2]])\n",
    "q3 = np.array([[-0.39089979],[ 0.57380586],[ 0.33858905]])\n",
    "\n",
    "np.dot(q1, q2) + q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7428981 ],\n",
       "       [ 4.85531027],\n",
       "       [-8.71370112]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[ 0.17872861, -0.6912346, -0.7062834, -1.16791303],[1.48206927, 0.64496092, -1.64362799, -0.18604671], [-1.62516337, 0.58674198, 0.05285727, -0.81424207]]), \n",
    "       np.array([[6.1], [2.8], [4.7], [1.2]])) + np.array([[0.82334188],[1.95710475],[0.28557921]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 3.2, 5.1, 2. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.83029444  1.74819998  0.15065959]\n",
      " [-0.64190703 -0.23828275  0.73563826]\n",
      " [ 1.14152941 -0.40749578  0.96474426]\n",
      " [ 0.34891558  0.46111748 -1.33873322]]\n",
      "\n",
      "[[ 1.31356114 -0.37492699 -2.61059038]\n",
      " [-0.62066217  0.02652033 -3.25676797]\n",
      " [ 2.15103401 -0.22474109 -0.19109542]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in W_n:\n",
    "    print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30884409]\n",
      " [-0.29061399]\n",
      " [ 0.70296863]]\n",
      "\n",
      "[[-0.65857087]\n",
      " [-0.41272655]\n",
      " [-0.51388702]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in B_n:\n",
    "    print(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide softmax and softmax_derivative function\n",
    "def softmax(x):\n",
    "    exp_sum = np.sum([np.exp(i) for i in x])\n",
    "    softmax_x = np.array([np.exp(i)/exp_sum for i in x])\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.dot(actual.T, expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.5204970299663\n",
      "[0.04661262257797389, 0.9362395518765058, 0.01714782554552039]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,5,1]).reshape(-1,1)\n",
    "y = np.array([0,1,0]).reshape(-1,1)\n",
    "\n",
    "exp_sum = np.sum([np.exp(i)[0] for i in a])\n",
    "print(exp_sum)\n",
    "softmax_x = [np.exp(i[0])/exp_sum for i in a]\n",
    "print(softmax_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - np.dot(np.array([0,1,0]).T, np.array([0.04661262257797389, 0.9362395518765058, 0.01714782554552039]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.38905609893065, 148.4131591025766, 2.718281828459045]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.exp(i)[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01714782554552039"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.718281828459045 /158.5204970299663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04661262],\n",
       "       [0.93623955],\n",
       "       [0.01714783]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(softmax(a), y)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
