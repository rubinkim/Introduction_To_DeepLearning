{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]\n",
      " [ 0.2829785 ]\n",
      " [-1.50629471]\n",
      " [-0.57860025]]\n",
      "\n",
      "[[ 1.65143654]\n",
      " [-2.42667924]\n",
      " [-0.42891263]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545  0.2829785  -1.50629471 -0.57860025]\n",
      " [ 1.65143654 -2.42667924 -0.42891263  1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897  1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609  1.0040539   0.3861864 ]]\n",
      "\n",
      "[[ 0.73736858  1.49073203 -0.93583387]\n",
      " [ 1.17582904 -1.25388067 -0.6377515 ]\n",
      " [ 0.9071052  -1.4286807  -0.14006872]\n",
      " [-0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]]\n",
      "\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "ind = [73, 41, 106]\n",
    "\n",
    "data = data[ind]\n",
    "target = target[ind]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label의 종류 : [0 1 2],  label종류의 갯수 : 3\n"
     ]
    }
   ],
   "source": [
    "kind_labels, count_labels = np.unique(target, return_counts=True)\n",
    "num_labels = len(kind_labels)\n",
    "print(f\"label의 종류 : {kind_labels},  label종류의 갯수 : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(target), num_labels))\n",
    "\n",
    "for i in range(len(one_hot_labels)):\n",
    "    for j in range(len(one_hot_labels[i])):\n",
    "        one_hot_labels[i, target[i]] = 1\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# data is a np.ndarray with shape (150,4)\n",
    "# one_hot_labels is a np.ndarray with shape (150,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide activation and activation_derivative funcitions\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_total = np.sum([np.exp(i) for i in x])\n",
    "    exp_x = np.array([np.exp(i)/exp_total for i in x])\n",
    "    return exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss for categorical cross-entropy loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.sum(actual.reshape(-1) * expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([[0.10, 0.85, 0.05]])\n",
    "expected = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "calculate_loss(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0th epoch total error : -50.800\n",
      "  1th epoch total error : -44.779\n",
      "  2th epoch total error : -49.793\n",
      "  3th epoch total error : -53.390\n",
      "  4th epoch total error : -50.820\n",
      "  5th epoch total error : -48.970\n",
      "  6th epoch total error : -49.957\n",
      "  7th epoch total error : -49.504\n",
      "  8th epoch total error : -49.143\n",
      "  9th epoch total error : -50.859\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.10\n",
    "epochs = 10\n",
    "\n",
    "all_epoch_errors = []\n",
    "actuals = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Create a list that contains errors of all data points for each epoch\n",
    "    per_epoch_errors = []    \n",
    "    \n",
    "    W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "    B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "    \n",
    "    for x, y in zip(data, one_hot_labels):       # x : (4,), y : (3,)\n",
    "        # Forward Propagate\n",
    "        # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "        Z_n, A_n = [], []\n",
    "        \n",
    "        for i, (b, w) in enumerate(zip(B_n, W_n)):\n",
    "            if i == 0:\n",
    "                z = np.dot(w.T, x).reshape(-1,1) + np.array(b)                \n",
    "                a = sigmoid(z)\n",
    "            elif (i > 0) and (i < H):\n",
    "                z = np.dot(w.T, a)\n",
    "                a = sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(w.T, a)\n",
    "                a = softmax(z)\n",
    "\n",
    "            Z_n.append(z)\n",
    "            A_n.append(a)\n",
    "            \n",
    "        # Backpropagate\n",
    "        e_Je_W_ns = [np.zeros(w.shape) for w in W_n]\n",
    "        e_Je_B_ns = [np.zeros(b.shape) for b in B_n]\n",
    "        \n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "            else:\n",
    "                delta = A_n[L] - y.reshape(-1,1)\n",
    "            \n",
    "            e_Je_B_ns = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "            else:\n",
    "                e_Je_W_ns[L] = np.dot(x.reshape(-1,1), delta.T)\n",
    "                \n",
    "        for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "            W_n[i] -= learning_rate/len(data) * ejew\n",
    "        B_n[i] -= learning_rate/len(data) * ejeb\n",
    "        \"\"\"\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()\n",
    "        \"\"\"    \n",
    "\n",
    "        datapoint_error = calculate_loss(A_n[-1], y)\n",
    "        per_epoch_errors.append(datapoint_error)\n",
    "    actuals.append(A_n[-1].reshape(-1))\n",
    "    total_errors = np.sum(per_epoch_errors)\n",
    "    all_epoch_errors.append(total_errors)\n",
    "    print(f\"{epoch:3d}th epoch total error : {total_errors:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 0, 1, 0, 0, 1, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "max_indexes = []\n",
    "for x in actuals:\n",
    "    max_idx = np.argmax(x)\n",
    "    max_indexes.append(max_idx)\n",
    "\n",
    "print(max_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21793764 0.19918345 0.5828789 ]\n",
      "[0.22538229 0.20111779 0.57349992]\n",
      "[0.2235659  0.19864331 0.57779079]\n",
      "[0.23675735 0.19494148 0.56830117]\n",
      "[0.22302536 0.19710422 0.57987042]\n",
      "[0.2358538  0.19394421 0.57020199]\n",
      "[0.23604556 0.19413944 0.569815  ]\n",
      "[0.2305708  0.19648368 0.57294551]\n",
      "[0.24022518 0.19548227 0.56429255]\n",
      "[0.23186856 0.19751767 0.57061377]\n",
      "[0.22379409 0.19806324 0.57814267]\n",
      "[0.24253549 0.19254045 0.56492406]\n",
      "[0.23138051 0.1986385  0.56998099]\n",
      "[0.22648499 0.19820402 0.575311  ]\n",
      "[0.20193601 0.20445489 0.5936091 ]\n",
      "[0.22761338 0.19567725 0.57670938]\n",
      "[0.22385807 0.19900232 0.57713961]\n",
      "[0.23390054 0.19720101 0.56889845]\n",
      "[0.23731205 0.19590766 0.56678028]\n",
      "[0.24033023 0.19334722 0.56632255]\n",
      "[0.24300888 0.19573179 0.56125933]\n",
      "[0.24475581 0.19360444 0.56163975]\n",
      "[0.22433133 0.19780411 0.57786456]\n",
      "[0.26252543 0.19355261 0.54392196]\n",
      "[0.26592503 0.18675509 0.54731989]\n",
      "[0.25166625 0.19614375 0.55218999]\n",
      "[0.25641634 0.19274414 0.55083952]\n",
      "[0.24132329 0.19547199 0.56320472]\n",
      "[0.23708059 0.19779732 0.56512209]\n",
      "[0.25805243 0.19095199 0.55099558]\n",
      "[0.25757402 0.19256928 0.5498567 ]\n",
      "[0.24850114 0.19820564 0.55329322]\n",
      "[0.24387358 0.1918041  0.56432232]\n",
      "[0.23542114 0.19486768 0.56971118]\n",
      "[0.25392076 0.19480742 0.55127182]\n",
      "[0.2362635  0.20010069 0.56363581]\n",
      "[0.23141124 0.20088982 0.56769894]\n",
      "[0.24705924 0.19269818 0.56024258]\n",
      "[0.25578709 0.19331107 0.55090185]\n",
      "[0.25257273 0.19383284 0.55359444]\n",
      "[0.2477374  0.19524963 0.55701297]\n",
      "[0.2739405  0.20298954 0.52306997]\n",
      "[0.25782384 0.19152574 0.55065043]\n",
      "[0.27548083 0.19023625 0.53428292]\n",
      "[0.27987628 0.18474915 0.53537457]\n",
      "[0.2631477 0.1953851 0.5414672]\n",
      "[0.26248025 0.18908174 0.54843801]\n",
      "[0.26255274 0.19134455 0.54610271]\n",
      "[0.25476142 0.19265513 0.55258345]\n",
      "[0.25656369 0.19424397 0.54919234]\n",
      "[0.43978747 0.17819324 0.38201929]\n",
      "[0.42114053 0.1733604  0.40549907]\n",
      "[0.44883169 0.17408002 0.37708828]\n",
      "[0.43638686 0.16798977 0.39562337]\n",
      "[0.45853652 0.17333983 0.36812365]\n",
      "[0.39396266 0.16281962 0.44321772]\n",
      "[0.41181662 0.16984491 0.41833848]\n",
      "[0.38216501 0.17468585 0.44314914]\n",
      "[0.43635436 0.17716913 0.38647651]\n",
      "[0.39885571 0.16746648 0.43367781]\n",
      "[0.41452702 0.17314827 0.41232471]\n",
      "[0.41714158 0.17436666 0.40849175]\n",
      "[0.4445462  0.18076064 0.37469316]\n",
      "[0.41370881 0.16849903 0.41779216]\n",
      "[0.40087454 0.18150158 0.41762388]\n",
      "[0.43836093 0.1839409  0.37769817]\n",
      "[0.3909994  0.16460659 0.44439402]\n",
      "[0.39130442 0.17688711 0.43180847]\n",
      "[0.48681992 0.17054481 0.34263527]\n",
      "[0.40932579 0.1783463  0.41232791]\n",
      "[0.41061671 0.16471442 0.42466887]\n",
      "[0.42918165 0.18469756 0.38612079]\n",
      "[0.46092888 0.16787426 0.37119685]\n",
      "[0.40388191 0.17219596 0.42392213]\n",
      "[0.43158539 0.18473242 0.38368218]\n",
      "[0.4421615  0.18603854 0.37179996]\n",
      "[0.46218519 0.18174678 0.35606803]\n",
      "[0.46238989 0.17588065 0.36172946]\n",
      "[0.42372412 0.17556869 0.40070719]\n",
      "[0.40023262 0.19024861 0.40951877]\n",
      "[0.41387542 0.18230789 0.40381669]\n",
      "[0.40556558 0.18479537 0.40963905]\n",
      "[0.41318639 0.18565293 0.40116068]\n",
      "[0.42845093 0.16297449 0.40857459]\n",
      "[0.37984388 0.16687426 0.45328185]\n",
      "[0.39377643 0.17845611 0.42776746]\n",
      "[0.4435064  0.18595866 0.37053493]\n",
      "[0.47320147 0.18341805 0.34338048]\n",
      "[0.38551746 0.18038487 0.43409767]\n",
      "[0.4209969  0.18057164 0.39843146]\n",
      "[0.39271175 0.17277452 0.43451373]\n",
      "[0.40989189 0.18022694 0.40988117]\n",
      "[0.42005697 0.18722956 0.39271347]\n",
      "[0.39339864 0.1885522  0.41804916]\n",
      "[0.40582243 0.18029333 0.41388424]\n",
      "[0.38035175 0.18255529 0.43709296]\n",
      "[0.39600619 0.18295631 0.4210375 ]\n",
      "[0.42099592 0.18945111 0.38955298]\n",
      "[0.39311004 0.19722867 0.40966129]\n",
      "[0.40593736 0.18585334 0.4082093 ]\n",
      "[0.45016585 0.15677455 0.39305961]\n",
      "[0.44238371 0.16343349 0.39418281]\n",
      "[0.48385667 0.16754933 0.348594  ]\n",
      "[0.42986291 0.16318433 0.40695276]\n",
      "[0.46007093 0.16093964 0.37898943]\n",
      "[0.48356939 0.16216384 0.35426677]\n",
      "[0.3978395  0.15919837 0.44296213]\n",
      "[0.4620783  0.16456089 0.37336081]\n",
      "[0.46935247 0.16208657 0.36856096]\n",
      "[0.46708063 0.16624844 0.36667093]\n",
      "[0.44809008 0.17573492 0.376175  ]\n",
      "[0.46077311 0.16676729 0.3724596 ]\n",
      "[0.47102983 0.16924635 0.35972382]\n",
      "[0.4503397  0.16038167 0.38927863]\n",
      "[0.46180252 0.15943082 0.37876665]\n",
      "[0.45387343 0.1668569  0.37926968]\n",
      "[0.42394412 0.16638243 0.40967345]\n",
      "[0.42619801 0.16461772 0.40918427]\n",
      "[0.49308628 0.15518773 0.35172599]\n",
      "[0.44248546 0.16481591 0.39269864]\n",
      "[0.46314006 0.16578082 0.37107912]\n",
      "[0.41669905 0.16056037 0.42274058]\n",
      "[0.47298921 0.159045   0.36796578]\n",
      "[0.44893421 0.1721378  0.378928  ]\n",
      "[0.42285196 0.16413286 0.41301518]\n",
      "[0.423626   0.16726202 0.40911198]\n",
      "[0.43554438 0.17281483 0.3916408 ]\n",
      "[0.40836042 0.169788   0.42185158]\n",
      "[0.44168786 0.15857503 0.39973711]\n",
      "[0.42471526 0.17056198 0.40472276]\n",
      "[0.46225473 0.16389499 0.37385028]\n",
      "[0.41532266 0.17180002 0.41287732]\n",
      "[0.44510069 0.15756405 0.39733526]\n",
      "[0.39543386 0.16814011 0.43642603]\n",
      "[0.36841808 0.15315801 0.47842392]\n",
      "[0.48399794 0.16469906 0.35130299]\n",
      "[0.40518026 0.1564368  0.43838293]\n",
      "[0.38418401 0.16022094 0.45559506]\n",
      "[0.39351797 0.16772936 0.43875267]\n",
      "[0.44474334 0.16901334 0.38624331]\n",
      "[0.44763585 0.16026644 0.39209771]\n",
      "[0.46834484 0.17274377 0.3589114 ]\n",
      "[0.397886   0.15594567 0.44616833]\n",
      "[0.42404384 0.15707518 0.41888098]\n",
      "[0.43347554 0.15845274 0.40807172]\n",
      "[0.45570124 0.16643151 0.37786725]\n",
      "[0.44278834 0.16393529 0.39327637]\n",
      "[0.41754785 0.16511318 0.41733897]\n",
      "[0.38303987 0.15586378 0.46109635]\n",
      "[0.36278217 0.15638443 0.48083341]\n"
     ]
    }
   ],
   "source": [
    "for x in actuals:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83154471]\n",
      " [ -0.96947549]\n",
      " [  6.09361791]\n",
      " [-15.10743014]\n",
      " [ -3.23182179]]\n",
      "\n",
      "[[ 1.95534369]\n",
      " [-2.13481311]\n",
      " [ 1.30590787]\n",
      " [ 2.54368828]\n",
      " [-0.56127734]]\n",
      "\n",
      "[[ 1.87108937]\n",
      " [ 0.37920913]\n",
      " [-3.28865198]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.61945643e-01]\n",
      " [2.74985060e-01]\n",
      " [9.97747856e-01]\n",
      " [2.74742811e-07]\n",
      " [3.79856179e-02]]\n",
      "\n",
      "[[0.87602815]\n",
      " [0.10575893]\n",
      " [0.78682759]\n",
      " [0.92714834]\n",
      " [0.36325196]]\n",
      "\n",
      "[[0.81255067]\n",
      " [0.1827827 ]\n",
      " [0.00466663]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in A_n:\n",
    "    print(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = np.array([[-0.67888615],[-0.09470897],[ 1.49138963]])\n",
    "\n",
    "qw = np.array([[-0.01183049, 2.39236527, 0.41291216],\n",
    "               [ 0.97873601, 2.23814334,-1.29408532],\n",
    "               [-1.03878821, 1.74371223, -0.79806274],\n",
    "               [ 0.02968323, 1.06931597, 0.89070639],\n",
    "               [ 1.75488618, 1.49564414, 1.06939267]])\n",
    "\n",
    "qa = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01183049,  2.39236527,  0.41291216],\n",
       "       [ 0.97873601,  2.23814334, -1.29408532],\n",
       "       [-1.03878821,  1.74371223, -0.79806274],\n",
       "       [ 0.02968323,  1.06931597,  0.89070639],\n",
       "       [ 1.75488618,  1.49564414,  1.06939267]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81255067],\n",
       "       [0.1827827 ],\n",
       "       [0.00466663]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = np.array([[ 1.87108937],[ 0.37920913], [-3.28865198]])\n",
    "softmax(qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.993801077857318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937)+np.exp(0.37920913)+np.exp(-3.28865198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125506680475049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937) / 7.993801077857318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.08463061]\n",
      " [-10.99406957]\n",
      " [  1.47841105]]\n",
      "[[ 0.20035037]\n",
      " [-0.61525204]\n",
      " [-1.41450794]]\n",
      "\n",
      "[[4.37456981e-02]\n",
      " [1.68007611e-05]\n",
      " [8.14332459e-01]]\n",
      "[[0.60927625]\n",
      " [0.26952722]\n",
      " [0.12119653]]\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "print()\n",
    "    \n",
    "for a in A_n:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24282174500874198 0.23243223430314788 0.5247460206881103\n"
     ]
    }
   ],
   "source": [
    "w1 = np.exp(4.37456981e-02)\n",
    "w2 = np.exp(1.68007611e-05)\n",
    "w3 = np.exp(8.14332459e-01)\n",
    "w = w1 + w2 + w3\n",
    "print(w1/w, w2/w, w3/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.82984282],\n",
       "       [-10.93711486],\n",
       "       [  3.874953  ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = np.array([[ 1.49073203, -1.25388067, -1.4286807,  -0.25561937],\n",
    "               [-0.93583387, -0.6377515,  -0.14006872, -2.79858911],\n",
    "               [ 1.17582904,  0.9071052,  -0.8617549,  -1.7715331 ]])\n",
    "q2 = np.array([[6.1], [2.8], [4.7], [1.2]])\n",
    "q3 = np.array([[-0.39089979],[ 0.57380586],[ 0.33858905]])\n",
    "\n",
    "np.dot(q1, q2) + q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7428981 ],\n",
       "       [ 4.85531027],\n",
       "       [-8.71370112]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[ 0.17872861, -0.6912346, -0.7062834, -1.16791303],[1.48206927, 0.64496092, -1.64362799, -0.18604671], [-1.62516337, 0.58674198, 0.05285727, -0.81424207]]), \n",
    "       np.array([[6.1], [2.8], [4.7], [1.2]])) + np.array([[0.82334188],[1.95710475],[0.28557921]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 3.2, 5.1, 2. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.83029444  1.74819998  0.15065959]\n",
      " [-0.64190703 -0.23828275  0.73563826]\n",
      " [ 1.14152941 -0.40749578  0.96474426]\n",
      " [ 0.34891558  0.46111748 -1.33873322]]\n",
      "\n",
      "[[ 1.31356114 -0.37492699 -2.61059038]\n",
      " [-0.62066217  0.02652033 -3.25676797]\n",
      " [ 2.15103401 -0.22474109 -0.19109542]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in W_n:\n",
    "    print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30884409]\n",
      " [-0.29061399]\n",
      " [ 0.70296863]]\n",
      "\n",
      "[[-0.65857087]\n",
      " [-0.41272655]\n",
      " [-0.51388702]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in B_n:\n",
    "    print(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide softmax and softmax_derivative function\n",
    "def softmax(x):\n",
    "    exp_sum = np.sum([np.exp(i) for i in x])\n",
    "    softmax_x = np.array([np.exp(i)/exp_sum for i in x])\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.dot(actual.T, expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.5204970299663\n",
      "[0.04661262257797389, 0.9362395518765058, 0.01714782554552039]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,5,1]).reshape(-1,1)\n",
    "y = np.array([0,1,0]).reshape(-1,1)\n",
    "\n",
    "exp_sum = np.sum([np.exp(i)[0] for i in a])\n",
    "print(exp_sum)\n",
    "softmax_x = [np.exp(i[0])/exp_sum for i in a]\n",
    "print(softmax_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - np.dot(np.array([0,1,0]).T, np.array([0.04661262257797389, 0.9362395518765058, 0.01714782554552039]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.38905609893065, 148.4131591025766, 2.718281828459045]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.exp(i)[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01714782554552039"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.718281828459045 /158.5204970299663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04661262],\n",
       "       [0.93623955],\n",
       "       [0.01714783]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(softmax(a), y)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
