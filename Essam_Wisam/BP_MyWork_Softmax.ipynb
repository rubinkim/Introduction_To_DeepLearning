{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]\n",
      " [ 0.2829785 ]\n",
      " [-1.50629471]\n",
      " [-0.57860025]]\n",
      "\n",
      "[[ 1.65143654]\n",
      " [-2.42667924]\n",
      " [-0.42891263]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545  0.2829785  -1.50629471 -0.57860025]\n",
      " [ 1.65143654 -2.42667924 -0.42891263  1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897  1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609  1.0040539   0.3861864 ]]\n",
      "\n",
      "[[ 0.73736858  1.49073203 -0.93583387]\n",
      " [ 1.17582904 -1.25388067 -0.6377515 ]\n",
      " [ 0.9071052  -1.4286807  -0.14006872]\n",
      " [-0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]]\n",
      "\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "ind = [73, 41, 106]\n",
    "\n",
    "data = data[ind]\n",
    "target = target[ind]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label의 종류 : [0 1 2],  label종류의 갯수 : 3\n"
     ]
    }
   ],
   "source": [
    "kind_labels, count_labels = np.unique(target, return_counts=True)\n",
    "num_labels = len(kind_labels)\n",
    "print(f\"label의 종류 : {kind_labels},  label종류의 갯수 : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(target), num_labels))\n",
    "\n",
    "for i in range(len(one_hot_labels)):\n",
    "    for j in range(len(one_hot_labels[i])):\n",
    "        one_hot_labels[i, target[i]] = 1\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# data is a np.ndarray with shape (150,4)\n",
    "# one_hot_labels is a np.ndarray with shape (150,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide activation and activation_derivative funcitions\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_total = np.sum([np.exp(i) for i in x])\n",
    "    exp_x = np.array([np.exp(i)/exp_total for i in x])\n",
    "    return exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss for categorical cross-entropy loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.sum(actual.reshape(-1) * expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([[0.10, 0.85, 0.05]])\n",
    "expected = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "calculate_loss(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0th epoch total error : -50.381\n",
      "  1th epoch total error : -49.988\n",
      "  2th epoch total error : -50.552\n",
      "  3th epoch total error : -48.540\n",
      "  4th epoch total error : -31.190\n",
      "  5th epoch total error : -53.166\n",
      "  6th epoch total error : -54.456\n",
      "  7th epoch total error : -46.513\n",
      "  8th epoch total error : -36.830\n",
      "  9th epoch total error : -48.973\n",
      " 10th epoch total error : -62.848\n",
      " 11th epoch total error : -73.693\n",
      " 12th epoch total error : -50.138\n",
      " 13th epoch total error : -58.243\n",
      " 14th epoch total error : -62.191\n",
      " 15th epoch total error : -50.106\n",
      " 16th epoch total error : -50.133\n",
      " 17th epoch total error : -50.323\n",
      " 18th epoch total error : -48.611\n",
      " 19th epoch total error : -52.103\n",
      " 20th epoch total error : -55.628\n",
      " 21th epoch total error : -54.323\n",
      " 22th epoch total error : -50.167\n",
      " 23th epoch total error : -49.406\n",
      " 24th epoch total error : -46.835\n",
      " 25th epoch total error : -47.370\n",
      " 26th epoch total error : -50.251\n",
      " 27th epoch total error : -52.559\n",
      " 28th epoch total error : -68.217\n",
      " 29th epoch total error : -47.956\n",
      " 30th epoch total error : -61.718\n",
      " 31th epoch total error : -49.960\n",
      " 32th epoch total error : -52.525\n",
      " 33th epoch total error : -47.857\n",
      " 34th epoch total error : -60.893\n",
      " 35th epoch total error : -45.618\n",
      " 36th epoch total error : -52.015\n",
      " 37th epoch total error : -48.794\n",
      " 38th epoch total error : -45.070\n",
      " 39th epoch total error : -49.960\n",
      " 40th epoch total error : -49.818\n",
      " 41th epoch total error : -50.230\n",
      " 42th epoch total error : -52.402\n",
      " 43th epoch total error : -50.931\n",
      " 44th epoch total error : -51.209\n",
      " 45th epoch total error : -40.666\n",
      " 46th epoch total error : -33.006\n",
      " 47th epoch total error : -45.897\n",
      " 48th epoch total error : -64.472\n",
      " 49th epoch total error : -49.841\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.10\n",
    "epochs = 50\n",
    "\n",
    "all_epoch_errors = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Create a list that contains errors of all data points for each epoch\n",
    "    per_epoch_errors = []\n",
    "    actuals = []    \n",
    "    \n",
    "    W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "    B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "    \n",
    "    for x, y in zip(data, one_hot_labels):       # x : (4,), y : (3,)\n",
    "        # Forward Propagate\n",
    "        # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "        Z_n, A_n = [], []\n",
    "        \n",
    "        for i, (b, w) in enumerate(zip(B_n, W_n)):\n",
    "            if i == 0:\n",
    "                z = np.dot(w.T, x).reshape(-1,1) + np.array(b)                \n",
    "                a = sigmoid(z)\n",
    "            elif (i > 0) and (i < H):\n",
    "                z = np.dot(w.T, a)\n",
    "                a = sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(w.T, a)\n",
    "                a = softmax(z)\n",
    "\n",
    "            Z_n.append(z)\n",
    "            A_n.append(a)\n",
    "            \n",
    "        # Backpropagate\n",
    "        e_Je_W_ns = [np.zeros(w.shape) for w in W_n]\n",
    "        e_Je_B_ns = [np.zeros(b.shape) for b in B_n]\n",
    "        \n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "            else:\n",
    "                delta = A_n[L] - y.reshape(-1,1)\n",
    "            \n",
    "            e_Je_B_ns = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "            else:\n",
    "                e_Je_W_ns[L] = np.dot(x.reshape(-1,1), delta.T)\n",
    "                \n",
    "        for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "            W_n[i] -= learning_rate/len(data) * ejew\n",
    "        B_n[i] -= learning_rate/len(data) * ejeb\n",
    "        \"\"\"\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()\n",
    "        \"\"\"    \n",
    "\n",
    "        datapoint_error = calculate_loss(A_n[-1], y)\n",
    "        per_epoch_errors.append(datapoint_error)\n",
    "        actuals.append(A_n[-1].reshape(-1))\n",
    "    total_errors = np.sum(per_epoch_errors)\n",
    "    all_epoch_errors.append(total_errors)\n",
    "    print(f\"{epoch:3d}th epoch total error : {total_errors:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "max_indexes = []\n",
    "for x in actuals:\n",
    "    max_idx = np.argmax(x)\n",
    "    max_indexes.append(max_idx)\n",
    "\n",
    "print(max_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.16527402 0.70016205 0.13456393]\n",
      "[0.18151241 0.68946506 0.12902252]\n",
      "[0.17592426 0.69387609 0.13019965]\n",
      "[0.18817138 0.67922597 0.13260265]\n",
      "[0.16567493 0.69889664 0.13542843]\n",
      "[0.17297687 0.69533912 0.13168401]\n",
      "[0.18383829 0.68760964 0.12855207]\n",
      "[0.17495971 0.69059898 0.13444131]\n",
      "[0.19812524 0.67300828 0.12886647]\n",
      "[0.17925199 0.6843447  0.13640331]\n",
      "[0.1654897  0.69754136 0.13696894]\n",
      "[0.18364637 0.67999567 0.13635795]\n",
      "[0.18221574 0.68404369 0.13374058]\n",
      "[0.1805228  0.68906096 0.13041624]\n",
      "[0.15731312 0.70556531 0.13712157]\n",
      "[0.16048401 0.70606227 0.13345372]\n",
      "[0.1712552  0.70330327 0.12544153]\n",
      "[0.18055671 0.69184085 0.12760244]\n",
      "[0.1746997  0.69118899 0.13411131]\n",
      "[0.17590633 0.69187717 0.1322165 ]\n",
      "[0.18308488 0.68190395 0.13501117]\n",
      "[0.18654711 0.68812651 0.12532637]\n",
      "[0.16975879 0.70125672 0.12898448]\n",
      "[0.21809664 0.66424352 0.11765984]\n",
      "[0.20677939 0.65227314 0.14094747]\n",
      "[0.20128129 0.66945948 0.12925923]\n",
      "[0.20513963 0.67188407 0.1229763 ]\n",
      "[0.18164309 0.68519795 0.13315896]\n",
      "[0.18277425 0.68668701 0.13053873]\n",
      "[0.20359485 0.66373093 0.13267422]\n",
      "[0.20532148 0.66384835 0.13083017]\n",
      "[0.19953102 0.68064079 0.11982819]\n",
      "[0.16434534 0.69128107 0.14437359]\n",
      "[0.16458478 0.69653038 0.13888484]\n",
      "[0.20182122 0.66988841 0.12829036]\n",
      "[0.18979655 0.68510298 0.12510047]\n",
      "[0.18184602 0.68881569 0.12933829]\n",
      "[0.17876645 0.6833075  0.13792605]\n",
      "[0.20899207 0.66563054 0.12537739]\n",
      "[0.19270547 0.67650668 0.13078785]\n",
      "[0.19305041 0.68314376 0.12380583]\n",
      "[0.24598145 0.64415722 0.10986133]\n",
      "[0.2045987  0.6679558  0.12744551]\n",
      "[0.23277292 0.65654226 0.11068482]\n",
      "[0.21657248 0.65286959 0.13055793]\n",
      "[0.21923831 0.6619068  0.11885488]\n",
      "[0.1885248  0.67522884 0.13624637]\n",
      "[0.20838227 0.66390167 0.12771607]\n",
      "[0.18779334 0.67934314 0.13286351]\n",
      "[0.20030688 0.67245886 0.12723426]\n",
      "[0.59070429 0.3236457  0.08565001]\n",
      "[0.60005747 0.31992998 0.08001256]\n",
      "[0.61255954 0.30698953 0.08045093]\n",
      "[0.60685179 0.31641147 0.07673674]\n",
      "[0.61529283 0.30831404 0.07639313]\n",
      "[0.59815785 0.31738589 0.08445626]\n",
      "[0.60603962 0.31619341 0.07776697]\n",
      "[0.54389332 0.36581857 0.09028811]\n",
      "[0.58776964 0.32505374 0.08717662]\n",
      "[0.59218756 0.3311737  0.07663874]\n",
      "[0.57064155 0.34355169 0.08580676]\n",
      "[0.59211743 0.33040968 0.07747289]\n",
      "[0.56259915 0.34602798 0.09137287]\n",
      "[0.59969817 0.31749132 0.0828105 ]\n",
      "[0.54754893 0.36858351 0.08386756]\n",
      "[0.5694531  0.34508182 0.08546508]\n",
      "[0.59569488 0.32569307 0.07861205]\n",
      "[0.54342045 0.35638502 0.10019453]\n",
      "[0.62288444 0.30553475 0.07158081]\n",
      "[0.55813254 0.35142355 0.09044391]\n",
      "[0.60943697 0.32043122 0.07013182]\n",
      "[0.55766584 0.35701245 0.0853217 ]\n",
      "[0.61832697 0.30590434 0.07576869]\n",
      "[0.5752785  0.33138255 0.09333895]\n",
      "[0.56005672 0.35156617 0.08837711]\n",
      "[0.5662098  0.34844066 0.08534954]\n",
      "[0.58957449 0.32614622 0.08427929]\n",
      "[0.61109501 0.31469624 0.07420875]\n",
      "[0.58886582 0.33191788 0.0792163 ]\n",
      "[0.4936442  0.40871486 0.09764094]\n",
      "[0.54892553 0.36117133 0.08990315]\n",
      "[0.52891144 0.37573669 0.09535187]\n",
      "[0.54160295 0.36863616 0.08976089]\n",
      "[0.60835855 0.31626634 0.07537511]\n",
      "[0.57795617 0.34167796 0.08036587]\n",
      "[0.56899128 0.34976327 0.08124545]\n",
      "[0.57327691 0.34252999 0.08419309]\n",
      "[0.58193771 0.33567016 0.08239213]\n",
      "[0.54578658 0.36441228 0.08980114]\n",
      "[0.56613909 0.35128065 0.08258026]\n",
      "[0.56265603 0.34632394 0.09102003]\n",
      "[0.56526587 0.34723413 0.08749999]\n",
      "[0.54247102 0.36757338 0.0899556 ]\n",
      "[0.51116463 0.39609668 0.09273868]\n",
      "[0.5581996  0.35512211 0.0866783 ]\n",
      "[0.53002148 0.3726812  0.09729733]\n",
      "[0.54543926 0.36463597 0.08992477]\n",
      "[0.54041012 0.36834359 0.09124629]\n",
      "[0.47626744 0.43469062 0.08904194]\n",
      "[0.54353154 0.36808471 0.08838375]\n",
      "[0.61295811 0.33020423 0.05683766]\n",
      "[0.60529519 0.32855478 0.06615003]\n",
      "[0.62124189 0.31224886 0.06650925]\n",
      "[0.60069291 0.32474785 0.07455924]\n",
      "[0.61512156 0.32148858 0.06338985]\n",
      "[0.62707734 0.30243682 0.07048584]\n",
      "[0.58678865 0.34318079 0.07003056]\n",
      "[0.60941041 0.31017169 0.0804179 ]\n",
      "[0.61515886 0.31061101 0.07423014]\n",
      "[0.61245239 0.32498168 0.06256593]\n",
      "[0.59277339 0.33585392 0.07137269]\n",
      "[0.60544548 0.32301029 0.07154422]\n",
      "[0.60836471 0.32272197 0.06891332]\n",
      "[0.60522583 0.32927229 0.06550188]\n",
      "[0.60709993 0.33494931 0.05795076]\n",
      "[0.60206489 0.3338324  0.06410272]\n",
      "[0.58690117 0.33114061 0.08195822]\n",
      "[0.5942872  0.32426285 0.08144995]\n",
      "[0.63593381 0.2958993  0.06816688]\n",
      "[0.58847474 0.3268159  0.08470935]\n",
      "[0.60564017 0.32620767 0.06815215]\n",
      "[0.58883836 0.34087477 0.07028687]\n",
      "[0.61364085 0.30487069 0.08148845]\n",
      "[0.58542464 0.33534535 0.07923001]\n",
      "[0.58739968 0.3345763  0.07802402]\n",
      "[0.57380903 0.3314308  0.09476017]\n",
      "[0.57638574 0.34214425 0.08147002]\n",
      "[0.56742423 0.34767457 0.0849012 ]\n",
      "[0.59774989 0.32810408 0.07414603]\n",
      "[0.55719887 0.33723192 0.10556921]\n",
      "[0.59360997 0.31815588 0.08823415]\n",
      "[0.55837107 0.33914845 0.10248048]\n",
      "[0.59754427 0.3297599  0.07269583]\n",
      "[0.54364226 0.350875   0.10548273]\n",
      "[0.54092997 0.34602875 0.11304129]\n",
      "[0.60620905 0.31661656 0.07717439]\n",
      "[0.58025627 0.34690019 0.07284354]\n",
      "[0.55295895 0.34863089 0.09841017]\n",
      "[0.55166209 0.35671444 0.09162347]\n",
      "[0.57719444 0.33869233 0.08411323]\n",
      "[0.59118197 0.33591391 0.07290412]\n",
      "[0.58437054 0.34039025 0.07523921]\n",
      "[0.56790636 0.34610214 0.08599151]\n",
      "[0.58071337 0.33800589 0.08128074]\n",
      "[0.5849246  0.34146996 0.07360543]\n",
      "[0.58416415 0.33955837 0.07627748]\n",
      "[0.57569095 0.33801934 0.08628971]\n",
      "[0.56158842 0.34765915 0.09075244]\n",
      "[0.5610458  0.35650942 0.08244478]\n",
      "[0.53776648 0.3605873  0.10164622]\n"
     ]
    }
   ],
   "source": [
    "for x in actuals:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83154471]\n",
      " [ -0.96947549]\n",
      " [  6.09361791]\n",
      " [-15.10743014]\n",
      " [ -3.23182179]]\n",
      "\n",
      "[[ 1.95534369]\n",
      " [-2.13481311]\n",
      " [ 1.30590787]\n",
      " [ 2.54368828]\n",
      " [-0.56127734]]\n",
      "\n",
      "[[ 1.87108937]\n",
      " [ 0.37920913]\n",
      " [-3.28865198]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.61945643e-01]\n",
      " [2.74985060e-01]\n",
      " [9.97747856e-01]\n",
      " [2.74742811e-07]\n",
      " [3.79856179e-02]]\n",
      "\n",
      "[[0.87602815]\n",
      " [0.10575893]\n",
      " [0.78682759]\n",
      " [0.92714834]\n",
      " [0.36325196]]\n",
      "\n",
      "[[0.81255067]\n",
      " [0.1827827 ]\n",
      " [0.00466663]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in A_n:\n",
    "    print(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = np.array([[-0.67888615],[-0.09470897],[ 1.49138963]])\n",
    "\n",
    "qw = np.array([[-0.01183049, 2.39236527, 0.41291216],\n",
    "               [ 0.97873601, 2.23814334,-1.29408532],\n",
    "               [-1.03878821, 1.74371223, -0.79806274],\n",
    "               [ 0.02968323, 1.06931597, 0.89070639],\n",
    "               [ 1.75488618, 1.49564414, 1.06939267]])\n",
    "\n",
    "qa = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01183049,  2.39236527,  0.41291216],\n",
       "       [ 0.97873601,  2.23814334, -1.29408532],\n",
       "       [-1.03878821,  1.74371223, -0.79806274],\n",
       "       [ 0.02968323,  1.06931597,  0.89070639],\n",
       "       [ 1.75488618,  1.49564414,  1.06939267]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81255067],\n",
       "       [0.1827827 ],\n",
       "       [0.00466663]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = np.array([[ 1.87108937],[ 0.37920913], [-3.28865198]])\n",
    "softmax(qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.993801077857318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937)+np.exp(0.37920913)+np.exp(-3.28865198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125506680475049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937) / 7.993801077857318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.08463061]\n",
      " [-10.99406957]\n",
      " [  1.47841105]]\n",
      "[[ 0.20035037]\n",
      " [-0.61525204]\n",
      " [-1.41450794]]\n",
      "\n",
      "[[4.37456981e-02]\n",
      " [1.68007611e-05]\n",
      " [8.14332459e-01]]\n",
      "[[0.60927625]\n",
      " [0.26952722]\n",
      " [0.12119653]]\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "print()\n",
    "    \n",
    "for a in A_n:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24282174500874198 0.23243223430314788 0.5247460206881103\n"
     ]
    }
   ],
   "source": [
    "w1 = np.exp(4.37456981e-02)\n",
    "w2 = np.exp(1.68007611e-05)\n",
    "w3 = np.exp(8.14332459e-01)\n",
    "w = w1 + w2 + w3\n",
    "print(w1/w, w2/w, w3/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.82984282],\n",
       "       [-10.93711486],\n",
       "       [  3.874953  ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = np.array([[ 1.49073203, -1.25388067, -1.4286807,  -0.25561937],\n",
    "               [-0.93583387, -0.6377515,  -0.14006872, -2.79858911],\n",
    "               [ 1.17582904,  0.9071052,  -0.8617549,  -1.7715331 ]])\n",
    "q2 = np.array([[6.1], [2.8], [4.7], [1.2]])\n",
    "q3 = np.array([[-0.39089979],[ 0.57380586],[ 0.33858905]])\n",
    "\n",
    "np.dot(q1, q2) + q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7428981 ],\n",
       "       [ 4.85531027],\n",
       "       [-8.71370112]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[ 0.17872861, -0.6912346, -0.7062834, -1.16791303],[1.48206927, 0.64496092, -1.64362799, -0.18604671], [-1.62516337, 0.58674198, 0.05285727, -0.81424207]]), \n",
    "       np.array([[6.1], [2.8], [4.7], [1.2]])) + np.array([[0.82334188],[1.95710475],[0.28557921]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 3.2, 5.1, 2. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.83029444  1.74819998  0.15065959]\n",
      " [-0.64190703 -0.23828275  0.73563826]\n",
      " [ 1.14152941 -0.40749578  0.96474426]\n",
      " [ 0.34891558  0.46111748 -1.33873322]]\n",
      "\n",
      "[[ 1.31356114 -0.37492699 -2.61059038]\n",
      " [-0.62066217  0.02652033 -3.25676797]\n",
      " [ 2.15103401 -0.22474109 -0.19109542]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in W_n:\n",
    "    print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30884409]\n",
      " [-0.29061399]\n",
      " [ 0.70296863]]\n",
      "\n",
      "[[-0.65857087]\n",
      " [-0.41272655]\n",
      " [-0.51388702]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in B_n:\n",
    "    print(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide softmax and softmax_derivative function\n",
    "def softmax(x):\n",
    "    exp_sum = np.sum([np.exp(i) for i in x])\n",
    "    softmax_x = np.array([np.exp(i)/exp_sum for i in x])\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.dot(actual.T, expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.5204970299663\n",
      "[0.04661262257797389, 0.9362395518765058, 0.01714782554552039]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,5,1]).reshape(-1,1)\n",
    "y = np.array([0,1,0]).reshape(-1,1)\n",
    "\n",
    "exp_sum = np.sum([np.exp(i)[0] for i in a])\n",
    "print(exp_sum)\n",
    "softmax_x = [np.exp(i[0])/exp_sum for i in a]\n",
    "print(softmax_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - np.dot(np.array([0,1,0]).T, np.array([0.04661262257797389, 0.9362395518765058, 0.01714782554552039]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.38905609893065, 148.4131591025766, 2.718281828459045]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.exp(i)[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01714782554552039"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.718281828459045 /158.5204970299663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04661262],\n",
       "       [0.93623955],\n",
       "       [0.01714783]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(softmax(a), y)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
