{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]\n",
      " [ 0.2829785 ]\n",
      " [-1.50629471]\n",
      " [-0.57860025]]\n",
      "\n",
      "[[ 1.65143654]\n",
      " [-2.42667924]\n",
      " [-0.42891263]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545  0.2829785  -1.50629471 -0.57860025]\n",
      " [ 1.65143654 -2.42667924 -0.42891263  1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897  1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609  1.0040539   0.3861864 ]]\n",
      "\n",
      "[[ 0.73736858  1.49073203 -0.93583387]\n",
      " [ 1.17582904 -1.25388067 -0.6377515 ]\n",
      " [ 0.9071052  -1.4286807  -0.14006872]\n",
      " [-0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1 2.8 4.7 1.2]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.9 2.5 4.5 1.7]]\n",
      "\n",
      "[1 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "ind = [73, 41, 106]\n",
    "\n",
    "data = data[ind]\n",
    "target = target[ind]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label의 종류 : [0 1 2],  label종류의 갯수 : 3\n"
     ]
    }
   ],
   "source": [
    "kind_labels, count_labels = np.unique(target, return_counts=True)\n",
    "num_labels = len(kind_labels)\n",
    "print(f\"label의 종류 : {kind_labels},  label종류의 갯수 : {num_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(target), num_labels))\n",
    "\n",
    "for i in range(len(one_hot_labels)):\n",
    "    for j in range(len(one_hot_labels[i])):\n",
    "        one_hot_labels[i, target[i]] = 1\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# data is a np.ndarray with shape (150,4)\n",
    "# one_hot_labels is a np.ndarray with shape (150,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide activation and activation_derivative funcitions\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exp_total = np.sum([np.exp(i) for i in x])\n",
    "    exp_x = np.array([np.exp(i)/exp_total for i in x])\n",
    "    return exp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss for categorical cross-entropy loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.sum(actual.reshape(-1) * expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.85"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([[0.10, 0.85, 0.05]])\n",
    "expected = np.array([0.0, 1.0, 0.0])\n",
    "\n",
    "calculate_loss(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0th epoch total error : -0.992\n",
      "  1th epoch total error : -0.964\n",
      "  2th epoch total error : -1.054\n",
      "  3th epoch total error : -1.036\n",
      "  4th epoch total error : -1.089\n",
      "  5th epoch total error : -0.992\n",
      "  6th epoch total error : -0.954\n",
      "  7th epoch total error : -0.995\n",
      "  8th epoch total error : -0.974\n",
      "  9th epoch total error : -1.003\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.10\n",
    "epochs = 10\n",
    "\n",
    "all_epoch_errors = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Create a list that contains errors of all data points for each epoch\n",
    "    per_epoch_errors = []\n",
    "    \n",
    "    W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "    B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "    \n",
    "    for x, y in zip(data, one_hot_labels):       # x : (4,), y : (3,)\n",
    "        # Forward Propagate\n",
    "        # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "        Z_n, A_n = [], []\n",
    "        \n",
    "        for i, (b, w) in enumerate(zip(B_n, W_n)):\n",
    "            if i == 0:\n",
    "                z = np.dot(w.T, x).reshape(-1,1) + np.array(b)                \n",
    "                a = sigmoid(z)\n",
    "            elif (i > 0) and (i < H):\n",
    "                z = np.dot(w.T, a)\n",
    "                a = sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(w.T, a)\n",
    "                a = softmax(z)\n",
    "\n",
    "            Z_n.append(z)\n",
    "            A_n.append(a)\n",
    "            \n",
    "        # Backpropagate\n",
    "        e_Je_W_ns = [np.zeros(w.shape) for w in W_n]\n",
    "        e_Je_B_ns = [np.zeros(b.shape) for b in B_n]\n",
    "        \n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "            else:\n",
    "                delta = A_n[L] - y.reshape(-1,1)\n",
    "            \n",
    "            e_Je_B_ns = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "            else:\n",
    "                e_Je_W_ns[L] = np.dot(x.reshape(-1,1), delta.T)\n",
    "                \n",
    "        for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "            W_n[i] -= learning_rate/len(data) * ejew\n",
    "        B_n[i] -= learning_rate/len(data) * ejeb\n",
    "        \"\"\"\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()\n",
    "        \"\"\"    \n",
    "\n",
    "        datapoint_error = calculate_loss(A_n[-1], y)\n",
    "        per_epoch_errors.append(datapoint_error)\n",
    "    total_errors = np.sum(per_epoch_errors)\n",
    "    all_epoch_errors.append(total_errors)\n",
    "    print(f\"{epoch:3d}th epoch total error : {total_errors:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.83154471]\n",
      " [ -0.96947549]\n",
      " [  6.09361791]\n",
      " [-15.10743014]\n",
      " [ -3.23182179]]\n",
      "\n",
      "[[ 1.95534369]\n",
      " [-2.13481311]\n",
      " [ 1.30590787]\n",
      " [ 2.54368828]\n",
      " [-0.56127734]]\n",
      "\n",
      "[[ 1.87108937]\n",
      " [ 0.37920913]\n",
      " [-3.28865198]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.61945643e-01]\n",
      " [2.74985060e-01]\n",
      " [9.97747856e-01]\n",
      " [2.74742811e-07]\n",
      " [3.79856179e-02]]\n",
      "\n",
      "[[0.87602815]\n",
      " [0.10575893]\n",
      " [0.78682759]\n",
      " [0.92714834]\n",
      " [0.36325196]]\n",
      "\n",
      "[[0.81255067]\n",
      " [0.1827827 ]\n",
      " [0.00466663]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in A_n:\n",
    "    print(a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb = np.array([[-0.67888615],[-0.09470897],[ 1.49138963]])\n",
    "\n",
    "qw = np.array([[-0.01183049, 2.39236527, 0.41291216],\n",
    "               [ 0.97873601, 2.23814334,-1.29408532],\n",
    "               [-1.03878821, 1.74371223, -0.79806274],\n",
    "               [ 0.02968323, 1.06931597, 0.89070639],\n",
    "               [ 1.75488618, 1.49564414, 1.06939267]])\n",
    "\n",
    "qa = np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01183049,  2.39236527,  0.41291216],\n",
       "       [ 0.97873601,  2.23814334, -1.29408532],\n",
       "       [-1.03878821,  1.74371223, -0.79806274],\n",
       "       [ 0.02968323,  1.06931597,  0.89070639],\n",
       "       [ 1.75488618,  1.49564414,  1.06939267]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81255067],\n",
       "       [0.1827827 ],\n",
       "       [0.00466663]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qr = np.array([[ 1.87108937],[ 0.37920913], [-3.28865198]])\n",
    "softmax(qr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.993801077857318"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937)+np.exp(0.37920913)+np.exp(-3.28865198)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8125506680475049"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1.87108937) / 7.993801077857318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -3.08463061]\n",
      " [-10.99406957]\n",
      " [  1.47841105]]\n",
      "[[ 0.20035037]\n",
      " [-0.61525204]\n",
      " [-1.41450794]]\n",
      "\n",
      "[[4.37456981e-02]\n",
      " [1.68007611e-05]\n",
      " [8.14332459e-01]]\n",
      "[[0.60927625]\n",
      " [0.26952722]\n",
      " [0.12119653]]\n"
     ]
    }
   ],
   "source": [
    "for z in Z_n:\n",
    "    print(z)\n",
    "print()\n",
    "    \n",
    "for a in A_n:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24282174500874198 0.23243223430314788 0.5247460206881103\n"
     ]
    }
   ],
   "source": [
    "w1 = np.exp(4.37456981e-02)\n",
    "w2 = np.exp(1.68007611e-05)\n",
    "w3 = np.exp(8.14332459e-01)\n",
    "w = w1 + w2 + w3\n",
    "print(w1/w, w2/w, w3/w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.82984282],\n",
       "       [-10.93711486],\n",
       "       [  3.874953  ]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = np.array([[ 1.49073203, -1.25388067, -1.4286807,  -0.25561937],\n",
    "               [-0.93583387, -0.6377515,  -0.14006872, -2.79858911],\n",
    "               [ 1.17582904,  0.9071052,  -0.8617549,  -1.7715331 ]])\n",
    "q2 = np.array([[6.1], [2.8], [4.7], [1.2]])\n",
    "q3 = np.array([[-0.39089979],[ 0.57380586],[ 0.33858905]])\n",
    "\n",
    "np.dot(q1, q2) + q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.7428981 ],\n",
       "       [ 4.85531027],\n",
       "       [-8.71370112]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.array([[ 0.17872861, -0.6912346, -0.7062834, -1.16791303],[1.48206927, 0.64496092, -1.64362799, -0.18604671], [-1.62516337, 0.58674198, 0.05285727, -0.81424207]]), \n",
    "       np.array([[6.1], [2.8], [4.7], [1.2]])) + np.array([[0.82334188],[1.95710475],[0.28557921]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.5, 3.2, 5.1, 2. ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.83029444  1.74819998  0.15065959]\n",
      " [-0.64190703 -0.23828275  0.73563826]\n",
      " [ 1.14152941 -0.40749578  0.96474426]\n",
      " [ 0.34891558  0.46111748 -1.33873322]]\n",
      "\n",
      "[[ 1.31356114 -0.37492699 -2.61059038]\n",
      " [-0.62066217  0.02652033 -3.25676797]\n",
      " [ 2.15103401 -0.22474109 -0.19109542]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for w in W_n:\n",
    "    print(w)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30884409]\n",
      " [-0.29061399]\n",
      " [ 0.70296863]]\n",
      "\n",
      "[[-0.65857087]\n",
      " [-0.41272655]\n",
      " [-0.51388702]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for b in B_n:\n",
    "    print(b)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide softmax and softmax_derivative function\n",
    "def softmax(x):\n",
    "    exp_sum = np.sum([np.exp(i) for i in x])\n",
    "    softmax_x = np.array([np.exp(i)/exp_sum for i in x])\n",
    "    return softmax_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.dot(actual.T, expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.5204970299663\n",
      "[0.04661262257797389, 0.9362395518765058, 0.01714782554552039]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2,5,1]).reshape(-1,1)\n",
    "y = np.array([0,1,0]).reshape(-1,1)\n",
    "\n",
    "exp_sum = np.sum([np.exp(i)[0] for i in a])\n",
    "print(exp_sum)\n",
    "softmax_x = [np.exp(i[0])/exp_sum for i in a]\n",
    "print(softmax_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - np.dot(np.array([0,1,0]).T, np.array([0.04661262257797389, 0.9362395518765058, 0.01714782554552039]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7.38905609893065, 148.4131591025766, 2.718281828459045]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.exp(i)[0] for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01714782554552039"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2.718281828459045 /158.5204970299663"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04661262],\n",
       "       [0.93623955],\n",
       "       [0.01714783]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9362395518765058"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(softmax(a), y)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
