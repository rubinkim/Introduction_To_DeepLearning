{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3]\n"
     ]
    }
   ],
   "source": [
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(\" \")\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()[\"data\"]\n",
    "target = load_iris()[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[2, 57, 105, 15, 75, 125]]\n",
    "target = target[[2, 57, 105, 15, 75, 125]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.1 3.5 1.4 0.2] 0\n",
      "[4.9 3.  1.4 0.2] 0\n",
      "[4.7 3.2 1.3 0.2] 0\n",
      "[4.6 3.1 1.5 0.2] 0\n",
      "[5.  3.6 1.4 0.2] 0\n",
      "[5.4 3.9 1.7 0.4] 0\n",
      "[4.6 3.4 1.4 0.3] 0\n",
      "[5.  3.4 1.5 0.2] 0\n",
      "[4.4 2.9 1.4 0.2] 0\n",
      "[4.9 3.1 1.5 0.1] 0\n",
      "[5.4 3.7 1.5 0.2] 0\n",
      "[4.8 3.4 1.6 0.2] 0\n",
      "[4.8 3.  1.4 0.1] 0\n",
      "[4.3 3.  1.1 0.1] 0\n",
      "[5.8 4.  1.2 0.2] 0\n",
      "[5.7 4.4 1.5 0.4] 0\n",
      "[5.4 3.9 1.3 0.4] 0\n",
      "[5.1 3.5 1.4 0.3] 0\n",
      "[5.7 3.8 1.7 0.3] 0\n",
      "[5.1 3.8 1.5 0.3] 0\n",
      "[5.4 3.4 1.7 0.2] 0\n",
      "[5.1 3.7 1.5 0.4] 0\n",
      "[4.6 3.6 1.  0.2] 0\n",
      "[5.1 3.3 1.7 0.5] 0\n",
      "[4.8 3.4 1.9 0.2] 0\n",
      "[5.  3.  1.6 0.2] 0\n",
      "[5.  3.4 1.6 0.4] 0\n",
      "[5.2 3.5 1.5 0.2] 0\n",
      "[5.2 3.4 1.4 0.2] 0\n",
      "[4.7 3.2 1.6 0.2] 0\n",
      "[4.8 3.1 1.6 0.2] 0\n",
      "[5.4 3.4 1.5 0.4] 0\n",
      "[5.2 4.1 1.5 0.1] 0\n",
      "[5.5 4.2 1.4 0.2] 0\n",
      "[4.9 3.1 1.5 0.2] 0\n",
      "[5.  3.2 1.2 0.2] 0\n",
      "[5.5 3.5 1.3 0.2] 0\n",
      "[4.9 3.6 1.4 0.1] 0\n",
      "[4.4 3.  1.3 0.2] 0\n",
      "[5.1 3.4 1.5 0.2] 0\n",
      "[5.  3.5 1.3 0.3] 0\n",
      "[4.5 2.3 1.3 0.3] 0\n",
      "[4.4 3.2 1.3 0.2] 0\n",
      "[5.  3.5 1.6 0.6] 0\n",
      "[5.1 3.8 1.9 0.4] 0\n",
      "[4.8 3.  1.4 0.3] 0\n",
      "[5.1 3.8 1.6 0.2] 0\n",
      "[4.6 3.2 1.4 0.2] 0\n",
      "[5.3 3.7 1.5 0.2] 0\n",
      "[5.  3.3 1.4 0.2] 0\n",
      "[7.  3.2 4.7 1.4] 1\n",
      "[6.4 3.2 4.5 1.5] 1\n",
      "[6.9 3.1 4.9 1.5] 1\n",
      "[5.5 2.3 4.  1.3] 1\n",
      "[6.5 2.8 4.6 1.5] 1\n",
      "[5.7 2.8 4.5 1.3] 1\n",
      "[6.3 3.3 4.7 1.6] 1\n",
      "[4.9 2.4 3.3 1. ] 1\n",
      "[6.6 2.9 4.6 1.3] 1\n",
      "[5.2 2.7 3.9 1.4] 1\n",
      "[5.  2.  3.5 1. ] 1\n",
      "[5.9 3.  4.2 1.5] 1\n",
      "[6.  2.2 4.  1. ] 1\n",
      "[6.1 2.9 4.7 1.4] 1\n",
      "[5.6 2.9 3.6 1.3] 1\n",
      "[6.7 3.1 4.4 1.4] 1\n",
      "[5.6 3.  4.5 1.5] 1\n",
      "[5.8 2.7 4.1 1. ] 1\n",
      "[6.2 2.2 4.5 1.5] 1\n",
      "[5.6 2.5 3.9 1.1] 1\n",
      "[5.9 3.2 4.8 1.8] 1\n",
      "[6.1 2.8 4.  1.3] 1\n",
      "[6.3 2.5 4.9 1.5] 1\n",
      "[6.1 2.8 4.7 1.2] 1\n",
      "[6.4 2.9 4.3 1.3] 1\n",
      "[6.6 3.  4.4 1.4] 1\n",
      "[6.8 2.8 4.8 1.4] 1\n",
      "[6.7 3.  5.  1.7] 1\n",
      "[6.  2.9 4.5 1.5] 1\n",
      "[5.7 2.6 3.5 1. ] 1\n",
      "[5.5 2.4 3.8 1.1] 1\n",
      "[5.5 2.4 3.7 1. ] 1\n",
      "[5.8 2.7 3.9 1.2] 1\n",
      "[6.  2.7 5.1 1.6] 1\n",
      "[5.4 3.  4.5 1.5] 1\n",
      "[6.  3.4 4.5 1.6] 1\n",
      "[6.7 3.1 4.7 1.5] 1\n",
      "[6.3 2.3 4.4 1.3] 1\n",
      "[5.6 3.  4.1 1.3] 1\n",
      "[5.5 2.5 4.  1.3] 1\n",
      "[5.5 2.6 4.4 1.2] 1\n",
      "[6.1 3.  4.6 1.4] 1\n",
      "[5.8 2.6 4.  1.2] 1\n",
      "[5.  2.3 3.3 1. ] 1\n",
      "[5.6 2.7 4.2 1.3] 1\n",
      "[5.7 3.  4.2 1.2] 1\n",
      "[5.7 2.9 4.2 1.3] 1\n",
      "[6.2 2.9 4.3 1.3] 1\n",
      "[5.1 2.5 3.  1.1] 1\n",
      "[5.7 2.8 4.1 1.3] 1\n",
      "[6.3 3.3 6.  2.5] 2\n",
      "[5.8 2.7 5.1 1.9] 2\n",
      "[7.1 3.  5.9 2.1] 2\n",
      "[6.3 2.9 5.6 1.8] 2\n",
      "[6.5 3.  5.8 2.2] 2\n",
      "[7.6 3.  6.6 2.1] 2\n",
      "[4.9 2.5 4.5 1.7] 2\n",
      "[7.3 2.9 6.3 1.8] 2\n",
      "[6.7 2.5 5.8 1.8] 2\n",
      "[7.2 3.6 6.1 2.5] 2\n",
      "[6.5 3.2 5.1 2. ] 2\n",
      "[6.4 2.7 5.3 1.9] 2\n",
      "[6.8 3.  5.5 2.1] 2\n",
      "[5.7 2.5 5.  2. ] 2\n",
      "[5.8 2.8 5.1 2.4] 2\n",
      "[6.4 3.2 5.3 2.3] 2\n",
      "[6.5 3.  5.5 1.8] 2\n",
      "[7.7 3.8 6.7 2.2] 2\n",
      "[7.7 2.6 6.9 2.3] 2\n",
      "[6.  2.2 5.  1.5] 2\n",
      "[6.9 3.2 5.7 2.3] 2\n",
      "[5.6 2.8 4.9 2. ] 2\n",
      "[7.7 2.8 6.7 2. ] 2\n",
      "[6.3 2.7 4.9 1.8] 2\n",
      "[6.7 3.3 5.7 2.1] 2\n",
      "[7.2 3.2 6.  1.8] 2\n",
      "[6.2 2.8 4.8 1.8] 2\n",
      "[6.1 3.  4.9 1.8] 2\n",
      "[6.4 2.8 5.6 2.1] 2\n",
      "[7.2 3.  5.8 1.6] 2\n",
      "[7.4 2.8 6.1 1.9] 2\n",
      "[7.9 3.8 6.4 2. ] 2\n",
      "[6.4 2.8 5.6 2.2] 2\n",
      "[6.3 2.8 5.1 1.5] 2\n",
      "[6.1 2.6 5.6 1.4] 2\n",
      "[7.7 3.  6.1 2.3] 2\n",
      "[6.3 3.4 5.6 2.4] 2\n",
      "[6.4 3.1 5.5 1.8] 2\n",
      "[6.  3.  4.8 1.8] 2\n",
      "[6.9 3.1 5.4 2.1] 2\n",
      "[6.7 3.1 5.6 2.4] 2\n",
      "[6.9 3.1 5.1 2.3] 2\n",
      "[5.8 2.7 5.1 1.9] 2\n",
      "[6.8 3.2 5.9 2.3] 2\n",
      "[6.7 3.3 5.7 2.5] 2\n",
      "[6.7 3.  5.2 2.3] 2\n",
      "[6.3 2.5 5.  1.9] 2\n",
      "[6.5 3.  5.2 2. ] 2\n",
      "[6.2 3.4 5.4 2.3] 2\n",
      "[5.9 3.  5.1 1.8] 2\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(data, target):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot_labels = np.zeros((len(data), 3))\n",
    "for i in range(len(one_hot_labels)):\n",
    "    for j in range(len(one_hot_labels[i])):\n",
    "        one_hot_labels[i, target[i]] = 1\n",
    "print(one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))\n",
    "\n",
    "def softmax(x):\n",
    "    exponential_sum = np.sum([np.exp(i) for i in x])\n",
    "    exponential_x = np.array([np.exp(i) / exponential_sum for i in x])\n",
    "    return exponential_x\n",
    "\n",
    "def calculate_loss(actual, expected):\n",
    "    loss = - np.sum(actual.reshape(-1) * expected)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.72"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual = np.array([[0.08], [0.24], [0.72]])\n",
    "expected = np.array([0, 0, 1])\n",
    "calculate_loss(actual, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th loss : -114.87034402462294\n",
      "1th loss : -114.85994379410555\n",
      "2th loss : -107.85268720145862\n",
      "3th loss : -104.84819371511468\n",
      "4th loss : -106.7267551647377\n",
      "5th loss : -97.17752244143004\n",
      "6th loss : -111.22318118996134\n",
      "7th loss : -122.67541014030442\n",
      "8th loss : -103.31342817313949\n",
      "9th loss : -118.98269592823598\n",
      "10th loss : -101.57303883789608\n",
      "11th loss : -119.50082084395335\n",
      "12th loss : -109.68559473042468\n",
      "13th loss : -110.4896466205947\n",
      "14th loss : -109.39357744761435\n",
      "15th loss : -99.63683114709302\n",
      "16th loss : -113.22698070176305\n",
      "17th loss : -117.08096008878549\n",
      "18th loss : -115.29052974134645\n",
      "19th loss : -109.64950930160717\n",
      "20th loss : -89.9455791306435\n",
      "21th loss : -104.61958348511207\n",
      "22th loss : -115.96974215746185\n",
      "23th loss : -113.44808199671444\n",
      "24th loss : -104.72773378298123\n",
      "25th loss : -111.92985830290648\n",
      "26th loss : -98.43628385521711\n",
      "27th loss : -112.81070187504741\n",
      "28th loss : -106.65810704012611\n",
      "29th loss : -99.5007217012643\n",
      "30th loss : -111.99617968696894\n",
      "31th loss : -113.82239010478051\n",
      "32th loss : -115.61738832421246\n",
      "33th loss : -116.38875326489021\n",
      "34th loss : -82.27414338962885\n",
      "35th loss : -117.69722999186014\n",
      "36th loss : -107.05554874267662\n",
      "37th loss : -105.63125685755271\n",
      "38th loss : -119.32126350817242\n",
      "39th loss : -104.4165309489107\n",
      "40th loss : -96.08834122907349\n",
      "41th loss : -89.5781039093059\n",
      "42th loss : -118.82692891144002\n",
      "43th loss : -110.6589586723261\n",
      "44th loss : -115.99221530241749\n",
      "45th loss : -108.0364329878416\n",
      "46th loss : -116.43478162883142\n",
      "47th loss : -110.24462790332645\n",
      "48th loss : -106.49177601247385\n",
      "49th loss : -116.8376231983538\n"
     ]
    }
   ],
   "source": [
    "H = len(structure) - 2\n",
    "learning_rate = 10\n",
    "epochs = 50\n",
    "all_epoch_errors = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    each_epoch_errors = []\n",
    "    sum_losses = 0\n",
    "\n",
    "    w_n = [np.random.randn(l, next_l) for l,next_l in zip(structure[:-1], structure[1:])] # (4,2), (2,3)\n",
    "    b_n = [np.random.randn(l, 1) for l in structure[1:]]  # (2,1), (3,1)   \n",
    "\n",
    "    \n",
    "    for k, (x, y) in enumerate(zip(data, one_hot_labels)):\n",
    "        z_n, a_n = [], []\n",
    "        \n",
    "        # np.random.seed(2023)\n",
    "        # w_n = [np.random.randn(l, next_l) for l,next_l in zip(structure[:-1], structure[1:])] # (4,2), (2,3)\n",
    "        # b_n = [np.random.randn(l, 1) for l in structure[1:]]  # (2,1), (3,1)\n",
    "        \n",
    "        for i, (b, w) in enumerate(zip(b_n, w_n)):\n",
    "            if i == 0:\n",
    "                z = np.dot(w.T, x).reshape(-1,1) + np.array(b)\n",
    "                a = sigmoid(z)                \n",
    "                \n",
    "            elif (i > 0) and (i < H):\n",
    "                z = np.dot(w.T, a)\n",
    "                a = sigmoid(z)\n",
    "            else:\n",
    "                z = np.dot(w.T, a)\n",
    "                a = softmax(z)\n",
    "            \n",
    "            \"\"\"    \n",
    "            print(z)\n",
    "            print(a)\n",
    "            print()\n",
    "            \"\"\"                \n",
    "            z_n.append(z)\n",
    "            a_n.append(a)\n",
    "        \n",
    "        #print(f\"{epoch}-{k}th softmax loss : {loss}\")\n",
    "        \n",
    "        # BackPropagate\n",
    "        # np.random.seed(2023)\n",
    "        e_je_w_ns = [np.zeros(w.shape) for w in w_n]\n",
    "        e_je_b_ns = [np.zeros(b.shape) for b in b_n]\n",
    "                \n",
    "        datapoint_errors = []\n",
    "        \n",
    "        for L in range(H, -1, -1):\n",
    "            if L != H:\n",
    "                delta = sigmoid_derivative(z_n[L]) * np.dot(w_n[L+1], delta)\n",
    "            else:\n",
    "                #print(y.reshape(-1,1).shape)\n",
    "                delta = a_n[L] - y.reshape(-1, 1)   # (3,1)                \n",
    "            e_je_b_ns[L] = delta\n",
    "            \n",
    "            if L != 0:\n",
    "                e_je_w_ns[L] = np.dot(a_n[L-1], delta.T)                \n",
    "                #print(f\"delta.T shape : {delta.T.shape}\")\n",
    "                #print(f\"a_n[L] shape : {a_n[L].shape}\")                \n",
    "            else:\n",
    "                #print(f\"x : {x.reshape(-1,1).shape}\")\n",
    "                #print(f\"delta : {delta.T.shape}\")\n",
    "                e_je_w_ns[L] = np.dot(x.reshape(-1,1), delta.T)   # (4,1), (1,2), (4,2)          \n",
    "        \"\"\"      \n",
    "        print(f\"{epoch}epoch {k}th data e_je_w_ns :\\n {e_je_w_ns}\")\n",
    "        print(f\"{epoch}epoch {k}th data e_je_b_ns :\\n {e_je_b_ns}\")\n",
    "        print()\n",
    "        \"\"\"\n",
    "        for i, (wn, ejew, bn, ejeb) in enumerate(zip(w_n, e_je_w_ns, b_n, e_je_b_ns)):\n",
    "            w_n[i] -= learning_rate/len(data) * ejew\n",
    "            b_n[i] -= learning_rate/len(data) * ejeb\n",
    "        \n",
    "        loss = calculate_loss(a_n[-1], y)\n",
    "        sum_losses += loss\n",
    "    print(f\"{epoch}th loss : {sum_losses}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 6.27374581],\n",
       "        [-6.78636791]]),\n",
       " array([[ 0.09834887],\n",
       "        [-3.11682648],\n",
       "        [-1.07497685]])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.99811839],\n",
       "        [0.00112779]]),\n",
       " array([[0.74102356],\n",
       "        [0.02975083],\n",
       "        [0.22922561]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1033476428641078 0.04429752467070435 0.34130565643548416\n",
      "0.7410235617601022 0.029750831227981552 0.22922560701191635\n"
     ]
    }
   ],
   "source": [
    "a0, a1, a2 = np.exp(0.09834887), np.exp(-3.11682648), np.exp(-1.07497685)\n",
    "a = a0 + a1 + a2\n",
    "print(a0, a1, a2)\n",
    "print(a0/a, a1/a, a2/a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74102356],\n",
       "       [0.02975083],\n",
       "       [0.22922561]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z_n[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
