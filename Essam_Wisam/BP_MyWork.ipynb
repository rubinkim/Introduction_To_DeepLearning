{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Don't forget W_n & B_n is of list where a set of numpy.array are contained."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "[0 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "indexes = [0, 52, 108, 49, 142, 88]\n",
    "\n",
    "data = data[indexes]\n",
    "target = target[indexes]\n",
    "\n",
    "print(data)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "Y = np.zeros((6, 3))\n",
    "for i in range(6):\n",
    "    for j in range(3):\n",
    "        Y[i, target[i]] = 1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "\n",
    "# Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "    if i == 0:\n",
    "        z = np.dot(np.array(W).T, X).reshape(-1, 1) + np.array(b)\n",
    "    else:\n",
    "        z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z_n.append(z)\n",
    "    A_n.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "H = len(structure) - 2\n",
    "\n",
    "for x, y in zip(X,Y):\n",
    "    # Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "    for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "        if i == 0:\n",
    "            z = np.dot(np.array(W).T, x).reshape(-1, 1) + np.array(b)\n",
    "        else:\n",
    "            z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        Z_n.append(z)\n",
    "        A_n.append(a)\n",
    "        \n",
    "    # Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer\n",
    "    e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "\n",
    "    # Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer\n",
    "    e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)\n",
    "    \n",
    "    for L in range(H, -1, -1):\n",
    "        if L != H:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "        else:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y.reshape(-1, 1))\n",
    "        e_Je_B_ns[L] = delta\n",
    "        # print(f\"{L} : {delta}\")\n",
    "        \n",
    "        if L != 0:\n",
    "            e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "        else:\n",
    "            e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.32640856e-04 -6.69606436e-03]\n",
      " [ 2.28282940e-04 -4.59533829e-03]\n",
      " [ 9.13131761e-05 -1.83813532e-03]\n",
      " [ 1.30447394e-05 -2.62590759e-04]\n",
      " [ 4.50043511e-04 -9.05938120e-03]\n",
      " [ 2.02193461e-04 -4.07015677e-03]\n",
      " [ 3.19596116e-04 -6.43347361e-03]\n",
      " [ 9.78355458e-05 -1.96943070e-03]\n",
      " [ 4.36998771e-04 -8.79679044e-03]\n",
      " [ 1.63059243e-04 -3.28238449e-03]\n",
      " [ 3.78297444e-04 -7.61513202e-03]\n",
      " [ 1.17402655e-04 -2.36331683e-03]\n",
      " [ 3.26118486e-04 -6.56476899e-03]\n",
      " [ 2.15238201e-04 -4.33274753e-03]\n",
      " [ 9.13131761e-05 -1.83813532e-03]\n",
      " [ 1.30447394e-05 -2.62590759e-04]\n",
      " [ 3.78297444e-04 -7.61513202e-03]\n",
      " [ 1.76103982e-04 -3.54497525e-03]\n",
      " [ 3.32640856e-04 -6.69606436e-03]\n",
      " [ 1.23925025e-04 -2.49461221e-03]\n",
      " [ 3.65252704e-04 -7.35254126e-03]\n",
      " [ 1.95671092e-04 -3.93886139e-03]\n",
      " [ 2.67417158e-04 -5.38311057e-03]\n",
      " [ 8.47908063e-05 -1.70683994e-03]]\n",
      "\n",
      "[[ 4.45316977e-05 -1.02837818e-05]\n",
      " [ 4.33761983e-02 -1.00169403e-02]]\n",
      "\n",
      "[[ 0.04947257 -0.00744208  0.00341264]\n",
      " [ 0.02044892 -0.0030761   0.00141058]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.84317054],\n",
       "       [  8.27689919]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(W_n[0].T, X).reshape(-1,1) + B_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "H = len(structure) - 2\n",
    "\n",
    "# Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "    if i == 0:\n",
    "        z = np.dot(np.array(W).T, X).reshape(-1, 1) + np.array(b)\n",
    "    else:\n",
    "        z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z_n.append(z)\n",
    "    A_n.append(a)\n",
    "    \n",
    "for L in range(H, -1, -1):\n",
    "    if L != H:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "    else:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y)\n",
    "    e_Je_B_ns[L] = delta\n",
    "    # print(f\"{L} : {delta}\")\n",
    "    \n",
    "    if L != 0:\n",
    "        e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "    else:\n",
    "        e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.8432]\n",
      " [  8.2769]]\n",
      "[[0.    ]\n",
      " [0.9997]]\n",
      "\n",
      "[[-0.3957]\n",
      " [-1.601 ]]\n",
      "[[0.4023]\n",
      " [0.1678]]\n",
      "\n",
      "[[-0.0515]\n",
      " [ 1.7646]\n",
      " [-2.2383]]\n",
      "[[0.4871]\n",
      " [0.8538]\n",
      " [0.0964]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z, a in zip(Z_n, A_n):\n",
    "    print(np.round(z, 4))\n",
    "    print(np.round(a, 4))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer in the network.\n",
    "e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "\n",
    "# Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer in the network.\n",
    "e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [0]]),\n",
       " array([[0.48713827],\n",
       "        [0.85378893],\n",
       "        [0.0963659 ]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, A_n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18944364],\n",
       "       [-0.07477456]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(W_n[2], sigmoid_derivative(Z_n[2]) * (A_n[2] - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = len(structure) - 2\n",
    "\n",
    "for L in range(H, -1, -1):\n",
    "    if L != H:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "    else:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y)\n",
    "    e_Je_B_ns[L] = delta\n",
    "    # print(f\"{L} : {delta}\")\n",
    "    \n",
    "    if L != 0:\n",
    "        e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "    else:\n",
    "        e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "for W, e_Je_W, B, e_Je_B in zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns):\n",
    "    W -= learning_rate * e_Je_W\n",
    "    B -= learning_rate * e_Je_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W의 shape : (4, 2),    e_Je_W의 shape : (4, 2)\n",
      "W의 shape : (2, 2),    e_Je_W의 shape : (2, 2)\n",
      "W의 shape : (2, 3),    e_Je_W의 shape : (2, 3)\n",
      "\n",
      "B의 shape : (2, 1),     e_Je_B의 shape : (2, 1)\n",
      "B의 shape : (2, 1),     e_Je_B의 shape : (2, 1)\n",
      "B의 shape : (3, 1),     e_Je_B의 shape : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "for W, e_Je_W in zip(W_n, e_Je_W_ns):\n",
    "    print(f\"W의 shape : {W.shape},    e_Je_W의 shape : {e_Je_W.shape}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for B, e_Je_B in zip(B_n, e_Je_B_ns):\n",
    "    print(f\"B의 shape : {B.shape},     e_Je_B의 shape : {e_Je_B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.79546853e-07]\n",
      " [-7.60981914e-06]]\n",
      "\n",
      "[[ 0.04555408]\n",
      " [-0.01044394]]\n",
      "\n",
      "[[ 0.12170398]\n",
      " [-0.01825202]\n",
      " [ 0.0083915 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_B_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
