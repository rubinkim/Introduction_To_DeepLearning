{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[0 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "indexes = [0, 52, 108, 49, 142, 88]\n",
    "\n",
    "data = data[indexes]\n",
    "target = target[indexes]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "Y = np.zeros((6, 3))\n",
    "for i in range(len(Y)):\n",
    "    for j in range(len(Y[i])):\n",
    "        Y[i, target[i]] = 1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# X is a np.ndarray with shape (6,4)\n",
    "# Y is a np.ndarray with shape (6,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[-5.87872410e-04  8.66681145e-03]\n",
      " [-4.03441850e-04  5.94781178e-03]\n",
      " [-1.61376740e-04  2.37912471e-03]\n",
      " [-2.30538200e-05  3.39874959e-04]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[-0.00011527]\n",
      " [ 0.00169937]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[-6.21037426e-05  4.24149591e-05]\n",
      " [-6.04920568e-02  4.13142269e-02]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[-0.06339147]\n",
      " [ 0.04329444]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[-0.05226762  0.04380252  0.00342724]\n",
      " [-0.02145442  0.01797973  0.00140679]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[-0.12745576]\n",
      " [ 0.10681343]\n",
      " [ 0.0083574 ]]\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[ 3.21524798e-07 -4.85530138e-06]\n",
      " [ 1.44453170e-07 -2.18136729e-06]\n",
      " [ 2.28329204e-07 -3.44796765e-06]\n",
      " [ 6.98966952e-08 -1.05550030e-06]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[ 4.65977968e-08]\n",
      " [-7.03666866e-07]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[ 3.18149726e-08 -7.29411251e-09]\n",
      " [ 4.55500704e-02 -1.04431125e-02]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[ 0.04555114]\n",
      " [-0.01044336]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[ 0.04895998 -0.00734256  0.00337597]\n",
      " [ 0.02042635 -0.00306335  0.00140847]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[ 0.12170017]\n",
      " [-0.01825144]\n",
      " [ 0.00839168]]\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[ 6.18229747e-08 -4.87869117e-07]\n",
      " [ 2.30682742e-08 -1.82040715e-07]\n",
      " [ 5.35183960e-08 -4.22334459e-07]\n",
      " [ 1.66091574e-08 -1.31069315e-07]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[ 9.22730966e-09]\n",
      " [-7.28162861e-08]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[7.49326696e-09 2.98459311e-10]\n",
      " [3.56698231e-02 1.42074090e-03]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[0.03566993]\n",
      " [0.00142075]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[ 0.04895942  0.04287678 -0.03165622]\n",
      " [ 0.02042627  0.01788854 -0.01320724]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[ 0.12169984]\n",
      " [ 0.10658004]\n",
      " [-0.07868878]]\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[-6.06742040e-04  7.06074810e-03]\n",
      " [-4.00449746e-04  4.66009375e-03]\n",
      " [-1.69887771e-04  1.97700947e-03]\n",
      " [-2.42696816e-05  2.82429924e-04]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[-0.00012135]\n",
      " [ 0.00141215]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[-6.53863271e-05  4.46487012e-05]\n",
      " [-6.09763989e-02  4.16374054e-02]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[-0.0633656 ]\n",
      " [ 0.04326886]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[-0.0521479   0.04364911  0.00341829]\n",
      " [-0.0214591   0.01796181  0.00140664]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[-0.12756907]\n",
      " [ 0.10677853]\n",
      " [ 0.00836215]]\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[ 1.76981883e-07 -4.64484191e-06]\n",
      " [ 8.23881179e-08 -2.16225399e-06]\n",
      " [ 1.55622001e-07 -4.08425754e-06]\n",
      " [ 5.79768237e-08 -1.52158614e-06]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[ 3.05141178e-08]\n",
      " [-8.00834812e-07]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[2.47797784e-08 9.87009508e-10]\n",
      " [3.56690436e-02 1.42074253e-03]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[0.03567022]\n",
      " [0.00142079]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[ 0.04896023  0.04287738 -0.03165659]\n",
      " [ 0.02042639  0.0178886  -0.01320725]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[ 0.12170032]\n",
      " [ 0.10658019]\n",
      " [-0.0786887 ]]\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "[[ 4.79546853e-07]\n",
      " [-7.60981914e-06]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "[[ 0.04555408]\n",
      " [-0.01044394]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "[[ 0.12170398]\n",
      " [-0.01825202]\n",
      " [ 0.0083915 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.1\n",
    "\n",
    "for x, y in zip(X, Y):     # x의 shape:(4,),  y의 shape:(3,)\n",
    "    \n",
    "    # Forward Propagate\n",
    "    # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "    Z_n, A_n = [], []\n",
    "    \n",
    "    for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "        if i == 0:\n",
    "            z = np.dot(np.array(W).T, x).reshape(-1, 1) + np.array(b)\n",
    "        else:\n",
    "            z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        Z_n.append(z)\n",
    "        A_n.append(a)\n",
    "    # print(Z_n) \n",
    "    # print()  \n",
    "    \n",
    "    \n",
    "    # Backpropagate\n",
    "    # Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer\n",
    "    e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "    #for x in e_Je_W_ns:\n",
    "    #    print(x.shape)\n",
    "    #print()\n",
    "\n",
    "    # Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer\n",
    "    e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)\n",
    "    \n",
    "    for L in range(H, -1, -1):\n",
    "        if L != H:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "        else:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y.reshape(-1, 1))\n",
    "            \n",
    "        e_Je_B_ns[L] = delta\n",
    "        # print(f\"{L} : {delta}\")\n",
    "        \n",
    "        if L != 0:\n",
    "            e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "        else:\n",
    "            e_Je_W_ns[L] = np.dot(x.reshape(-1, 1), delta.T)\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in e_Je_W_ns:\n",
    "        print(x)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "        #W_n[i] -= learning_rate/len(X) * ejew\n",
    "        #B_n[i] -= learning_rate/len(X) * ejeb\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48835056, -0.64420125, -0.44232442],\n",
       "       [-0.43563446,  2.20374093,  2.18747708]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in W_n:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-1.0856306   0.99734545]\n",
    " [ 0.2829785  -1.50629471]\n",
    " [-0.57860025  1.65143654]\n",
    " [-2.42667924 -0.42891263]]\n",
    "\n",
    "[[ 1.26593626 -0.8667404 ]\n",
    " [-0.67888615 -0.09470897]]\n",
    "\n",
    "[[ 1.49138963 -0.638902   -0.44398196]\n",
    " [-0.43435128  2.20593008  2.18678609]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
