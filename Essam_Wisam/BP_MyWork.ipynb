{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[0 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "indexes = [0, 52, 108, 49, 142, 88]\n",
    "\n",
    "data = data[indexes]\n",
    "target = target[indexes]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "Y = np.zeros((6, 3))\n",
    "for i in range(len(Y)):\n",
    "    for j in range(len(Y[i])):\n",
    "        Y[i, target[i]] = 1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_n의 타입은 <class 'list'>이다.\n",
      "W_n의 타입은 <class 'list'>이다.\n",
      "X의 타입은 <class 'numpy.ndarray'>이다.\n",
      "Y의 타입은 <class 'numpy.ndarray'>이다.\n"
     ]
    }
   ],
   "source": [
    "# Don't forget W_n & B_n is of list where a set of numpy.array are contained.<br>\n",
    "# B_n has 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n has 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "for name, object in zip(['B_n','W_n','X','Y'], [B_n, W_n, X, Y]):\n",
    "    print(f\"{name}의 타입은 {type(object)}이다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (3,)\n",
      "(4,) (3,)\n",
      "(4,) (3,)\n",
      "(4,) (3,)\n",
      "(4,) (3,)\n",
      "(4,) (3,)\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "\n",
    "for x, y in zip(X, Y):     # x의 shape:(4,),  y의 shape:(3,)\n",
    "    \n",
    "    # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "    Z_n, A_n = [], []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,4) and (6,4) not aligned: 4 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_MyWork.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (b, W) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(B_n, W_n)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(np\u001b[39m.\u001b[39;49marray(W)\u001b[39m.\u001b[39;49mT, X)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39marray(b)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         z \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39marray(W)\u001b[39m.\u001b[39mT, a)\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39marray(b)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,4) and (6,4) not aligned: 4 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "\n",
    "# Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "    if i == 0:\n",
    "        z = np.dot(np.array(W).T, X).reshape(-1, 1) + np.array(b)\n",
    "    else:\n",
    "        z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z_n.append(z)\n",
    "    A_n.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "H = len(structure) - 2\n",
    "\n",
    "for x, y in zip(X,Y):\n",
    "    \n",
    "    Z_n, A_n = [], []\n",
    "    # Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "    for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "        if i == 0:\n",
    "            z = np.dot(np.array(W).T, x).reshape(-1, 1) + np.array(b)\n",
    "        else:\n",
    "            z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        Z_n.append(z)\n",
    "        A_n.append(a)\n",
    "        \n",
    "    # Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer\n",
    "    e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "\n",
    "    # Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer\n",
    "    e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)\n",
    "    \n",
    "    for L in range(H, -1, -1):\n",
    "        if L != H:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "        else:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y.reshape(-1, 1))\n",
    "        e_Je_B_ns[L] = delta\n",
    "        # print(f\"{L} : {delta}\")\n",
    "        \n",
    "        if L != 0:\n",
    "            e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "        else:\n",
    "            e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in W_n:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.44568895e-06, -3.88100776e-05],\n",
       "        [ 1.67841398e-06, -2.66343670e-05],\n",
       "        [ 6.71365594e-07, -1.06537468e-05],\n",
       "        [ 9.59093705e-08, -1.52196383e-06],\n",
       "        [ 3.30887328e-06, -5.25077520e-05],\n",
       "        [ 1.48659524e-06, -2.35904393e-05],\n",
       "        [ 2.34977958e-06, -3.72881138e-05],\n",
       "        [ 7.19320279e-07, -1.14147287e-05],\n",
       "        [ 3.21296391e-06, -5.09857882e-05],\n",
       "        [ 1.19886713e-06, -1.90245478e-05],\n",
       "        [ 2.78137175e-06, -4.41369510e-05],\n",
       "        [ 8.63184335e-07, -1.36976744e-05],\n",
       "        [ 2.39773426e-06, -3.80490957e-05],\n",
       "        [ 1.58250461e-06, -2.51124031e-05],\n",
       "        [ 6.71365594e-07, -1.06537468e-05],\n",
       "        [ 9.59093705e-08, -1.52196383e-06],\n",
       "        [ 2.78137175e-06, -4.41369510e-05],\n",
       "        [ 1.29477650e-06, -2.05465117e-05],\n",
       "        [ 2.44568895e-06, -3.88100776e-05],\n",
       "        [ 9.11139020e-07, -1.44586564e-05],\n",
       "        [ 2.68546237e-06, -4.26149872e-05],\n",
       "        [ 1.43864056e-06, -2.28294574e-05],\n",
       "        [ 1.96614210e-06, -3.12002585e-05],\n",
       "        [ 6.23410908e-07, -9.89276488e-06]]),\n",
       " array([[ 3.27416513e-07, -7.50649946e-08],\n",
       "        [ 4.55425009e-02, -1.04412803e-02]]),\n",
       " array([[ 0.04896634, -0.00734351,  0.00337623],\n",
       "        [ 0.02042727, -0.00306349,  0.00140846]])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_Je_W_ns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.84317054],\n",
       "       [  8.27689919]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(W_n[0].T, X).reshape(-1,1) + B_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "H = len(structure) - 2\n",
    "\n",
    "# Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "    if i == 0:\n",
    "        z = np.dot(np.array(W).T, X).reshape(-1, 1) + np.array(b)\n",
    "    else:\n",
    "        z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "    a = sigmoid(z)\n",
    "\n",
    "    Z_n.append(z)\n",
    "    A_n.append(a)\n",
    "    \n",
    "for L in range(H, -1, -1):\n",
    "    if L != H:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "    else:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y)\n",
    "    e_Je_B_ns[L] = delta\n",
    "    # print(f\"{L} : {delta}\")\n",
    "    \n",
    "    if L != 0:\n",
    "        e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "    else:\n",
    "        e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-11.8432]\n",
      " [  8.2769]]\n",
      "[[0.    ]\n",
      " [0.9997]]\n",
      "\n",
      "[[-0.3957]\n",
      " [-1.601 ]]\n",
      "[[0.4023]\n",
      " [0.1678]]\n",
      "\n",
      "[[-0.0515]\n",
      " [ 1.7646]\n",
      " [-2.2383]]\n",
      "[[0.4871]\n",
      " [0.8538]\n",
      " [0.0964]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z, a in zip(Z_n, A_n):\n",
    "    print(np.round(z, 4))\n",
    "    print(np.round(a, 4))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Backpropagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer in the network.\n",
    "e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "\n",
    "# Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer in the network.\n",
    "e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0],\n",
       "        [1],\n",
       "        [0]]),\n",
       " array([[0.48713827],\n",
       "        [0.85378893],\n",
       "        [0.0963659 ]]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, A_n[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18944364],\n",
       "       [-0.07477456]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(W_n[2], sigmoid_derivative(Z_n[2]) * (A_n[2] - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = len(structure) - 2\n",
    "\n",
    "for L in range(H, -1, -1):\n",
    "    if L != H:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "    else:\n",
    "        delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y)\n",
    "    e_Je_B_ns[L] = delta\n",
    "    # print(f\"{L} : {delta}\")\n",
    "    \n",
    "    if L != 0:\n",
    "        e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "    else:\n",
    "        e_Je_W_ns[L] = np.dot(X.reshape(-1, 1), delta.T)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implement Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "\n",
    "for W, e_Je_W, B, e_Je_B in zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns):\n",
    "    W -= learning_rate * e_Je_W\n",
    "    B -= learning_rate * e_Je_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W의 shape : (4, 2),    e_Je_W의 shape : (4, 2)\n",
      "W의 shape : (2, 2),    e_Je_W의 shape : (2, 2)\n",
      "W의 shape : (2, 3),    e_Je_W의 shape : (2, 3)\n",
      "\n",
      "B의 shape : (2, 1),     e_Je_B의 shape : (2, 1)\n",
      "B의 shape : (2, 1),     e_Je_B의 shape : (2, 1)\n",
      "B의 shape : (3, 1),     e_Je_B의 shape : (3, 1)\n"
     ]
    }
   ],
   "source": [
    "for W, e_Je_W in zip(W_n, e_Je_W_ns):\n",
    "    print(f\"W의 shape : {W.shape},    e_Je_W의 shape : {e_Je_W.shape}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for B, e_Je_B in zip(B_n, e_Je_B_ns):\n",
    "    print(f\"B의 shape : {B.shape},     e_Je_B의 shape : {e_Je_B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.79546853e-07]\n",
      " [-7.60981914e-06]]\n",
      "\n",
      "[[ 0.04555408]\n",
      " [-0.01044394]]\n",
      "\n",
      "[[ 0.12170398]\n",
      " [-0.01825202]\n",
      " [ 0.0083915 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_B_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
