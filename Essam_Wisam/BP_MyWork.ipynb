{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Enter the number of layers of your network\n",
    "num_layers = int(input(\"Enter the number of layers : \"))\n",
    "\n",
    "# Enter the number of neurons of your network\n",
    "split_int = lambda x : int(x.split(' '))\n",
    "num_neurons = input(\"Enter the number of neurons of each layer in your network\")\n",
    "\n",
    "split_int(num_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[ 2.60503775]\n",
      " [-0.75451092]\n",
      " [-0.90028959]\n",
      " [ 1.42270438]\n",
      " [-0.41890072]]\n",
      "\n",
      "[[-0.88314158]\n",
      " [ 1.96014907]\n",
      " [ 0.98873152]]\n",
      "\n",
      "weight matrix of each layer\n",
      "\n",
      "[[-0.96712273 -0.7144127   0.58876549 -0.78371523  1.10158183]\n",
      " [-1.46924907 -0.03249069 -0.10695256  1.71057386  2.76915119]]\n",
      "\n",
      "[[ 0.78366542  0.96512507 -0.37425481]\n",
      " [ 0.8323296   0.2885378   0.50221212]\n",
      " [-1.65778657 -1.22604899  0.18092286]\n",
      " [-1.43416146 -0.08564885 -0.36229425]\n",
      " [ 0.48930521 -1.68884624  1.26006031]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rubin\\AppData\\Local\\Temp\\ipykernel_41980\\2924603932.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  B_n = np.array(B_n)\n",
      "C:\\Users\\rubin\\AppData\\Local\\Temp\\ipykernel_41980\\2924603932.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  w_n = np.array(W_n)\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "B_n = np.array(B_n)\n",
    "\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()\n",
    "\n",
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "w_n = np.array(W_n)\n",
    "\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([4, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "Z_n, A_n = [], []\n",
    "\n",
    "# Forward pass layer by layer from L=0(First hidden layer) thru L=H(Output layer)\n",
    "for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "    if i == 0:\n",
    "        z = np.dot(W.T, x) + b\n",
    "    else:\n",
    "        z = np.dot(W.T, a)\n",
    "    a = sigmoid(z)\n",
    "    \n",
    "    Z_n.append(z)\n",
    "    A_n.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.59716928, -1.62108939, -0.22605826,  0.3382741 , -2.54043146],\n",
      "       [ 0.88824668, -0.11187268, -0.72703204, -2.72262173,  0.07305009]]), array([[ 0.85730031, -0.56459314, -0.28259055],\n",
      "       [ 0.9084166 , -1.4537277 ,  0.09349522],\n",
      "       [-0.55943577,  1.34928798, -0.24278885],\n",
      "       [-0.63823328, -0.03144898,  0.80522977],\n",
      "       [-0.11595886, -0.389975  , -0.06478941]])]\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'T'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\Essam_Wisam\\BP_MyWork.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(W_n)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/Essam_Wisam/BP_MyWork.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(W_n\u001b[39m.\u001b[39;49mT)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'T'"
     ]
    }
   ],
   "source": [
    "print(W_n)\n",
    "print()\n",
    "print(W_n.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.28437601  -9.58949415  -8.31548516 -20.02728356 -11.97240304]\n",
      " [  8.5573902   -7.31647996  -6.04247097 -17.75426937  -9.69938885]\n",
      " [  8.83227965  -7.04159051  -5.76758151 -17.47937991  -9.4244994 ]\n",
      " [  8.31323346  -7.5606367   -6.28662771 -17.99842611  -9.94354559]\n",
      " [  9.62379728  -6.25007287  -4.97606388 -16.68786228  -8.63298177]] [[9.98138252e-01 6.84393509e-05 2.44638285e-04 2.00567824e-09\n",
      "  6.31609538e-06]\n",
      " [9.99807917e-01 6.64055892e-04 2.37005093e-03 1.94723683e-08\n",
      "  6.13171996e-05]\n",
      " [9.99854076e-01 8.73969694e-04 3.11756215e-03 2.56331362e-08\n",
      "  8.07154850e-05]\n",
      " [9.99754810e-01 5.20272884e-04 1.85756832e-03 1.52539687e-08\n",
      "  4.80343764e-05]\n",
      " [9.99933868e-01 1.92659453e-03 6.85387323e-03 5.65657398e-08\n",
      "  1.78100976e-04]]\n",
      "\n",
      "[[ 4.50564223e-01 -3.82478611e-04 -1.36168294e-03 -1.12264913e-08\n",
      "  -3.53483008e-05]\n",
      " [-1.08928987e+00 -5.92445791e-04 -2.10829853e-03 -1.73923771e-08\n",
      "  -5.47616633e-05]\n",
      " [ 3.08906625e-01  1.24671941e-04  4.47257572e-04  3.64843704e-09\n",
      "   1.14908298e-05]] [[0.61077337 0.49990438 0.49965958 0.5        0.49999116]\n",
      " [0.25175202 0.49985189 0.49947293 0.5        0.49998631]\n",
      " [0.57661836 0.50003117 0.50011181 0.5        0.50000287]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z, a in zip(Z_n, A_n):\n",
    "    print(z, a)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
