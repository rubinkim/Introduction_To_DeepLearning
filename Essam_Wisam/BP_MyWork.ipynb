{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[0 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "indexes = [0, 52, 108, 49, 142, 88]\n",
    "\n",
    "data = data[indexes]\n",
    "target = target[indexes]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "Y = np.zeros((6, 3))\n",
    "for i in range(len(Y)):\n",
    "    for j in range(len(Y[i])):\n",
    "        Y[i, target[i]] = 1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# X is a np.ndarray with shape (6,4)\n",
    "# Y is a np.ndarray with shape (6,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Loss\n",
    "def calculate_loss(actual, expected):\n",
    "    diff = np.sum(np.sqrt((actual.reshape(-1) - expected) * (actual.reshape(-1) - expected)))\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.3 -0.2  0.1]\n",
      "[0.09 0.04 0.01]\n",
      "[0.3 0.2 0.1]\n",
      "0.6\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[0.3],[0.8],[0.1]])\n",
    "y = [0, 1, 0]\n",
    "\n",
    "#print(calculate_loss(a, y))\n",
    "print((a.reshape(-1) - y)) \n",
    "print((a.reshape(-1) - y) * (a.reshape(-1) - y)) \n",
    "print(np.sqrt((a.reshape(-1) - y) * (a.reshape(-1) - y)))\n",
    "print(np.sum(np.sqrt((a.reshape(-1) - y) * (a.reshape(-1) - y))))\n",
    "\n",
    "print(calculate_loss(a, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_loss(a, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.08465082  0.98290076]\n",
      " [ 0.2836509  -1.51620773]\n",
      " [-0.57833129  1.64747133]\n",
      " [-2.42664082 -0.42947909]]\n",
      "[[-5.87872410e-04  8.66681145e-03]\n",
      " [-4.03441850e-04  5.94781178e-03]\n",
      " [-1.61376740e-04  2.37912471e-03]\n",
      " [-2.30538200e-05  3.39874959e-04]]\n",
      "[[-1.08543849]\n",
      " [ 0.99451316]]\n",
      "[[-0.00011527]\n",
      " [ 0.00169937]]\n",
      "\n",
      "[[ 1.26603976 -0.86681109]\n",
      " [-0.57806606 -0.16356601]]\n",
      "[[-6.21037426e-05  4.24149591e-05]\n",
      " [-6.04920568e-02  4.13142269e-02]]\n",
      "[[ 0.38863094]\n",
      " [-1.57845211]]\n",
      "[[-0.06339147]\n",
      " [ 0.04329444]]\n",
      "\n",
      "[[ 1.57850233 -0.7119062  -0.44969403]\n",
      " [-0.39859391  2.17596387  2.18444144]]\n",
      "[[-0.05226762  0.04380252  0.00342724]\n",
      " [-0.02145442  0.01797973  0.00140679]]\n",
      "[[-0.36617398]\n",
      " [ 1.47341416]\n",
      " [-2.44060825]]\n",
      "[[-0.12745576]\n",
      " [ 0.10681343]\n",
      " [ 0.0083574 ]]\n",
      "\n",
      "[[-1.08465151  0.98291083]\n",
      " [ 0.28365059 -1.51620321]\n",
      " [-0.57833178  1.64747848]\n",
      " [-2.42664097 -0.4294769 ]]\n",
      "[[ 4.17393938e-07 -6.04316926e-06]\n",
      " [ 1.87524813e-07 -2.71504706e-06]\n",
      " [ 2.96410188e-07 -4.29152600e-06]\n",
      " [ 9.07378126e-08 -1.31373245e-06]]\n",
      "[[-1.08543859]\n",
      " [ 0.99451461]]\n",
      "[[ 6.04918751e-08]\n",
      " [-8.75821632e-07]]\n",
      "\n",
      "[[ 1.2660397  -0.86681108]\n",
      " [-0.67625286 -0.14217561]]\n",
      "[[ 4.15786823e-08 -9.05808969e-09]\n",
      " [ 5.89120828e-02 -1.28342434e-02]]\n",
      "[[ 0.29044145]\n",
      " [-1.55706112]]\n",
      "[[ 0.0589137]\n",
      " [-0.0128346]]\n",
      "\n",
      "[[ 1.47285232 -0.6906301  -0.45520876]\n",
      " [-0.43337388  2.18296796  2.18262599]]\n",
      "[[ 0.06339001 -0.01276566  0.00330884]\n",
      " [ 0.02086798 -0.00420245  0.00108927]]\n",
      "[[-0.59950694]\n",
      " [ 1.52040342]\n",
      " [-2.45278779]]\n",
      "[[ 0.13999978]\n",
      " [-0.02819356]\n",
      " [ 0.00730772]]\n",
      "\n",
      "[[-1.0846516   0.98291169]\n",
      " [ 0.28365056 -1.51620289]\n",
      " [-0.57833186  1.64747922]\n",
      " [-2.42664099 -0.42947667]]\n",
      "[[ 5.01484156e-08 -5.11405080e-07]\n",
      " [ 1.87120954e-08 -1.90822791e-07]\n",
      " [ 4.34120612e-08 -4.42708875e-07]\n",
      " [ 1.34727087e-08 -1.37392409e-07]]\n",
      "[[-1.0854386 ]\n",
      " [ 0.99451474]]\n",
      "[[ 7.48483814e-09]\n",
      " [-7.63291164e-08]]\n",
      "\n",
      "[[ 1.26603968 -0.86681108]\n",
      " [-0.72865792 -0.15089533]]\n",
      "[[6.67210846e-09 1.11017782e-09]\n",
      " [3.14430336e-02 5.23183318e-03]]\n",
      "[[ 0.23803621]\n",
      " [-1.56578087]]\n",
      "[[0.03144314]\n",
      " [0.00523185]]\n",
      "\n",
      "[[ 1.39160125 -0.76991135 -0.40442156]\n",
      " [-0.46440365  2.15269046  2.20202161]]\n",
      "[[ 0.04875064  0.04756875 -0.03047232]\n",
      " [ 0.01861786  0.0181665  -0.01163737]]\n",
      "[[-0.80026237]\n",
      " [ 1.32451502]\n",
      " [-2.3273026 ]]\n",
      "[[ 0.12045326]\n",
      " [ 0.11753304]\n",
      " [-0.07529111]]\n",
      "\n",
      "[[-1.0835132   0.96785969]\n",
      " [ 0.2844019  -1.52613721]\n",
      " [-0.57801311  1.64326466]\n",
      " [-2.42659546 -0.43007875]]\n",
      "[[-6.83036779e-04  9.03119827e-03]\n",
      " [-4.50804274e-04  5.96059086e-03]\n",
      " [-1.91250298e-04  2.52873551e-03]\n",
      " [-2.73214712e-05  3.61247931e-04]]\n",
      "[[-1.08521092]\n",
      " [ 0.99150434]]\n",
      "[[-0.00013661]\n",
      " [ 0.00180624]]\n",
      "\n",
      "[[ 1.26616339 -0.86689333]\n",
      " [-0.61469249 -0.22667102]]\n",
      "[[-7.42242846e-05  4.93517738e-05]\n",
      " [-6.83792591e-02  4.54654127e-02]]\n",
      "[[ 0.35700303]\n",
      " [-1.64488198]]\n",
      "[[-0.07138009]\n",
      " [ 0.04746067]]\n",
      "\n",
      "[[ 1.48302714 -0.85353406 -0.41074652]\n",
      " [-0.42828572  2.11965519  2.19952293]]\n",
      "[[-0.05485554  0.05017362  0.00379497]\n",
      " [-0.02167076  0.01982116  0.00149921]]\n",
      "[[-0.56420324]\n",
      " [ 1.10860352]\n",
      " [-2.34363346]]\n",
      "[[-0.14163547]\n",
      " [ 0.1295469 ]\n",
      " [ 0.00979852]]\n",
      "\n",
      "[[-1.08351336  0.96786671]\n",
      " [ 0.28440182 -1.52613394]\n",
      " [-0.57801325  1.64327083]\n",
      " [-2.42659551 -0.43007645]]\n",
      "[[ 9.44420243e-08 -4.21100886e-06]\n",
      " [ 4.39643906e-08 -1.96029723e-06]\n",
      " [ 8.30438489e-08 -3.70278365e-06]\n",
      " [ 3.09379045e-08 -1.37946842e-06]]\n",
      "[[-1.08521095]\n",
      " [ 0.99150555]]\n",
      "[[ 1.62831076e-08]\n",
      " [-7.26036010e-07]]\n",
      "\n",
      "[[ 1.26616336 -0.86689334]\n",
      " [-0.65485129 -0.24114294]]\n",
      "[[1.70724953e-08 6.15237095e-09]\n",
      " [2.40952846e-02 8.68315537e-03]]\n",
      "[[ 0.31684249]\n",
      " [-1.65935454]]\n",
      "[[0.02409633]\n",
      " [0.00868353]]\n",
      "\n",
      "[[ 1.39107747 -0.95756877 -0.35321177]\n",
      " [-0.45641515  2.08782868  2.21712407]]\n",
      "[[ 0.0551698   0.06242083 -0.03452084]\n",
      " [ 0.01687766  0.01909591 -0.01056069]]\n",
      "[[-0.77512672]\n",
      " [ 0.86995815]\n",
      " [-2.21165444]]\n",
      "[[ 0.12655409]\n",
      " [ 0.14318722]\n",
      " [-0.07918741]]\n",
      "\n",
      "[[-1.08351899  0.96795702]\n",
      " [ 0.28439881 -1.52608556]\n",
      " [-0.57801736  1.64333696]\n",
      " [-2.42659682 -0.43005548]]\n",
      "[[ 3.37625647e-06 -5.41897248e-05]\n",
      " [ 1.80870883e-06 -2.90302097e-05]\n",
      " [ 2.47190206e-06 -3.96746199e-05]\n",
      " [ 7.83773824e-07 -1.25797575e-05]]\n",
      "[[-1.08521195]\n",
      " [ 0.99152168]]\n",
      "[[ 6.02902942e-07]\n",
      " [-9.67673657e-06]]\n",
      "\n",
      "[[ 1.26616273 -0.86689311]\n",
      " [-0.74103299 -0.20884277]]\n",
      "[[ 3.78932554e-07 -1.42020749e-07]\n",
      " [ 5.17090164e-02 -1.93801064e-02]]\n",
      "[[ 0.23063221]\n",
      " [-1.62704365]]\n",
      "[[ 0.05172617]\n",
      " [-0.01938653]]\n",
      "\n",
      "[[ 1.31657222 -0.9086986  -0.36094287]\n",
      " [-0.47968939  2.10309494  2.214709  ]]\n",
      "[[ 0.04470315 -0.0293221   0.00463866]\n",
      " [ 0.01396455 -0.00915975  0.00144904]]\n",
      "[[-0.95407608]\n",
      " [ 0.98733626]\n",
      " [-2.23022326]]\n",
      "[[ 0.10736962]\n",
      " [-0.07042686]\n",
      " [ 0.01114129]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 10\n",
    "\n",
    "for x, y in zip(X, Y):     # x의 shape:(4,),  y의 shape:(3,)\n",
    "    \n",
    "    # Forward Propagate\n",
    "    # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "    Z_n, A_n = [], []\n",
    "    \n",
    "    for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "        if i == 0:\n",
    "            z = np.dot(np.array(W).T, x).reshape(-1, 1) + np.array(b)\n",
    "        else:\n",
    "            z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        Z_n.append(z)\n",
    "        A_n.append(a)\n",
    "    # print(Z_n) \n",
    "    # print()  \n",
    "    \n",
    "    \n",
    "    # Backpropagate\n",
    "    # Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer\n",
    "    e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "    #for x in e_Je_W_ns:\n",
    "    #    print(x.shape)\n",
    "    #print()\n",
    "\n",
    "    # Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer\n",
    "    e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)\n",
    "    \n",
    "    for L in range(H, -1, -1):\n",
    "        if L != H:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "        else:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y.reshape(-1, 1))\n",
    "            \n",
    "        e_Je_B_ns[L] = delta\n",
    "        # print(f\"{L} : {delta}\")\n",
    "        \n",
    "        if L != 0:\n",
    "            e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "        else:\n",
    "            e_Je_W_ns[L] = np.dot(x.reshape(-1, 1), delta.T)\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in e_Je_W_ns:\n",
    "        print(x)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "        W_n[i] -= learning_rate/len(X) * ejew\n",
    "        B_n[i] -= learning_rate/len(X) * ejeb\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print(bn)\n",
    "        print(ejeb)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.49138963, -0.638902  , -0.44398196],\n",
       "       [-0.43435128,  2.20593008,  2.18678609]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.08351899  0.96795702]\n",
      " [ 0.28439881 -1.52608556]\n",
      " [-0.57801736  1.64333696]\n",
      " [-2.42659682 -0.43005548]]\n",
      "\n",
      "[[ 1.26616273 -0.86689311]\n",
      " [-0.74103299 -0.20884277]]\n",
      "\n",
      "[[ 1.31657222 -0.9086986  -0.36094287]\n",
      " [-0.47968939  2.10309494  2.214709  ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in W_n:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-1.0856306   0.99734545]\n",
    " [ 0.2829785  -1.50629471]\n",
    " [-0.57860025  1.65143654]\n",
    " [-2.42667924 -0.42891263]]\n",
    "\n",
    "[[ 1.26593626 -0.8667404 ]\n",
    " [-0.67888615 -0.09470897]]\n",
    "\n",
    "[[ 1.49138963 -0.638902   -0.44398196]\n",
    " [-0.43435128  2.20593008  2.18678609]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
