{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 2, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains the number of neurons of each layer in your network.\n",
    "structure = input(\"Enter the number of neurons of each layer in your network\").split(' ')\n",
    "structure = [int(x) for x in structure]\n",
    "print(structure)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bias vector of each layer\n",
      "\n",
      "[[-1.0856306 ]\n",
      " [ 0.99734545]]\n",
      "\n",
      "[[ 0.2829785 ]\n",
      " [-1.50629471]]\n",
      "\n",
      "[[-0.57860025]\n",
      " [ 1.65143654]\n",
      " [-2.42667924]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the bias vectors of your network(_n means it has all vectors)\n",
    "np.random.seed(123)\n",
    "B_n = [np.random.randn(l, 1) for l in structure[1:]]\n",
    "print(\"bias vector of each layer\\n\")\n",
    "for B in B_n:\n",
    "    print(B)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight matrix of each layer\n",
      "\n",
      "[[-1.0856306   0.99734545]\n",
      " [ 0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654]\n",
      " [-2.42667924 -0.42891263]]\n",
      "\n",
      "[[ 1.26593626 -0.8667404 ]\n",
      " [-0.67888615 -0.09470897]]\n",
      "\n",
      "[[ 1.49138963 -0.638902   -0.44398196]\n",
      " [-0.43435128  2.20593008  2.18678609]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Construct a list that contains all the weight matrices of your network(_n means it has all matrices)\n",
    "np.random.seed(123)\n",
    "W_n = [np.random.randn(l, next_l) for l, next_l in zip(structure[:-1], structure[1:])]\n",
    "print(\"weight matrix of each layer\\n\")\n",
    "for W in W_n:\n",
    "    print(W)\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_iris().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(150, 4) (150,)\n",
      "150 150\n"
     ]
    }
   ],
   "source": [
    "data = load_iris()['data']\n",
    "target = load_iris()['target']\n",
    "\n",
    "print(type(data), type(target))\n",
    "print(data.shape, target.shape)\n",
    "print(len(data), len(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[0 1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Just pick up 5 indexes out of dataset randomly\n",
    "indexes = [0, 52, 108, 49, 142, 88]\n",
    "\n",
    "data = data[indexes]\n",
    "target = target[indexes]\n",
    "\n",
    "print(data)\n",
    "print()\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [5.6 3.  4.1 1.3]]\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = data\n",
    "print(X)\n",
    "print()\n",
    "\n",
    "Y = np.zeros((6, 3))\n",
    "for i in range(len(Y)):\n",
    "    for j in range(len(Y[i])):\n",
    "        Y[i, target[i]] = 1\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B_n is a list of 3 np.ndarrays with (2, 1),(2, 1),(3, 1)\n",
    "# W_n is a list of 3 np.ndarrays with (4, 2),(2, 2),(2, 3)\n",
    "\n",
    "# X is a np.ndarray with shape (6,4)\n",
    "# Y is a np.ndarray with shape (6,3)\n",
    "\n",
    "# Z_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "# A_n is a list of 3 np.ndarrays with (2,1),(2,1),(3,1)\n",
    "\n",
    "# e_Je_B_ns a list of 3 np.ndarrays with (2,1), (2,1), (3,1)\n",
    "# e_Je_W_ns a list of 3 np.ndarrays with (4,2), (2,2), (2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide sigmoid and sigmoid_derivative function\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1.0 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[-5.91440732e-04  8.75134715e-03]\n",
      " [-4.05890698e-04  6.00582647e-03]\n",
      " [-1.62356279e-04  2.40233059e-03]\n",
      " [-2.31937542e-05  3.43190084e-04]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[-6.24979727e-05  4.26467863e-05]\n",
      " [-6.08447973e-02  4.15187079e-02]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[-0.05243339  0.04414797  0.00344513]\n",
      " [-0.02147409  0.0180808   0.00141095]]\n",
      "\n",
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[ 3.20469338e-07 -4.86008885e-06]\n",
      " [ 1.43978978e-07 -2.18351818e-06]\n",
      " [ 2.27579675e-07 -3.45136745e-06]\n",
      " [ 6.96672475e-08 -1.05654106e-06]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[ 3.16560990e-08 -7.34949565e-09]\n",
      " [ 4.53034900e-02 -1.05179669e-02]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[ 0.04862855 -0.00752288  0.00339298]\n",
      " [ 0.02024309 -0.00313163  0.00141243]]\n",
      "\n",
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[ 6.04612850e-08 -4.83256157e-07]\n",
      " [ 2.25601810e-08 -1.80319462e-07]\n",
      " [ 5.23396198e-08 -4.18341151e-07]\n",
      " [ 1.62433303e-08 -1.29830012e-07]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[7.36316803e-09 3.42960107e-10]\n",
      " [3.50362180e-02 1.63190967e-03]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[ 0.04862798  0.04320949 -0.03169456]\n",
      " [ 0.02024301  0.01798738 -0.01319391]]\n",
      "\n",
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[-6.10405885e-04  7.12911884e-03]\n",
      " [-4.02867884e-04  4.70521843e-03]\n",
      " [-1.70913648e-04  1.99615328e-03]\n",
      " [-2.44162354e-05  2.85164754e-04]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[-6.57992084e-05  4.48915350e-05]\n",
      " [-6.13328698e-02  4.18443738e-02]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[-0.05231148  0.04399231  0.00343602]\n",
      " [-0.02147815  0.01806245  0.00141077]]\n",
      "\n",
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[ 1.73077202e-07 -4.59862204e-06]\n",
      " [ 8.05704215e-08 -2.14073784e-06]\n",
      " [ 1.52188574e-07 -4.04361593e-06]\n",
      " [ 5.66977040e-08 -1.50644515e-06]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[2.43486279e-08 1.13412664e-09]\n",
      " [3.50354530e-02 1.63190472e-03]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[ 0.04862879  0.04321009 -0.03169493]\n",
      " [ 0.02024313  0.01798744 -0.01319393]]\n",
      "\n",
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "[[ 2.67647923e-06 -4.26212797e-05]\n",
      " [ 1.43382816e-06 -2.28328284e-05]\n",
      " [ 1.95956515e-06 -3.12048655e-05]\n",
      " [ 6.21325536e-07 -9.89422564e-06]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "[[ 3.25761107e-07 -7.56302070e-08]\n",
      " [ 4.52959547e-02 -1.05161186e-02]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "[[ 0.04863492 -0.00752387  0.00339325]\n",
      " [ 0.02024402 -0.00313177  0.00141242]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set the output layer to H and let L begin from the first hidden layer(not from the input layer)\n",
    "H = len(structure) - 2\n",
    "learning_rate = 0.1\n",
    "\n",
    "for x, y in zip(X, Y):     # x의 shape:(4,),  y의 shape:(3,)\n",
    "    \n",
    "    # Forward Propagate\n",
    "    # Create two lists that contain pre and post activation vector of each layer, respectively\n",
    "    Z_n, A_n = [], []\n",
    "    \n",
    "    for i, (b, W) in enumerate(zip(B_n, W_n)):\n",
    "        if i == 0:\n",
    "            z = np.dot(np.array(W).T, x).reshape(-1, 1) + np.array(b)\n",
    "        else:\n",
    "            z = np.dot(np.array(W).T, a).reshape(-1, 1) + np.array(b)\n",
    "        a = sigmoid(z)\n",
    "\n",
    "        Z_n.append(z)\n",
    "        A_n.append(a)\n",
    "    # print(Z_n) \n",
    "    # print()  \n",
    "    \n",
    "    \n",
    "    # Backpropagate\n",
    "    # Initialize a list called e_Je_W_ns that will contain e_Je_W matrices for each layer\n",
    "    e_Je_W_ns = [np.zeros(W.shape) for W in W_n]    # (4, 2), (2, 2), (2, 3)\n",
    "    #for x in e_Je_W_ns:\n",
    "    #    print(x.shape)\n",
    "    #print()\n",
    "\n",
    "    # Initialize a list called e_Je_B_ns that will contain e_Je_B vectors for each layer\n",
    "    e_Je_B_ns = [np.zeros(B.shape) for B in B_n]    # (2, 1), (2, 1), (3, 1)\n",
    "    \n",
    "    for L in range(H, -1, -1):\n",
    "        if L != H:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * np.dot(W_n[L+1], delta)\n",
    "        else:\n",
    "            delta = sigmoid_derivative(Z_n[L]) * (A_n[L] - y.reshape(-1, 1))\n",
    "            \n",
    "        e_Je_B_ns[L] = delta\n",
    "        # print(f\"{L} : {delta}\")\n",
    "        \n",
    "        if L != 0:\n",
    "            e_Je_W_ns[L] = np.dot(A_n[L-1], delta.T)\n",
    "        else:\n",
    "            e_Je_W_ns[L] = np.dot(x.reshape(-1, 1), delta.T)\n",
    "    \n",
    "    \"\"\"\n",
    "    for x in e_Je_W_ns:\n",
    "        print(x)\n",
    "    print()\n",
    "    \"\"\"\n",
    "    \n",
    "    for i, (wn, ejew, bn, ejeb) in enumerate(zip(W_n, e_Je_W_ns, B_n, e_Je_B_ns)):\n",
    "        #W_n[i] -= learning_rate/len(X) * ejew\n",
    "        #B_n[i] -= learning_rate/len(X) * ejeb\n",
    "        print(wn)\n",
    "        print(ejew)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48835056, -0.64420125, -0.44232442],\n",
       "       [-0.43563446,  2.20374093,  2.18747708]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0855908   0.99682108]\n",
      " [ 0.2830053  -1.50664865]\n",
      " [-0.57858926  1.65129212]\n",
      " [-2.42667769 -0.42893303]]\n",
      "\n",
      "[[ 1.26594051 -0.86674331]\n",
      " [-0.68022852 -0.09688271]]\n",
      "\n",
      "[[ 1.48835056 -0.64420125 -0.44232442]\n",
      " [-0.43563446  2.20374093  2.18747708]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in W_n:\n",
    "    print(x)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[-1.0856306   0.99734545]\n",
    " [ 0.2829785  -1.50629471]\n",
    " [-0.57860025  1.65143654]\n",
    " [-2.42667924 -0.42891263]]\n",
    "\n",
    "[[ 1.26593626 -0.8667404 ]\n",
    " [-0.67888615 -0.09470897]]\n",
    "\n",
    "[[ 1.49138963 -0.638902   -0.44398196]\n",
    " [-0.43435128  2.20593008  2.18678609]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.68546237e-06 -4.26149872e-05]\n",
      " [ 1.43864056e-06 -2.28294574e-05]\n",
      " [ 1.96614210e-06 -3.12002585e-05]\n",
      " [ 6.23410908e-07 -9.89276488e-06]]\n",
      "\n",
      "[[ 3.27416513e-07 -7.50649946e-08]\n",
      " [ 4.55425009e-02 -1.04412803e-02]]\n",
      "\n",
      "[[ 0.04896634 -0.00734351  0.00337623]\n",
      " [ 0.02042727 -0.00306349  0.00140846]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in e_Je_W_ns:\n",
    "    print(x)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
