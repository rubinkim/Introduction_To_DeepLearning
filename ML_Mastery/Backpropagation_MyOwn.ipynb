{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import random, seed\n",
    "from math import exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    # Create a list named 'network' in which I contain hidden and output layer\n",
    "    network = []\n",
    "    \n",
    "    # Create a hidden layer\n",
    "    hidden_layer = [{'weights' : [random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    \n",
    "    # Create a output layer\n",
    "    output_layer = [{'weights' : [random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Forward Propagate Inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1. Neuron Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activaton for an input\n",
    "def activate(weights, inputs):\n",
    "    # Include the bias for calculation\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. Neuron Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    # Sigmoid(Logistic) function is applied\n",
    "    return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-3. Forward Propagate input to a network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "    # Create a variable 'input' to forward propagate the neurons in the input layer to the hidden layer\n",
    "    # and save the values in row to the variable 'input'.\n",
    "    inputs = row\n",
    "    \n",
    "    # Loop the network list to access the layers sequentially\n",
    "    for layer in network:\n",
    "        # Create a variable 'new_inputs' to contain the values that result from activate and transfer.\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "            \n",
    "        # We need this to be used as the input to the next layer\n",
    "        inputs = new_inputs\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Back Propagate Error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1. Transfer Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    # Sigmoid(Logistic) funtion is used.\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2. Error Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected):\n",
    "    for i in range(len(network)-1, -1, -1):\n",
    "        \n",
    "        # Start with the output layer because outputs flows backwards from output layer to input layer.\n",
    "        layer = network[i]   # output layer\n",
    "        # error_signal = error * transfer_derivative(output) for the output layer\n",
    "        errors, error_signals = [],[]  \n",
    "        \n",
    "        for k, neuron in enumerate(layer):\n",
    "            if i == len(network) - 1:\n",
    "                error = neuron['output'] - expected[k]\n",
    "                error_signal = error * transfer_derivative(neuron['output'])\n",
    "            else:\n",
    "                error = 0.0\n",
    "                for j, next_neuron in enumerate(network[i+1]):\n",
    "                    error += next_neuron['weights'][k] * next_neuron['delta']\n",
    "                    error_signal = error * transfer_derivative(neuron['output'])\n",
    "                    \n",
    "            errors.append(error)\n",
    "            error_signals.append(error_signal)\n",
    "            neuron['delta'] = error_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610517}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "# test backpropagation of error\n",
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    " [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1. Update network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i, layer in enumerate(network):\n",
    "        if i == 0:\n",
    "            inputs = row[:-1]     # last element is the target variable\n",
    "        else:\n",
    "            inputs = [neuron['output'] for neuron in network[i-1]]\n",
    "            \n",
    "        for neuron in layer:\n",
    "            for k, input in enumerate(inputs):\n",
    "                neuron['weights'][k] -= l_rate * neuron['delta'] * input\n",
    "                neuron['weights'][-1] -- l_rate * neuron['delta']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    # Implement Stochastic Gradient Descent\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        # For each epoch, train the network by minimizing sum_error\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1 \n",
    "            \n",
    "            sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate) \n",
    "            # print(\">epoch=%d, lrate=%.3f, error=%.3f\"% (epoch, l_rate, sum_error))\n",
    "            print(f\"epoch : {epoch}, lrate : {l_rate}, error : {sum_error}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    " [1.465489372,2.362125076,0],\n",
    " [3.396561688,4.400293529,0],\n",
    " [1.38807019,1.850220317,0],\n",
    " [3.06407232,3.005305973,0],\n",
    " [7.627531214,2.759262235,1],\n",
    " [5.332441248,2.088626775,1],\n",
    " [6.922596716,1.77106367,1],\n",
    " [8.675418651,-0.242068655,1],\n",
    " [7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, lrate : 0.5, error : 0.8201685044785078\n",
      "epoch : 0, lrate : 0.5, error : 1.6048443796616851\n",
      "epoch : 0, lrate : 0.5, error : 2.3737110352546518\n",
      "epoch : 0, lrate : 0.5, error : 3.099604371264342\n",
      "epoch : 0, lrate : 0.5, error : 3.8057010280956374\n",
      "epoch : 0, lrate : 0.5, error : 4.44406104755368\n",
      "epoch : 0, lrate : 0.5, error : 5.040105358865549\n",
      "epoch : 0, lrate : 0.5, error : 5.595516560946015\n",
      "epoch : 0, lrate : 0.5, error : 6.106966394518055\n",
      "epoch : 0, lrate : 0.5, error : 6.572735806403106\n",
      "epoch : 1, lrate : 0.5, error : 0.8017588163645339\n",
      "epoch : 1, lrate : 0.5, error : 1.554235764723766\n",
      "epoch : 1, lrate : 0.5, error : 2.271287679145059\n",
      "epoch : 1, lrate : 0.5, error : 2.937861094620695\n",
      "epoch : 1, lrate : 0.5, error : 3.563806702442225\n",
      "epoch : 1, lrate : 0.5, error : 4.151465521690812\n",
      "epoch : 1, lrate : 0.5, error : 4.686934686810796\n",
      "epoch : 1, lrate : 0.5, error : 5.173678005565783\n",
      "epoch : 1, lrate : 0.5, error : 5.611907021537395\n",
      "epoch : 1, lrate : 0.5, error : 6.003693967305004\n",
      "epoch : 2, lrate : 0.5, error : 0.7791588579143638\n",
      "epoch : 2, lrate : 0.5, error : 1.4959647329990402\n",
      "epoch : 2, lrate : 0.5, error : 2.160677942618154\n",
      "epoch : 2, lrate : 0.5, error : 2.7705103933008535\n",
      "epoch : 2, lrate : 0.5, error : 3.324063805260753\n",
      "epoch : 2, lrate : 0.5, error : 3.899685710119204\n",
      "epoch : 2, lrate : 0.5, error : 4.414671904052277\n",
      "epoch : 2, lrate : 0.5, error : 4.875054926149896\n",
      "epoch : 2, lrate : 0.5, error : 5.284409935037432\n",
      "epoch : 2, lrate : 0.5, error : 5.647628052397665\n",
      "epoch : 3, lrate : 0.5, error : 0.7536477539007584\n",
      "epoch : 3, lrate : 0.5, error : 1.4378103604349572\n",
      "epoch : 3, lrate : 0.5, error : 2.06093458795712\n",
      "epoch : 3, lrate : 0.5, error : 2.6288810574358736\n",
      "epoch : 3, lrate : 0.5, error : 3.133715342264745\n",
      "epoch : 3, lrate : 0.5, error : 3.718601904625882\n",
      "epoch : 3, lrate : 0.5, error : 4.236706180937963\n",
      "epoch : 3, lrate : 0.5, error : 4.695778240756356\n",
      "epoch : 3, lrate : 0.5, error : 5.101427857054211\n",
      "epoch : 3, lrate : 0.5, error : 5.460142365954338\n",
      "epoch : 4, lrate : 0.5, error : 0.7325625801833318\n",
      "epoch : 4, lrate : 0.5, error : 1.3927836509703346\n",
      "epoch : 4, lrate : 0.5, error : 1.9890663226357486\n",
      "epoch : 4, lrate : 0.5, error : 2.531056577094683\n",
      "epoch : 4, lrate : 0.5, error : 3.008532582083034\n",
      "epoch : 4, lrate : 0.5, error : 3.6055406301962405\n",
      "epoch : 4, lrate : 0.5, error : 4.1323959786209565\n",
      "epoch : 4, lrate : 0.5, error : 4.597412220766465\n",
      "epoch : 4, lrate : 0.5, error : 5.007142382896104\n",
      "epoch : 4, lrate : 0.5, error : 5.3688773564498415\n",
      "epoch : 5, lrate : 0.5, error : 0.7179105710064515\n",
      "epoch : 5, lrate : 0.5, error : 1.3622752983885962\n",
      "epoch : 5, lrate : 0.5, error : 1.9427384489393977\n",
      "epoch : 5, lrate : 0.5, error : 2.4694467448103627\n",
      "epoch : 5, lrate : 0.5, error : 2.932351660426529\n",
      "epoch : 5, lrate : 0.5, error : 3.538160757381651\n",
      "epoch : 5, lrate : 0.5, error : 4.072310430633075\n",
      "epoch : 5, lrate : 0.5, error : 4.543042966687652\n",
      "epoch : 5, lrate : 0.5, error : 4.957300933007833\n",
      "epoch : 5, lrate : 0.5, error : 5.3227921763397985\n",
      "epoch : 6, lrate : 0.5, error : 0.708298612610675\n",
      "epoch : 6, lrate : 0.5, error : 1.3422772300745214\n",
      "epoch : 6, lrate : 0.5, error : 1.913558367488095\n",
      "epoch : 6, lrate : 0.5, error : 2.431153851464755\n",
      "epoch : 6, lrate : 0.5, error : 2.886323216835114\n",
      "epoch : 6, lrate : 0.5, error : 3.4971638344660128\n",
      "epoch : 6, lrate : 0.5, error : 4.035853408002307\n",
      "epoch : 6, lrate : 0.5, error : 4.510287168831306\n",
      "epoch : 6, lrate : 0.5, error : 4.92756828046134\n",
      "epoch : 6, lrate : 0.5, error : 5.295684260441635\n",
      "epoch : 7, lrate : 0.5, error : 0.7019657527249382\n",
      "epoch : 7, lrate : 0.5, error : 1.328886091200323\n",
      "epoch : 7, lrate : 0.5, error : 1.8947686381743025\n",
      "epoch : 7, lrate : 0.5, error : 2.4068017408264284\n",
      "epoch : 7, lrate : 0.5, error : 2.8579918289821165\n",
      "epoch : 7, lrate : 0.5, error : 3.470803053640537\n",
      "epoch : 7, lrate : 0.5, error : 4.011564866517321\n",
      "epoch : 7, lrate : 0.5, error : 4.487663204782953\n",
      "epoch : 7, lrate : 0.5, error : 4.906267776180292\n",
      "epoch : 7, lrate : 0.5, error : 5.275647544093847\n",
      "epoch : 8, lrate : 0.5, error : 0.6975938640904102\n",
      "epoch : 8, lrate : 0.5, error : 1.3193763887444667\n",
      "epoch : 8, lrate : 0.5, error : 1.8819693091147358\n",
      "epoch : 8, lrate : 0.5, error : 2.3905935646787446\n",
      "epoch : 8, lrate : 0.5, error : 2.8400546414604335\n",
      "epoch : 8, lrate : 0.5, error : 3.4523385358329683\n",
      "epoch : 8, lrate : 0.5, error : 3.9931346447868954\n",
      "epoch : 8, lrate : 0.5, error : 4.469127686348179\n",
      "epoch : 8, lrate : 0.5, error : 4.88750468619343\n",
      "epoch : 8, lrate : 0.5, error : 5.25692974203009\n",
      "epoch : 9, lrate : 0.5, error : 0.6942633508247544\n",
      "epoch : 9, lrate : 0.5, error : 1.3118977647778105\n",
      "epoch : 9, lrate : 0.5, error : 1.8722085529936794\n",
      "epoch : 9, lrate : 0.5, error : 2.3788281112576373\n",
      "epoch : 9, lrate : 0.5, error : 2.82804298257002\n",
      "epoch : 9, lrate : 0.5, error : 3.4374751809851185\n",
      "epoch : 9, lrate : 0.5, error : 3.976495330757107\n",
      "epoch : 9, lrate : 0.5, error : 4.45075079443385\n",
      "epoch : 9, lrate : 0.5, error : 4.8674023954621815\n",
      "epoch : 9, lrate : 0.5, error : 5.2357920463204355\n",
      "epoch : 10, lrate : 0.5, error : 0.6912558941541229\n",
      "epoch : 10, lrate : 0.5, error : 1.3050175834648234\n",
      "epoch : 10, lrate : 0.5, error : 1.8630187307765402\n",
      "epoch : 10, lrate : 0.5, error : 2.3686112440296037\n",
      "epoch : 10, lrate : 0.5, error : 2.81856888941365\n",
      "epoch : 10, lrate : 0.5, error : 3.422580704548455\n",
      "epoch : 10, lrate : 0.5, error : 3.9580084553559924\n",
      "epoch : 10, lrate : 0.5, error : 4.428805042405521\n",
      "epoch : 10, lrate : 0.5, error : 4.842043776273931\n",
      "epoch : 10, lrate : 0.5, error : 5.208396702563063\n",
      "epoch : 11, lrate : 0.5, error : 0.6878570131168118\n",
      "epoch : 11, lrate : 0.5, error : 1.2973077828723996\n",
      "epoch : 11, lrate : 0.5, error : 1.851423057210565\n",
      "epoch : 11, lrate : 0.5, error : 2.356656430633701\n",
      "epoch : 11, lrate : 0.5, error : 2.807703613133538\n",
      "epoch : 11, lrate : 0.5, error : 3.4031447634770613\n",
      "epoch : 11, lrate : 0.5, error : 3.933043341203901\n",
      "epoch : 11, lrate : 0.5, error : 4.398344481174104\n",
      "epoch : 11, lrate : 0.5, error : 4.805942454413103\n",
      "epoch : 11, lrate : 0.5, error : 5.169403588720918\n",
      "epoch : 12, lrate : 0.5, error : 0.6832472260345432\n",
      "epoch : 12, lrate : 0.5, error : 1.2870783780514243\n",
      "epoch : 12, lrate : 0.5, error : 1.8329087860086535\n",
      "epoch : 12, lrate : 0.5, error : 2.3380588722207496\n",
      "epoch : 12, lrate : 0.5, error : 2.789070603603289\n",
      "epoch : 12, lrate : 0.5, error : 3.3726435786320583\n",
      "epoch : 12, lrate : 0.5, error : 3.895227899938667\n",
      "epoch : 12, lrate : 0.5, error : 4.352507124969272\n",
      "epoch : 12, lrate : 0.5, error : 4.751204759822978\n",
      "epoch : 12, lrate : 0.5, error : 5.111365555189453\n",
      "epoch : 13, lrate : 0.5, error : 0.6770033247167\n",
      "epoch : 13, lrate : 0.5, error : 1.2730955966148492\n",
      "epoch : 13, lrate : 0.5, error : 1.8025211415770301\n",
      "epoch : 13, lrate : 0.5, error : 2.307317454382871\n",
      "epoch : 13, lrate : 0.5, error : 2.7545487801125152\n",
      "epoch : 13, lrate : 0.5, error : 3.326024385359379\n",
      "epoch : 13, lrate : 0.5, error : 3.8398660692285906\n",
      "epoch : 13, lrate : 0.5, error : 4.285494165582994\n",
      "epoch : 13, lrate : 0.5, error : 4.670478269103952\n",
      "epoch : 13, lrate : 0.5, error : 5.0267790529309195\n",
      "epoch : 14, lrate : 0.5, error : 0.6710350629254493\n",
      "epoch : 14, lrate : 0.5, error : 1.2576782236672548\n",
      "epoch : 14, lrate : 0.5, error : 1.763073940535932\n",
      "epoch : 14, lrate : 0.5, error : 2.267168148506131\n",
      "epoch : 14, lrate : 0.5, error : 2.706300488980498\n",
      "epoch : 14, lrate : 0.5, error : 3.2701898856632443\n",
      "epoch : 14, lrate : 0.5, error : 3.7716532590819596\n",
      "epoch : 14, lrate : 0.5, error : 4.199306298117283\n",
      "epoch : 14, lrate : 0.5, error : 4.5648864518260615\n",
      "epoch : 14, lrate : 0.5, error : 4.913505423537239\n",
      "epoch : 15, lrate : 0.5, error : 0.6687210855030963\n",
      "epoch : 15, lrate : 0.5, error : 1.2453431360410414\n",
      "epoch : 15, lrate : 0.5, error : 1.7250285760376713\n",
      "epoch : 15, lrate : 0.5, error : 2.228362196862335\n",
      "epoch : 15, lrate : 0.5, error : 2.6580547264917342\n",
      "epoch : 15, lrate : 0.5, error : 3.2134376745061224\n",
      "epoch : 15, lrate : 0.5, error : 3.6956920110000064\n",
      "epoch : 15, lrate : 0.5, error : 4.098155853613648\n",
      "epoch : 15, lrate : 0.5, error : 4.440316475813691\n",
      "epoch : 15, lrate : 0.5, error : 4.7751297972274305\n",
      "epoch : 16, lrate : 0.5, error : 0.6690246280335146\n",
      "epoch : 16, lrate : 0.5, error : 1.233448700204015\n",
      "epoch : 16, lrate : 0.5, error : 1.6871987042073755\n",
      "epoch : 16, lrate : 0.5, error : 2.188562246270509\n",
      "epoch : 16, lrate : 0.5, error : 2.607777087135743\n",
      "epoch : 16, lrate : 0.5, error : 3.14784078967\n",
      "epoch : 16, lrate : 0.5, error : 3.604404236401234\n",
      "epoch : 16, lrate : 0.5, error : 3.977111559226087\n",
      "epoch : 16, lrate : 0.5, error : 4.294234396888944\n",
      "epoch : 16, lrate : 0.5, error : 4.610699063411269\n",
      "epoch : 17, lrate : 0.5, error : 0.6682796773118349\n",
      "epoch : 17, lrate : 0.5, error : 1.2155607528453862\n",
      "epoch : 17, lrate : 0.5, error : 1.642050176396224\n",
      "epoch : 17, lrate : 0.5, error : 2.1384139950427534\n",
      "epoch : 17, lrate : 0.5, error : 2.5445872230155553\n",
      "epoch : 17, lrate : 0.5, error : 3.0624192176706893\n",
      "epoch : 17, lrate : 0.5, error : 3.488992943666258\n",
      "epoch : 17, lrate : 0.5, error : 3.8304728842817424\n",
      "epoch : 17, lrate : 0.5, error : 4.122509234475266\n",
      "epoch : 17, lrate : 0.5, error : 4.4184394344170475\n",
      "epoch : 18, lrate : 0.5, error : 0.6635186721048332\n",
      "epoch : 18, lrate : 0.5, error : 1.187303756834618\n",
      "epoch : 18, lrate : 0.5, error : 1.5854609847242807\n",
      "epoch : 18, lrate : 0.5, error : 2.0724512621097895\n",
      "epoch : 18, lrate : 0.5, error : 2.4621672540576904\n",
      "epoch : 18, lrate : 0.5, error : 2.9519705635771043\n",
      "epoch : 18, lrate : 0.5, error : 3.3467514848191797\n",
      "epoch : 18, lrate : 0.5, error : 3.657701394051655\n",
      "epoch : 18, lrate : 0.5, error : 3.925530890880432\n",
      "epoch : 18, lrate : 0.5, error : 4.200640093800341\n",
      "epoch : 19, lrate : 0.5, error : 0.6527680423968523\n",
      "epoch : 19, lrate : 0.5, error : 1.1469821016123505\n",
      "epoch : 19, lrate : 0.5, error : 1.5166973484340511\n",
      "epoch : 19, lrate : 0.5, error : 1.9893365883649514\n",
      "epoch : 19, lrate : 0.5, error : 2.359268991367373\n",
      "epoch : 19, lrate : 0.5, error : 2.816525517145648\n",
      "epoch : 19, lrate : 0.5, error : 3.179940989733504\n",
      "epoch : 19, lrate : 0.5, error : 3.462248392200836\n",
      "epoch : 19, lrate : 0.5, error : 3.707280162631106\n",
      "epoch : 19, lrate : 0.5, error : 3.9625986554053196\n",
      "[{'weights': [1.059701226717645, 0.4228210299557029, 0.4453871940548014], 'output': 0.9999572841499275, 'delta': 3.574138792343127e-06}, {'weights': [0.7809135780796149, -1.2148681083275472, 0.9452706955539223], 'output': 0.8899896440842864, 'delta': -0.016425926921201088}]\n",
      "\n",
      "[{'weights': [0.4305801224800517, -1.3006372401709931, 0.0254458609934608], 'output': 0.3472809686979757, 'delta': 0.07872057253767108}, {'weights': [-0.5048326592461019, 0.83705212130071, 0.38120423768821243], 'output': 0.6329653673637737, 'delta': -0.08526956332838513}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[0.8094918973879515, 0.7734292563511262]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n_outputs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m([row[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m dataset]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m network \u001b[39m=\u001b[39m initialize_network(n_inputs, \u001b[39m2\u001b[39m, n_outputs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_network(network, dataset, \u001b[39m0.5\u001b[39;49m, \u001b[39m20\u001b[39;49m, n_outputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m network:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(layer)\n",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(network, train, l_rate, n_epoch, n_outputs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sum_error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(expected[i] \u001b[39m-\u001b[39m outputs[\u001b[39m0\u001b[39m][i]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(expected))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m backward_propagate_error(network, expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m update_weights(network, row, l_rate) \n",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sum_error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(expected[i] \u001b[39m-\u001b[39m outputs[\u001b[39m0\u001b[39;49m][i]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(expected))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m backward_propagate_error(network, expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m update_weights(network, row, l_rate) \n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(expected)):\n",
    "    expected = [0 for i in range(3)]\n",
    "    expected[i] = 1\n",
    "    print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "outputs = [1,0,2,0,1,5]\n",
    "for output in outputs:\n",
    "    expected = [0 for j in range(len(outputs))]\n",
    "    expected[output] = 1\n",
    "    print(expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
