{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import random, seed\n",
    "from math import exp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    # Create a list named 'network' in which I contain hidden and output layer\n",
    "    network = []\n",
    "    \n",
    "    # Create a hidden layer\n",
    "    hidden_layer = [{'weights' : [random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    \n",
    "    # Create a output layer\n",
    "    output_layer = [{'weights' : [random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Forward Propagate Inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-1. Neuron Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate neuron activaton for an input\n",
    "def activate(weights, inputs):\n",
    "    # Include the bias for calculation\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-2. Neuron Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    # Sigmoid(Logistic) function is applied\n",
    "    return 1.0 / (1.0 + exp(-activation))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2-3. Forward Propagate input to a network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagate(network, row):\n",
    "    # Create a variable 'input' to forward propagate the neurons in the input layer to the hidden layer\n",
    "    # and save the values in row to the variable 'input'.\n",
    "    inputs = row\n",
    "    \n",
    "    # Loop the network list to access the layers sequentially\n",
    "    for layer in network:\n",
    "        # Create a variable 'new_inputs' to contain the values that result from activate and transfer.\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "            \n",
    "        # We need this to be used as the input to the next layer\n",
    "        inputs = new_inputs\n",
    "        \n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Back Propagate Error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-1. Transfer Derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    # Sigmoid(Logistic) funtion is used.\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3-2. Error Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagate_error(network, expected):\n",
    "    for i in range(len(network)-1, -1, -1):\n",
    "        \n",
    "        # Start with the output layer because outputs flows backwards from output layer to input layer.\n",
    "        layer = network[i]   # output layer\n",
    "        # error_signal = error * transfer_derivative(output) for the output layer\n",
    "        errors, error_signals = [],[]  \n",
    "        \n",
    "        for k, neuron in enumerate(layer):\n",
    "            if i == len(network) - 1:\n",
    "                error = neuron['output'] - expected[k]\n",
    "                error_signal = error * transfer_derivative(neuron['output'])\n",
    "            else:\n",
    "                error = 0.0\n",
    "                for j, next_neuron in enumerate(network[i+1]):\n",
    "                    error += next_neuron['weights'][k] * next_neuron['delta']\n",
    "                    error_signal = error * transfer_derivative(neuron['output'])\n",
    "                    \n",
    "            errors.append(error)\n",
    "            error_signals.append(error_signal)\n",
    "            neuron['delta'] = error_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610517}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "# test backpropagation of error\n",
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    " [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1. Update network weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i, layer in enumerate(network):\n",
    "        if i == 0:\n",
    "            inputs = row[:-1]     # last element is the target variable\n",
    "        else:\n",
    "            inputs = [neuron['output'] for neuron in network[i-1]]\n",
    "            \n",
    "        for neuron in layer:\n",
    "            for k, input in enumerate(inputs):\n",
    "                neuron['weights'][k] -= l_rate * neuron['delta'] * input\n",
    "                neuron['weights'][-1] -- l_rate * neuron['delta']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: invalid syntax (2521316650.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [46]\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"epoch : {epoch>2d}, lrate : {l_rate}, error : {sum_error}\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    # Implement Stochastic Gradient Descent\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        # For each epoch, train the network by minimizing sum_error\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1 \n",
    "            \n",
    "            sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])\n",
    "        backward_propagate_error(network, expected)\n",
    "        update_weights(network, row, l_rate) \n",
    "        # print(\">epoch=%d, lrate=%.3f, error=%.3f\"% (epoch, l_rate, sum_error))\n",
    "        print(f\"epoch : {epoch>2d}, lrate : {l_rate}, error : {sum_error}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test training backprop algorithm\n",
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    " [1.465489372,2.362125076,0],\n",
    " [3.396561688,4.400293529,0],\n",
    " [1.38807019,1.850220317,0],\n",
    " [3.06407232,3.005305973,0],\n",
    " [7.627531214,2.759262235,1],\n",
    " [5.332441248,2.088626775,1],\n",
    " [6.922596716,1.77106367,1],\n",
    " [8.675418651,-0.242068655,1],\n",
    " [7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.500, error=6.713\n",
      ">epoch=1, lrate=0.500, error=6.635\n",
      ">epoch=2, lrate=0.500, error=6.550\n",
      ">epoch=3, lrate=0.500, error=6.460\n",
      ">epoch=4, lrate=0.500, error=6.367\n",
      ">epoch=5, lrate=0.500, error=6.277\n",
      ">epoch=6, lrate=0.500, error=6.193\n",
      ">epoch=7, lrate=0.500, error=6.121\n",
      ">epoch=8, lrate=0.500, error=6.066\n",
      ">epoch=9, lrate=0.500, error=6.030\n",
      ">epoch=10, lrate=0.500, error=6.015\n",
      ">epoch=11, lrate=0.500, error=6.020\n",
      ">epoch=12, lrate=0.500, error=6.043\n",
      ">epoch=13, lrate=0.500, error=6.080\n",
      ">epoch=14, lrate=0.500, error=6.129\n",
      ">epoch=15, lrate=0.500, error=6.186\n",
      ">epoch=16, lrate=0.500, error=6.248\n",
      ">epoch=17, lrate=0.500, error=6.313\n",
      ">epoch=18, lrate=0.500, error=6.380\n",
      ">epoch=19, lrate=0.500, error=6.447\n",
      "[{'weights': [0.13007336290078605, 0.8454718780783583, 0.763774618976614], 'output': 0.9911266714210061, 'delta': -0.00035184083782383035}, {'weights': [0.25192063083482386, 0.49399559106998153, 0.4494910647887381], 'output': 0.983541865395868, 'delta': -0.0007175332832771064}]\n",
      "\n",
      "[{'weights': [-0.534856489632628, -0.38700736681078995, 0.0938595867742349], 'output': 0.321116317202378, 'delta': 0.07000355882040082}, {'weights': [0.28342355154478777, 1.088573270237146, 0.43276706790505337], 'output': 0.8540336728918916, 'delta': -0.018196185466927892}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n",
      "[0.8094918973879515, 0.7734292563511262]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m n_outputs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m([row[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m dataset]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m network \u001b[39m=\u001b[39m initialize_network(n_inputs, \u001b[39m2\u001b[39m, n_outputs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_network(network, dataset, \u001b[39m0.5\u001b[39;49m, \u001b[39m20\u001b[39;49m, n_outputs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m network:\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(layer)\n",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(network, train, l_rate, n_epoch, n_outputs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sum_error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(expected[i] \u001b[39m-\u001b[39m outputs[\u001b[39m0\u001b[39m][i]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(expected))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m backward_propagate_error(network, expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m update_weights(network, row, l_rate) \n",
      "\u001b[1;32me:\\딥러닝입문\\ML_Mastery\\Backpropagation_MyOwn.ipynb Cell 23\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(outputs) \n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sum_error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m([(expected[i] \u001b[39m-\u001b[39m outputs[\u001b[39m0\u001b[39;49m][i]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(expected))])\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m backward_propagate_error(network, expected)\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/%EB%94%A5%EB%9F%AC%EB%8B%9D%EC%9E%85%EB%AC%B8/ML_Mastery/Backpropagation_MyOwn.ipynb#X33sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m update_weights(network, row, l_rate) \n",
      "\u001b[1;31mTypeError\u001b[0m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1\n",
    "n_outputs = len(set([row[-1] for row in dataset]))\n",
    "network = initialize_network(n_inputs, 2, n_outputs)\n",
    "train_network(network, dataset, 0.5, 20, n_outputs)\n",
    "\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0]\n",
      "[0, 1, 0]\n",
      "[0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(expected)):\n",
    "    expected = [0 for i in range(3)]\n",
    "    expected[i] = 1\n",
    "    print(expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 0, 0, 0]\n",
      "[0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "outputs = [1,0,2,0,1,5]\n",
    "for output in outputs:\n",
    "    expected = [0 for j in range(len(outputs))]\n",
    "    expected[output] = 1\n",
    "    print(expected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
