{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This tutorial is broken down into 6 parts:\n",
    "- Initialize Network\n",
    "- Forward Propagate Inputs\n",
    "    - Neuron Activation\n",
    "    - Neuron Transfer\n",
    "    - Forward Propagation\n",
    "- Back Propagate Error\n",
    "- Train Network\n",
    "- Predict\n",
    "- Seeds Dataset Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, seed\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    \n",
    "    network = list()\n",
    "    \n",
    "    hidden_layer = [{\"weights\" : [random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    \n",
    "    output_layer = [{\"weights\" : [random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    # Sigmoid(Logistic) function is applied.\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Forward Propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Forward Propagate inputs to a network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n",
      "\n",
      "[0.6629970129852887, 0.7253160725279748]\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "network = initialize_network(2,1,2)\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "print()\n",
    "    \n",
    "row = [1, 0, None]\n",
    "output = forward_propagate(network, row)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}], [{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
      "\n",
      "input layer의 neuron값 : [0.7105668883115941]\n",
      "output layer의 첫번째 neuron값 : 0.6629970129852887,  output layer의 두번째 neuron값 : 0.7253160725279748\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "network = initialize_network(2,1,2)\n",
    "print(network)\n",
    "print()\n",
    "\n",
    "# Activate a neuron\n",
    "input = [1, 0, None]\n",
    "hidden_1 = [transfer(activate(network[0][0]['weights'], input))]\n",
    "print(f\"input layer의 neuron값 : {hidden_1}\")\n",
    "\n",
    "output_1 = transfer(activate(network[1][0]['weights'], hidden_1))\n",
    "output_2 = transfer(activate(network[1][1]['weights'], hidden_1))\n",
    "print(f\"output layer의 첫번째 neuron값 : {output_1},  output layer의 두번째 neuron값 : {output_2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
