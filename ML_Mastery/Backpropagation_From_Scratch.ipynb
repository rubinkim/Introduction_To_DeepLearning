{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This tutorial is broken down into 6 parts:\n",
    "- Initialize Network\n",
    "- Forward Propagate Inputs\n",
    "    - Neuron Activation\n",
    "    - Neuron Transfer\n",
    "    - Forward Propagation\n",
    "- Back Propagate Error\n",
    "- Train Network\n",
    "- Predict\n",
    "- Seeds Dataset Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, seed\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a network\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    \n",
    "    network = list()\n",
    "    \n",
    "    hidden_layer = [{\"weights\" : [random() for i in range(n_inputs+1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    \n",
    "    output_layer = [{\"weights\" : [random() for i in range(n_hidden+1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    \n",
    "    return network\n",
    "\n",
    "# Calculate neuron activation for an input\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "# Transfer neuron activation\n",
    "def transfer(activation):\n",
    "    # Sigmoid(Logistic) function is applied.\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "# Forward Propagate input to a network output\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test Forward Propagate inputs to a network output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941}\n",
      "{'weights': [0.2550690257394217, 0.49543508709194095], 'output': 0.6629970129852887}\n",
      "{'weights': [0.4494910647887381, 0.651592972722763], 'output': 0.7253160725279748}\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "network = initialize_network(2,1,2)\n",
    "row = [1,0,None]\n",
    "output = forward_propagate(network, row)\n",
    "\n",
    "for layer in network:\n",
    "    for neuron in layer:\n",
    "        print(neuron)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n",
      "\n",
      "\n",
      "[[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941}], [{'weights': [0.2550690257394217, 0.49543508709194095], 'output': 0.6629970129852887}, {'weights': [0.4494910647887381, 0.651592972722763], 'output': 0.7253160725279748}]]\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "network = initialize_network(2,1,2)\n",
    "for layer in network:\n",
    "    print(layer)    \n",
    "print()\n",
    "    \n",
    "row = [1, 0, None]\n",
    "output = forward_propagate(network, row)\n",
    "print()\n",
    "\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}], [{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
      "\n",
      "input layer의 neuron값 : [0.7105668883115941]\n",
      "output layer의 첫번째 neuron값 : 0.6629970129852887,  output layer의 두번째 neuron값 : 0.7253160725279748\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "network = initialize_network(2,1,2)\n",
    "print(network)\n",
    "print()\n",
    "\n",
    "# Activate a neuron\n",
    "input = [1, 0, None]\n",
    "hidden_1 = [transfer(activate(network[0][0]['weights'], input))]\n",
    "print(f\"input layer의 neuron값 : {hidden_1}\")\n",
    "\n",
    "output_1 = transfer(activate(network[1][0]['weights'], hidden_1))\n",
    "output_2 = transfer(activate(network[1][1]['weights'], hidden_1))\n",
    "print(f\"output layer의 첫번째 neuron값 : {output_1},  output layer의 두번째 neuron값 : {output_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213859615555266, 0, 0.6213859615555266\n",
      "0.6573693455986976, 1, -0.34263065440130236\n",
      "\n",
      "[0.6213859615555266, -0.34263065440130236]\n",
      "\n",
      "델타 : 0.14619064683582808\n",
      "델타 : -0.0771723774346327\n",
      "에러 : 0.03728870586063054\n",
      "에러 : 0.0026004117552590952\n",
      "[0.0026004117552590952]\n",
      "\n",
      "델타 : 0.0005348048046610517\n",
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610517}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    " [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "\n",
    "expected = [0, 1]\n",
    "\n",
    "for i in reversed(range(len(network))):\n",
    "    layer = network[i]\n",
    "    # print(layer)\n",
    "    errors = list()\n",
    "    if i != len(network)-1:\n",
    "        for j in range(len(layer)):\n",
    "            error = 0.0\n",
    "            for neuron in network[i+1]:\n",
    "                error += (neuron['weights'][j] * neuron['delta'])\n",
    "                print(f\"에러 : {error}\")\n",
    "            errors.append(error)\n",
    "            # print(errors)\n",
    "            # print()\n",
    "    else:\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            error = neuron['output'] - expected[j]\n",
    "            errors.append(error)\n",
    "            # errors.append((neuron['output'] - expected[j])) \n",
    "            print(f\"{neuron['output']}, {expected[j]}, {error}\")\n",
    "        print()\n",
    "    print(errors)\n",
    "    print()\n",
    "    \n",
    "    for j in range(len(layer)):\n",
    "        neuron = layer[j]   \n",
    "        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "        print(f\"델타 : {neuron['delta']}\")\n",
    "        \n",
    "for layer in network:\n",
    "    print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "델타 : 0.0005348048046610531\n",
    "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': \n",
    "    0.0005348048046610531}]\n",
    "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, \n",
    " {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6213859615555266, 0, 0.6213859615555266\n",
      "0.6573693455986976, 1, -0.34263065440130236\n",
      "\n",
      "[0.6213859615555266, -0.34263065440130236]\n",
      "\n",
      "델타 : 0.14619064683582808\n",
      "델타 : -0.0771723774346327\n",
      "에러 : 0.037288705860630544\n",
      "에러 : 0.002600411755259102\n",
      "[0.002600411755259102]\n",
      "\n",
      "델타 : 0.0005348048046610531\n",
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610531}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    " [{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "\n",
    "expected = [0, 1]\n",
    "\n",
    "for i in reversed(range(len(network))):\n",
    "    layer = network[i]\n",
    "    # print(layer)\n",
    "    errors = list()\n",
    "    if i != len(network)-1:\n",
    "        for j in range(len(layer)):\n",
    "            error = 0.0\n",
    "            for i, neuron in enumerate(network[i+1]):\n",
    "                # error += (neuron['weights'][j] * neuron['delta'])\n",
    "                error += neuron['weights'][j] * (neuron['output']-expected[i]) * transfer_derivative(neuron['output'])\n",
    "                print(f\"에러 : {error}\")\n",
    "            errors.append(error)\n",
    "            # print(errors)\n",
    "            # print()\n",
    "    else:\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            error = neuron['output'] - expected[j]\n",
    "            errors.append(error)\n",
    "            # errors.append((neuron['output'] - expected[j])) \n",
    "            print(f\"{neuron['output']}, {expected[j]}, {error}\")\n",
    "        print()\n",
    "    print(errors)\n",
    "    print()\n",
    "    \n",
    "    for j in range(len(layer)):\n",
    "        neuron = layer[j]   \n",
    "        neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "        print(f\"델타 : {neuron['delta']}\")\n",
    "        \n",
    "for layer in network:\n",
    "    print(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03728870586063054\n",
      "0.0026004117552590952\n"
     ]
    }
   ],
   "source": [
    "er_1 = 0.2550690257394217 * 0.14619064683582808\n",
    "print(er_1)\n",
    "er_2 = er_1 + 0.4494910647887381 * (-0.0771723774346327)\n",
    "print(er_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': \n",
    "    0.0005348048046610517}]\n",
    "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, \n",
    " {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error = (weight_k * error_j) * transfer_derivative(output)\n",
    "# Where error_j is the error signal from the jth neuron in the output layer, \n",
    "# weight_k is the weight connecting the kth neuron of the hidden layer to the current neuron in the output layer.\n",
    "# output is the output for the current neuron in the output layer.\n",
    "# The delta value of the current neuron in the output layer = error_j * transfer_derivative[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'delta': 0.0005348048046610517}]\n",
      "[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095], 'delta': 0.14619064683582808}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763], 'delta': -0.0771723774346327}]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "\treturn output * (1.0 - output)\n",
    "\n",
    "# Backpropagate error and store in neurons\n",
    "def backward_propagate_error(network, expected):\n",
    "\tfor i in reversed(range(len(network))):\n",
    "\t\tlayer = network[i]\n",
    "\t\terrors = list()\n",
    "\t\tif i != len(network)-1:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\terror = 0.0\n",
    "\t\t\t\tfor neuron in network[i + 1]:\n",
    "\t\t\t\t\terror += (neuron['weights'][j] * neuron['delta'])\n",
    "\t\t\t\terrors.append(error)\n",
    "\t\telse:\n",
    "\t\t\tfor j in range(len(layer)):\n",
    "\t\t\t\tneuron = layer[j]\n",
    "\t\t\t\terrors.append(neuron['output'] - expected[j])\n",
    "\t\tfor j in range(len(layer)):\n",
    "\t\t\tneuron = layer[j]\n",
    "\t\t\tneuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "# test backpropagation of error\n",
    "network = [[{'output': 0.7105668883115941, 'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}],\n",
    "\t\t[{'output': 0.6213859615555266, 'weights': [0.2550690257394217, 0.49543508709194095]}, {'output': 0.6573693455986976, 'weights': [0.4494910647887381, 0.651592972722763]}]]\n",
    "expected = [0, 1]\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "\tprint(layer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
